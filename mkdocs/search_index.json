{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to SCONE\n\n\nSCONE is a platform to \nbuild and run secure applications\n. While we focus on securing containers and cloud-native applications, SCONE can help you to secure almost any program running on top of Linux.\n\n\nSo, what problems can SCONE help me to solve?\n\n\n\n\n\n\nsecure application configuration\n, i.e., providing applications with secrets in a secure fashion. \nWhy is that a problem?\n Say, you want to run MySQL and you configure MySQL to encrypt its data at rest. To do so, MySQL requires a key to decrypt and encrypt its files. One can store this key in the MySQL configuration file but this configuration file cannot be encrypted since MySQL would need a key to decrypt the file. SCONE can transparently encrypt this configuration file and ensure that only MySQL can get access to the key. \nHow can SCONE do that?\n Continue to read to learn about \ntransparent attestation and secure configuration\n.\n\n\n\n\n\n\nsecure environment variables\n, i.e., give applications access to environment variables that are not visible to anybody else - even users with root access. \nWhy would I need this?\n Consider the MySQL example from above. Instead of storing the key to encrypt files inside the MySQL configuration file, you could pass the key as an environment variable. Hence, we need to protect environment variables from accesses by adversaries.\n\n\n\n\n\n\nsecure command line arguments\n, i.e., some applications might not use environment variables but command line arguments to pass secrets to the application. SCONE provides a secure way to pass arguments to your application without other privileged parties, like the operating system, being able to see the arguments.\n\n\n\n\n\n\nsecure main memory\n. An adversary with root access can read the memory content of any process. In this way, an adversary can get access the keys that an application is using, for example, to protect its data at rest. SCONE helps to protect the main memory from accesses not only from any adversary but also from the operating system, the hypervisor and even the cloud provider despite having physical access to the machines.\n\n\n\n\n\n\ntransparent TLS\n: some popular applications like memcached do not support TLS out of the box. SCONE can transparently add TLS encryption to TCP connections. Unlike alternatives like \nstunnel\n that uses an external process, in SCONE, the plain text is never seen by the operating system. \n\n\n\n\n\n\ntransparent file protection\n, i.e., SCONE can protect the integrity and confidentiality of files. A file can either be \nintegrity-protected\n (i.e., the file is stored in plain text but modifications are detected) or \nconfidentiality-\n and \nintegrity-protected\n (i.e., the file is encrypted and modifications are detected).\n\n\n\n\n\n\nAuthor: Christof Fetzer, October 2017",
            "title": "Introduction"
        },
        {
            "location": "/#welcome-to-scone",
            "text": "SCONE is a platform to  build and run secure applications . While we focus on securing containers and cloud-native applications, SCONE can help you to secure almost any program running on top of Linux.  So, what problems can SCONE help me to solve?    secure application configuration , i.e., providing applications with secrets in a secure fashion.  Why is that a problem?  Say, you want to run MySQL and you configure MySQL to encrypt its data at rest. To do so, MySQL requires a key to decrypt and encrypt its files. One can store this key in the MySQL configuration file but this configuration file cannot be encrypted since MySQL would need a key to decrypt the file. SCONE can transparently encrypt this configuration file and ensure that only MySQL can get access to the key.  How can SCONE do that?  Continue to read to learn about  transparent attestation and secure configuration .    secure environment variables , i.e., give applications access to environment variables that are not visible to anybody else - even users with root access.  Why would I need this?  Consider the MySQL example from above. Instead of storing the key to encrypt files inside the MySQL configuration file, you could pass the key as an environment variable. Hence, we need to protect environment variables from accesses by adversaries.    secure command line arguments , i.e., some applications might not use environment variables but command line arguments to pass secrets to the application. SCONE provides a secure way to pass arguments to your application without other privileged parties, like the operating system, being able to see the arguments.    secure main memory . An adversary with root access can read the memory content of any process. In this way, an adversary can get access the keys that an application is using, for example, to protect its data at rest. SCONE helps to protect the main memory from accesses not only from any adversary but also from the operating system, the hypervisor and even the cloud provider despite having physical access to the machines.    transparent TLS : some popular applications like memcached do not support TLS out of the box. SCONE can transparently add TLS encryption to TCP connections. Unlike alternatives like  stunnel  that uses an external process, in SCONE, the plain text is never seen by the operating system.     transparent file protection , i.e., SCONE can protect the integrity and confidentiality of files. A file can either be  integrity-protected  (i.e., the file is stored in plain text but modifications are detected) or  confidentiality-  and  integrity-protected  (i.e., the file is encrypted and modifications are detected).    Author: Christof Fetzer, October 2017",
            "title": "Welcome to SCONE"
        },
        {
            "location": "/outline/",
            "text": "Outline\n\n\n\n\n\n\nApplication-Oriented Security\n: we give a short introduction into application-oriented security provided by SCONE.\n\n\n\n\n\n\nSCONE Background\n: we give a short introduction into why good systems security is difficult to achieve and how SCONE helps to complement systems security.\n\n\n\n\n\n\nSCONE CLI\n: introduces the SCONE command line interface and how to install the SCONE CLI.\n\n\n\n\n\n\nSCONE Host Setup\n: to run secure containers, we need to configure each host to run a Linux SGX driver and also a (for convenience, a patched) Docker engine.\n\n\n\n\n\n\nSCONE SGX Toolchain\n: SCONE supports cross-compilers (C, C++, more to come soon) to compile and build  applications for SGX enclaves.\n\n\n\n\n\n\nSCONE Curated Container Images\n: we will support a set of secure container images to simplify the use of SCONE.\n\n\n\n\n\n\nSCONE Tutorial\n: we show how to compile simple example applications with the help of the SCONE SGX Toolchain.\n\n\n\n\n\n\nSCONE Dockerfile\n: we support the use of Dockerfiles to generate Docker images that contain services running inside of SGX enclaves (this requires a \npatched Docker Engine\n).\n\n\n\n\n\n\nSCONE Swarm\n: show how to setup a Docker Swarm usable for SCONE.\n\n\n\n\n\n\nSCONE Swarm Example\n: shows an example of how to start SCONE services on top of a Docker Swarm.\n\n\n\n\n\n\nPublications\n:  some of the technical aspects of SCONE have been published in scientific papers. We provide a short summary of the papers and links to the pdfs.\n\n\n\n\n\n\nAuthor: Christof Fetzer, October 2017",
            "title": "Outline"
        },
        {
            "location": "/outline/#outline",
            "text": "Application-Oriented Security : we give a short introduction into application-oriented security provided by SCONE.    SCONE Background : we give a short introduction into why good systems security is difficult to achieve and how SCONE helps to complement systems security.    SCONE CLI : introduces the SCONE command line interface and how to install the SCONE CLI.    SCONE Host Setup : to run secure containers, we need to configure each host to run a Linux SGX driver and also a (for convenience, a patched) Docker engine.    SCONE SGX Toolchain : SCONE supports cross-compilers (C, C++, more to come soon) to compile and build  applications for SGX enclaves.    SCONE Curated Container Images : we will support a set of secure container images to simplify the use of SCONE.    SCONE Tutorial : we show how to compile simple example applications with the help of the SCONE SGX Toolchain.    SCONE Dockerfile : we support the use of Dockerfiles to generate Docker images that contain services running inside of SGX enclaves (this requires a  patched Docker Engine ).    SCONE Swarm : show how to setup a Docker Swarm usable for SCONE.    SCONE Swarm Example : shows an example of how to start SCONE services on top of a Docker Swarm.    Publications :  some of the technical aspects of SCONE have been published in scientific papers. We provide a short summary of the papers and links to the pdfs.    Author: Christof Fetzer, October 2017",
            "title": "Outline"
        },
        {
            "location": "/appsecurity/",
            "text": "Application-Oriented Security\n\n\nSCONE supports \nservice providers\n (i.e., companies operating applications accessible via the Internet)\nto protect the confidentiality and integrity of their applications - even when running in clouds that\ncannot be completely trusted. SCONE's focus is on supporting the development of \nmicroservice-based applications\n as well as \ncloud-native applications\n. However, SCONE can protect almost any program running on top of Linux.\n\n\nSCONE supports service providers to ensure end-to-end encryption in the sense that \ndata is always encrypted\n, i.e., while being transmitted,\nwhile being at rest and even while being processed. The latter has only recently become possible with the help of a novel CPU extension by Intel (SGX). To reduce the required computing resources, a service provider can decide what to protect and what not to protect.  For example, a service that operates only on encrypted data might not need to be protected with SGX.\n\n\nOur general recommendation is, however, that service providers should protect all parts of an application. The cost of computing resources have been dropping dramatically and hence, the reduction in cost might not be justified when compared with the potential costs - and also loss of reputation - by data breaches.\n\n\nEase of Use\n\n\nSCONE supports strong application-oriented security with a workflow like Docker, i.e., SCONE supports \nDockerfiles\n as well as extended Docker \ncompose\n files. This simplifies the construction and operation of applications consisting of a set of containers. This fits, in particular, modern cloud-native applications consisting of microservices and each microservice runs either in a standard or a secure container.\n\n\nThe Docker Engine itself is not protected. The Docker Engine, like the operating system, never sees any plain text data. This facilitates that the Docker Engine or the Docker Swarm can be managed by a cloud provider. SCONE helps a service providers to ensure the confidentiality and integrity of the application data while the cloud provider will ensure the availability of the service. For example, with the help of Docker Swarm, failed containers will automatically be restarted on an appropriate host.\n\n\n\n\nAuthor: Christof Fetzer, October 2017",
            "title": "Application-oriented security"
        },
        {
            "location": "/appsecurity/#application-oriented-security",
            "text": "SCONE supports  service providers  (i.e., companies operating applications accessible via the Internet)\nto protect the confidentiality and integrity of their applications - even when running in clouds that\ncannot be completely trusted. SCONE's focus is on supporting the development of  microservice-based applications  as well as  cloud-native applications . However, SCONE can protect almost any program running on top of Linux.  SCONE supports service providers to ensure end-to-end encryption in the sense that  data is always encrypted , i.e., while being transmitted,\nwhile being at rest and even while being processed. The latter has only recently become possible with the help of a novel CPU extension by Intel (SGX). To reduce the required computing resources, a service provider can decide what to protect and what not to protect.  For example, a service that operates only on encrypted data might not need to be protected with SGX.  Our general recommendation is, however, that service providers should protect all parts of an application. The cost of computing resources have been dropping dramatically and hence, the reduction in cost might not be justified when compared with the potential costs - and also loss of reputation - by data breaches.",
            "title": "Application-Oriented Security"
        },
        {
            "location": "/appsecurity/#ease-of-use",
            "text": "SCONE supports strong application-oriented security with a workflow like Docker, i.e., SCONE supports  Dockerfiles  as well as extended Docker  compose  files. This simplifies the construction and operation of applications consisting of a set of containers. This fits, in particular, modern cloud-native applications consisting of microservices and each microservice runs either in a standard or a secure container.  The Docker Engine itself is not protected. The Docker Engine, like the operating system, never sees any plain text data. This facilitates that the Docker Engine or the Docker Swarm can be managed by a cloud provider. SCONE helps a service providers to ensure the confidentiality and integrity of the application data while the cloud provider will ensure the availability of the service. For example, with the help of Docker Swarm, failed containers will automatically be restarted on an appropriate host.   Author: Christof Fetzer, October 2017",
            "title": "Ease of Use"
        },
        {
            "location": "/background/",
            "text": "SCONE Background\n\n\n\n\nCloud Security\n. The objective of SCONE is to help service providers to build secure applications for public, private or hybrid clouds. This means that the focus of SCONE is on application-oriented security and not on the security of the underlying cloud system. Of course, SCONE-based applications benefit from strong security properties of the underlying cloud because this minimizes, for example, the attack surface of SCONE-based applications and by providing higher availability. SCONE helps to ensure the security of an application, i.e., the application's integrity and confidentiality, even if the security of the underlying cloud or system software would be compromised. The security of applications is ensured with the help of Intel SGX enclaves. \n\n\n\n\n\n\n\n\nWorkflow\n. SCONE combines strong security with the ease of use of Docker. SCONE supports a workflow very similar to that of Docker. It supports the construction of applications consisting of multiple containers while ensuring end-to-end encryption between all application components in the sense that all network traffic, all files and even all computation is encrypted. A service provider can ensure the confidentiality and integrity of all application data. In particular, SCONE supports the construction of applications such that no higher privileged software like the operating system or the hypervisor, nor any system administrator with root access nor cold boot attacks can gain access to application data.\n\n\n\n\n\n\n\n\nSide Channel Attacks\n. Side Channel attacks on Intel SGX are the focus of a several recent research papers. First, mounting a successful side-channels is much more difficult than just dumping the memory of an existing application. In SCONE, we provide scheduling within enclaves which makes it more difficult for an attacker to determine which core is executing what function. Moreover, we are working on a compiler extension that will harden applications against side channel attacks. Until will release this extension, a pragmatic solution would be to run applications that might be suceptible to side channel attacks either on \nisolated hosts\n or on \nbaremetal clouds\n.\n\n\n\n\nProblem: Defender's Dilemma\n\n\nTraditionally, one ensures the security of an application by ensuring that the system software, i.e., the hypervisor, operating system and cloud software is trustworthy. This not only protects the integrity and confidentiality of the system data but also protects the security of the applications. A service provider running applications in the cloud must trust all system software and also all administrators who have root or physical access to these systems.\n\n\nA popular way to intrude into a system is to steal the credentials of a system administrator. With these root credentials, one gains access to all data being processed in this system as well as all keys that are kept in main memory or in some plain text files. If stealing credentials would be too difficult, an attacker will look for other ways to attack a system, like, exploiting known code vulnerabilities.\n\n\nFor an attacker, it might be sufficient to exploit a single vulnerability in either the application or the system software to violate the application security. The problem is that the defenders must protect against the exploitation of all code vulnerabilities that might exist in the source code. A service provider might not have access to all source code of the system software that the cloud provider uses to operate the cloud. Even if the source code were available, this will typically be too large to be inspected.\n\n\nTo show that this is a difficult problem, let's look at the number of lines of source code of common system software components. While lines of source code is not an ideal  indicator for the number of vulnerabilities, it gives some indication of the problem we are facing. Some security researchers state that given the current state of the art, only code with up to 10,000s of lines of code can be reasonably inspected. Just the system software itself contains millions of lines of code. This is orders of magnitudes more than we can reasonably expect to be able to inspect.\n\n\nSCONE runs on top of Linux - which contains millions of lines of code and is still growing in size with each release:\n\n\n\n\nLinux Lines of Code (StefanPohl, CC0, \noriginal\n}\n\n\nOpenStack is a popular open source software to manage clouds. OpenStack - despite being relatively young - has been growing dramatically over the years that it has already reached 5 million lines of code (including comments and blank lines):\n\n\n\n\nOpenStack Lines of Code (OpenHub \noriginal\n)\n\n\nTo manage containers, we need an engine like Docker. Docker is younger than OpenStack but has nevertheless reached already more than 180,000 lines of code:\n\n\n\n\nDocker Lines of Code (OpenHub \noriginal\n)\n\n\nCode complexity\n.There is no one-to-one correlation between lines of codes and bugs. Static analysis of open source code repositories indicates approximately 0.61 defects per 1,000 LOC. A recent analysis of Linux shows that, despite an increasing number of defects being fixed, there are always approximately 5,000 defects waiting to be fixed. Not all of these defects can, however, be exploited for security attacks. Another analysis found that approximately 500 security-relevant bugs were fixed in Linux over the past five years - bugs that had been in the kernel for five years before being discovered and fixed. Commercial code had a slightly higher defect density than open source projects. Hence, we need to expect vulnerabilities in commercial software too.\n\n\nSCONE Approach\n\n\nThe approach of SCONE is to partition the code and to place essential components of an application into separate enclaves. Practically, it is quite difficult to split an existing code base of a single process into one component that runs inside an enclave and a component that runs outside of an enclave. However, many modern applications - like cloud-native applications - are already partitioned in several components running in separate address spaces. These components are typically called microservices. This partitioning facilitates a more intelligent scaling of services as well as a scaling of the development team.\n\n\nA large application might consist of a variety of microservices. Not all microservices of an application need to run inside enclaves to protect the application\u2019s integrity and confidentiality. For example, some services might only process encrypted data, like encrypted log data, and do not need to run inside enclaves.  Also, the resource manager does not need to run in an enclave either. However, we recommend that each microservice that has the credential to send requests to at least one microservice running inside an enclave, should itself also run inside of an enclave to restrict the access to enclaved microservices.\n\n\nCurrent SGX-capable CPUs have a limited EPC (Extended Page Cache) size. If the working set of a microservice does not fit inside the EPC, overheads can become high. The usage of microservices supports horizontal scalability. This helps to cope with limited EPC (extended page cache) by spreading secure microservices across different hosts.\n\n\nAuthor: Christof Fetzer, October 2017",
            "title": "SCONE Background"
        },
        {
            "location": "/background/#scone-background",
            "text": "Cloud Security . The objective of SCONE is to help service providers to build secure applications for public, private or hybrid clouds. This means that the focus of SCONE is on application-oriented security and not on the security of the underlying cloud system. Of course, SCONE-based applications benefit from strong security properties of the underlying cloud because this minimizes, for example, the attack surface of SCONE-based applications and by providing higher availability. SCONE helps to ensure the security of an application, i.e., the application's integrity and confidentiality, even if the security of the underlying cloud or system software would be compromised. The security of applications is ensured with the help of Intel SGX enclaves.      Workflow . SCONE combines strong security with the ease of use of Docker. SCONE supports a workflow very similar to that of Docker. It supports the construction of applications consisting of multiple containers while ensuring end-to-end encryption between all application components in the sense that all network traffic, all files and even all computation is encrypted. A service provider can ensure the confidentiality and integrity of all application data. In particular, SCONE supports the construction of applications such that no higher privileged software like the operating system or the hypervisor, nor any system administrator with root access nor cold boot attacks can gain access to application data.     Side Channel Attacks . Side Channel attacks on Intel SGX are the focus of a several recent research papers. First, mounting a successful side-channels is much more difficult than just dumping the memory of an existing application. In SCONE, we provide scheduling within enclaves which makes it more difficult for an attacker to determine which core is executing what function. Moreover, we are working on a compiler extension that will harden applications against side channel attacks. Until will release this extension, a pragmatic solution would be to run applications that might be suceptible to side channel attacks either on  isolated hosts  or on  baremetal clouds .",
            "title": "SCONE Background"
        },
        {
            "location": "/background/#problem-defenders-dilemma",
            "text": "Traditionally, one ensures the security of an application by ensuring that the system software, i.e., the hypervisor, operating system and cloud software is trustworthy. This not only protects the integrity and confidentiality of the system data but also protects the security of the applications. A service provider running applications in the cloud must trust all system software and also all administrators who have root or physical access to these systems.  A popular way to intrude into a system is to steal the credentials of a system administrator. With these root credentials, one gains access to all data being processed in this system as well as all keys that are kept in main memory or in some plain text files. If stealing credentials would be too difficult, an attacker will look for other ways to attack a system, like, exploiting known code vulnerabilities.  For an attacker, it might be sufficient to exploit a single vulnerability in either the application or the system software to violate the application security. The problem is that the defenders must protect against the exploitation of all code vulnerabilities that might exist in the source code. A service provider might not have access to all source code of the system software that the cloud provider uses to operate the cloud. Even if the source code were available, this will typically be too large to be inspected.  To show that this is a difficult problem, let's look at the number of lines of source code of common system software components. While lines of source code is not an ideal  indicator for the number of vulnerabilities, it gives some indication of the problem we are facing. Some security researchers state that given the current state of the art, only code with up to 10,000s of lines of code can be reasonably inspected. Just the system software itself contains millions of lines of code. This is orders of magnitudes more than we can reasonably expect to be able to inspect.  SCONE runs on top of Linux - which contains millions of lines of code and is still growing in size with each release:   Linux Lines of Code (StefanPohl, CC0,  original }  OpenStack is a popular open source software to manage clouds. OpenStack - despite being relatively young - has been growing dramatically over the years that it has already reached 5 million lines of code (including comments and blank lines):   OpenStack Lines of Code (OpenHub  original )  To manage containers, we need an engine like Docker. Docker is younger than OpenStack but has nevertheless reached already more than 180,000 lines of code:   Docker Lines of Code (OpenHub  original )  Code complexity .There is no one-to-one correlation between lines of codes and bugs. Static analysis of open source code repositories indicates approximately 0.61 defects per 1,000 LOC. A recent analysis of Linux shows that, despite an increasing number of defects being fixed, there are always approximately 5,000 defects waiting to be fixed. Not all of these defects can, however, be exploited for security attacks. Another analysis found that approximately 500 security-relevant bugs were fixed in Linux over the past five years - bugs that had been in the kernel for five years before being discovered and fixed. Commercial code had a slightly higher defect density than open source projects. Hence, we need to expect vulnerabilities in commercial software too.",
            "title": "Problem: Defender's Dilemma"
        },
        {
            "location": "/background/#scone-approach",
            "text": "The approach of SCONE is to partition the code and to place essential components of an application into separate enclaves. Practically, it is quite difficult to split an existing code base of a single process into one component that runs inside an enclave and a component that runs outside of an enclave. However, many modern applications - like cloud-native applications - are already partitioned in several components running in separate address spaces. These components are typically called microservices. This partitioning facilitates a more intelligent scaling of services as well as a scaling of the development team.  A large application might consist of a variety of microservices. Not all microservices of an application need to run inside enclaves to protect the application\u2019s integrity and confidentiality. For example, some services might only process encrypted data, like encrypted log data, and do not need to run inside enclaves.  Also, the resource manager does not need to run in an enclave either. However, we recommend that each microservice that has the credential to send requests to at least one microservice running inside an enclave, should itself also run inside of an enclave to restrict the access to enclaved microservices.  Current SGX-capable CPUs have a limited EPC (Extended Page Cache) size. If the working set of a microservice does not fit inside the EPC, overheads can become high. The usage of microservices supports horizontal scalability. This helps to cope with limited EPC (extended page cache) by spreading secure microservices across different hosts.  Author: Christof Fetzer, October 2017",
            "title": "SCONE Approach"
        },
        {
            "location": "/SCONE_CLI/",
            "text": "SCONE CLI\n\n\nWe maintain a single unified command line interface (CLI) \nscone\n that helps to to start and stop secure containers as well as secure applications. \nscone\n also provides functionality to install and monitor SCONE hosts.\n\n\nThe \nscone\n command is structured similar as the \ndocker\n CLI or the \ninfinit\n CLI:\n\n\n\n\nOne needs to specify an \nobject\n (like \nhost\n) and a \ncommand\n (like \ninstall\n) and some options. For some commands, some of the options are actually not optional but mandatory.\n\n\nSee below how to install scone on Ubuntu. Instead of installing \nscone\n in a VM or a host, you could just start it in a container. Assuming\nthat you have docker installed, you try the following examples by running the following container:  \n\n\ndocker run -it  sconecuratedimages/sconecli\n\n\n\n\nNote\n\n\nThe \nscone\n utility requires \nssh\n connectivity to your SGX hosts. See \nSCONE host setup\n for some more\ninformation on how to set up ssh.\n\n\nHelp\n\n\nscone\n has a built in help. To get a list of all \nobjects\n, just type:\n\n\nscone --help\n\n\n\n\nTo get a list of all \ncommands\n for a given \nobject\n (like host), execute:\n\n\nscone host --help\n\n\n\n\nTo get a list of all options for a given \nobject\n and \ncommand\n (e.g., host install) and some examples, just execute:\n\n\nscone host install --help\n\n\n\n\nbash auto-completion\n\n\nIf you are using \nbash\n as your shell, \nscone\n supports auto-completion. This means that instead you can use the \nTAB\n key to see the options. For example,\n\n\nscone <TAB>\n\n\n\n\nwill show all available objects. If you have already specified an object, auto-completion helps you to list all commands:\n\n\nscone host <TAB>\n\n\n\n\nIf you also specified an command, it will provide you with a list of options (that you have not specified yet):\n\n\nscone host install <TAB>\n\n\n\n\nOf course, it also supports auto-completion:\n\n\nscone host install -n<TAB>\n\n\n\n\nwill result in \n\n\nscone host install -name\n\n\n\n\nInstallation of scone\n\n\nOn Ubuntu platform, you can just execute\n\n\ncurl -L https://sconecontainers.github.io/install.sh | bash\n\n\n\n\nYou could alternatively first download the above installation script and store it as file \ninstall.sh\n, inspect it and then run it \n./install.sh\"\n.\n\n\nThe \nscone\n command is located in directory \n/opt/scone/bin/\n. You might want this directory to add this to you \nPATH\n\n\nPATH=/opt/scone/bin/:$PATH\n\n\n\n\nFor convenience, you might want to add above statement to your \n.bashrc\n script (- in case you are using bash).\n\n\nManual installation of SCONE Deb Package\n\n\nYou can execute the following commands (these are the same as in the above installation script):\n\n\nKEYNAME=\"96B9BADB\"\nREPO=\"deb https://sconecontainers.github.io/SCONE ./\"\n\nsudo apt-get update\nsudo apt-get install -y linux-image-extra-$(uname -r) linux-image-extra-virtual\n\nsudo sudo apt-get install -y apt-transport-https ca-certificates\nsudo apt-key adv \\\n  --keyserver hkp://ha.pool.sks-keyservers.net:80 \\\n  --recv-keys $KEYNAME\n\necho $REPO | sudo tee /etc/apt/sources.list.d/scone.list\n\nsudo apt-get clean\nsudo apt-get update\n\napt-cache policy scone\n\nsudo apt-get install -y scone\n\n\n\n\nThe \nscone\n utility will be installed at \n/opt/scone/bin\n. Hence, it makes sense to add this path to your \nPATH\n:\n\n\nexport PATH=/opt/scone/bin:$PATH\n\n\n\n\nYou can then execute some scone commands to see if the installation was successful:\n\n\nscone --version\nscone --help\nscone volume --help\n\n\n\n\nAuthor: Christof Fetzer, October 2017",
            "title": "SCONE CLI"
        },
        {
            "location": "/SCONE_CLI/#scone-cli",
            "text": "We maintain a single unified command line interface (CLI)  scone  that helps to to start and stop secure containers as well as secure applications.  scone  also provides functionality to install and monitor SCONE hosts.  The  scone  command is structured similar as the  docker  CLI or the  infinit  CLI:   One needs to specify an  object  (like  host ) and a  command  (like  install ) and some options. For some commands, some of the options are actually not optional but mandatory.  See below how to install scone on Ubuntu. Instead of installing  scone  in a VM or a host, you could just start it in a container. Assuming\nthat you have docker installed, you try the following examples by running the following container:    docker run -it  sconecuratedimages/sconecli",
            "title": "SCONE CLI"
        },
        {
            "location": "/SCONE_CLI/#note",
            "text": "The  scone  utility requires  ssh  connectivity to your SGX hosts. See  SCONE host setup  for some more\ninformation on how to set up ssh.",
            "title": "Note"
        },
        {
            "location": "/SCONE_CLI/#help",
            "text": "scone  has a built in help. To get a list of all  objects , just type:  scone --help  To get a list of all  commands  for a given  object  (like host), execute:  scone host --help  To get a list of all options for a given  object  and  command  (e.g., host install) and some examples, just execute:  scone host install --help",
            "title": "Help"
        },
        {
            "location": "/SCONE_CLI/#bash-auto-completion",
            "text": "If you are using  bash  as your shell,  scone  supports auto-completion. This means that instead you can use the  TAB  key to see the options. For example,  scone <TAB>  will show all available objects. If you have already specified an object, auto-completion helps you to list all commands:  scone host <TAB>  If you also specified an command, it will provide you with a list of options (that you have not specified yet):  scone host install <TAB>  Of course, it also supports auto-completion:  scone host install -n<TAB>  will result in   scone host install -name",
            "title": "bash auto-completion"
        },
        {
            "location": "/SCONE_CLI/#installation-of-scone",
            "text": "On Ubuntu platform, you can just execute  curl -L https://sconecontainers.github.io/install.sh | bash  You could alternatively first download the above installation script and store it as file  install.sh , inspect it and then run it  ./install.sh\" .  The  scone  command is located in directory  /opt/scone/bin/ . You might want this directory to add this to you  PATH  PATH=/opt/scone/bin/:$PATH  For convenience, you might want to add above statement to your  .bashrc  script (- in case you are using bash).",
            "title": "Installation of scone"
        },
        {
            "location": "/SCONE_CLI/#manual-installation-of-scone-deb-package",
            "text": "You can execute the following commands (these are the same as in the above installation script):  KEYNAME=\"96B9BADB\"\nREPO=\"deb https://sconecontainers.github.io/SCONE ./\"\n\nsudo apt-get update\nsudo apt-get install -y linux-image-extra-$(uname -r) linux-image-extra-virtual\n\nsudo sudo apt-get install -y apt-transport-https ca-certificates\nsudo apt-key adv \\\n  --keyserver hkp://ha.pool.sks-keyservers.net:80 \\\n  --recv-keys $KEYNAME\n\necho $REPO | sudo tee /etc/apt/sources.list.d/scone.list\n\nsudo apt-get clean\nsudo apt-get update\n\napt-cache policy scone\n\nsudo apt-get install -y scone  The  scone  utility will be installed at  /opt/scone/bin . Hence, it makes sense to add this path to your  PATH :  export PATH=/opt/scone/bin:$PATH  You can then execute some scone commands to see if the installation was successful:  scone --version\nscone --help\nscone volume --help  Author: Christof Fetzer, October 2017",
            "title": "Manual installation of SCONE Deb Package"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/",
            "text": "SCONE: Host Installation Guide\n\n\nThis page describes how \n\n\n\n\n\n\nto set up a host such that it can run SCONE secure containers, i.e., containers in which processes run inside of SGX enclaves, and\n\n\n\n\n\n\nwe remind you of how to set up your \nssh\n configuration.\n\n\n\n\n\n\nDuring this setup, we\n\n\n\n\n\n\ninstall a \npatched\n Intel SGX driver - required for better monitoring support,\n\n\n\n\n\n\ninstall a \npatched\n docker engine - to ensure that all containers have access to SGX, and\n\n\n\n\n\n\nstart or join a docker swarm - if requested by command line options.\n\n\n\n\n\n\nPrerequisite\n:  We assume that you have set up the \nscone\n \ncommand line interface\n.\nThe \nscone\n CLI can run on your developer machine, a virtual machine or inside a container. \nThe easiest way to get started is to run \nscone\n in a Docker container.\n\n\nIndependent of where \nscone\n runs, it requires that \nssh\n is properly installed.\n\n\nSSH\n\n\nThe \nscone\n utility executes commands via \nssh\n on the SGX-capable machine that should be installed.\n\n\n\n\nSince we potentially execute many \nssh\n commands, you need to configure \nssh\n such that\n\n\n\n\n\n\nyou can log into the SGX machines with having to type a password, \n\n\n\n\n\n\nyou can use simple basename for your SGX machines, and\n\n\n\n\n\n\nyou want ssh to reuse connection to reduce the execution time of the \nscone\n commands.\n\n\n\n\n\n\nPasswordless ssh\n\n\nTo set up passwordless ssh authentication, you need to ensure that you have a pair of authentication keys.\nIf there exists no public key \n$HOME/.ssh/id_rsa.pub\n (often the case if you use a container), you can generate a new pair\nby executing:\n\n\nssh-keygen -b 4096 -t rsa\n\n\n\n\nAppend the generated public key \n$HOME/.ssh/id_rsa.pub\n to file \n$HOME/.ssh/authorized_keys\n on the SGX hosts for which you to be able to log in without a password.\n\n\nAdditionally, you need to start a ssh-agent:\n\n\nSA=`ssh-agent`\neval \"$SA\"\n\n\n\n\nand add your authentication keys by executing:\n\n\nssh-add\n\n\n\n\nHost alias\n\n\nTo reduce your typing overhead, you can use the basename of a host - if you configure ssh appropriately. For example, instead of typing \nnode2.my.very.long.domain.com\n, you could configure  \nssh\n such that \nnode2\n refers to \nnode2.my.very.long.domain.com\n.\n\n\nAs a caveat, this basename must be sufficient for other hosts in the \nsame swarm\n to reach \nnode2\n. In the above figure, \nmanager\n must be able to resolve \nnode2\n to \nnode2.my.very.long.domain.com\n.\n\n\nTo add an alias, you could add the following lines to your \nssh config\n (stored in \n$HOME/.ssh/config\n):\n\n\nHost node2\n     HostName node2.my.very.long.domain.com\n     Port 22\n     User scone\n     IdentityFile ~/.ssh/id_rsa\n\n\n\n\nssh connection reuse\n\n\nTo reuse the connection establishment, you can configure ssh to reuse connections. To do so, you need to set \nControlMaster\n to \nauto\n and you have to specify a control path via option \nControlPath\n. You can define a generic path like \n~/.ssh/ssh_mux_%h_%p_%r\n that can be the same for all hosts. For example, for some host \nalice\n you might add the following lines to \n$HOME/.ssh/config\n:\n\n\nHost alice\n        ControlMaster auto\n        ControlPath ~/.ssh/ssh_mux_%h_%p_%r\n        user ubuntu\n        port 10101\n        hostname sshproxy.cloudprovider.com\n\n\n\n\nInstallation of a single host\n\n\nAfter you set up the \nscone CLI\n and your passwordless ssh works, you can install the scone related software on a new host, say, \nalice\n as follows:\n\n\nscone host install --name alice\n\n\n\n\nTo verify that a host is properly installed for SCONE and contains the newest patched Docker engine and SGX driver, just execute:\n\n\nscone host check --name alice\n\n\n\n\nThis command will issue an error unless the newest versions of the patched Docker engine and the patched SGX driver is installed.\n\n\nInstallation of a swarm\n\n\nFor a set of hosts to form a (Docker) swarm, you need to decide which hosts should be managers and which should be just members of the swarm. Say, you decided that \nalice\n and \nbob\n should be managers but \ncaroline\n a non-manager, execute the following:\n\n\nscone host install --name alice --as-manager\nscone host install --name bob --as-manager --join alice\nscone host install --name caroline  --join alice\n\n\n\n\nNote that the hosts must be able to communicate with each other (i.e., not partitioned through firewalls). Docker recommends/expects  that they will be in the same local area network.\n\n\nChecking your Installation\n\n\nTo test the installation, one can run a simple hello-world container:\n\n\nsudo docker run hello-world\n\n\n\n\nBackground Information\n\n\nPatched Docker Engine (Moby)\n\n\nFor an container to be able to use SGX, it has to have access to a device (/dev/isgx). This device permits the container to talk to the SGX driver. This driver is needed, for example, to create SGX enclaves. \n\n\nSome docker commands (like \ndocker run\n) support an option --device (i.e., \n--device /dev/isgx\n) which allows us to give a container access to the SGX device. We need to point out that some docker commands (like \ndocker build\n) do, however, not yet support the device option. Therefore, we maintain and install a slightly patched docker engine (i.e., a variant of moby): this engine ensures that each container has access to the SGX device (/dev/isgx).  With the help of this patched engine, we can use Dockerfiles to generate container images (see this \nTutorial\n).\n\n\nRight now we provide a patched version of the currently active branch of Moby (a.k.a., the Docker engine): 17.06.0-dev, build f9a45b7\n\n\nPatched SGX Driver\n\n\nWe also maintain a patched version of the SGX driver. This version adds some additional monitoring like the number of \navailable\n and \nfree\n EPC (Extended Page Cache) pages.\n\n\nRight now, we provide a patched version of the latest Intel SGX driver from August 3, 2017 (commit cd516380e5ffa008505dc0e86ddbf45276021219).\n\n\nAuthor: Christof Fetzer, October 2017",
            "title": "SCONE Host Setup"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#scone-host-installation-guide",
            "text": "This page describes how     to set up a host such that it can run SCONE secure containers, i.e., containers in which processes run inside of SGX enclaves, and    we remind you of how to set up your  ssh  configuration.    During this setup, we    install a  patched  Intel SGX driver - required for better monitoring support,    install a  patched  docker engine - to ensure that all containers have access to SGX, and    start or join a docker swarm - if requested by command line options.    Prerequisite :  We assume that you have set up the  scone   command line interface .\nThe  scone  CLI can run on your developer machine, a virtual machine or inside a container. \nThe easiest way to get started is to run  scone  in a Docker container.  Independent of where  scone  runs, it requires that  ssh  is properly installed.",
            "title": "SCONE: Host Installation Guide"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#ssh",
            "text": "The  scone  utility executes commands via  ssh  on the SGX-capable machine that should be installed.   Since we potentially execute many  ssh  commands, you need to configure  ssh  such that    you can log into the SGX machines with having to type a password,     you can use simple basename for your SGX machines, and    you want ssh to reuse connection to reduce the execution time of the  scone  commands.    Passwordless ssh  To set up passwordless ssh authentication, you need to ensure that you have a pair of authentication keys.\nIf there exists no public key  $HOME/.ssh/id_rsa.pub  (often the case if you use a container), you can generate a new pair\nby executing:  ssh-keygen -b 4096 -t rsa  Append the generated public key  $HOME/.ssh/id_rsa.pub  to file  $HOME/.ssh/authorized_keys  on the SGX hosts for which you to be able to log in without a password.  Additionally, you need to start a ssh-agent:  SA=`ssh-agent`\neval \"$SA\"  and add your authentication keys by executing:  ssh-add  Host alias  To reduce your typing overhead, you can use the basename of a host - if you configure ssh appropriately. For example, instead of typing  node2.my.very.long.domain.com , you could configure   ssh  such that  node2  refers to  node2.my.very.long.domain.com .  As a caveat, this basename must be sufficient for other hosts in the  same swarm  to reach  node2 . In the above figure,  manager  must be able to resolve  node2  to  node2.my.very.long.domain.com .  To add an alias, you could add the following lines to your  ssh config  (stored in  $HOME/.ssh/config ):  Host node2\n     HostName node2.my.very.long.domain.com\n     Port 22\n     User scone\n     IdentityFile ~/.ssh/id_rsa  ssh connection reuse  To reuse the connection establishment, you can configure ssh to reuse connections. To do so, you need to set  ControlMaster  to  auto  and you have to specify a control path via option  ControlPath . You can define a generic path like  ~/.ssh/ssh_mux_%h_%p_%r  that can be the same for all hosts. For example, for some host  alice  you might add the following lines to  $HOME/.ssh/config :  Host alice\n        ControlMaster auto\n        ControlPath ~/.ssh/ssh_mux_%h_%p_%r\n        user ubuntu\n        port 10101\n        hostname sshproxy.cloudprovider.com",
            "title": "SSH"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#installation-of-a-single-host",
            "text": "After you set up the  scone CLI  and your passwordless ssh works, you can install the scone related software on a new host, say,  alice  as follows:  scone host install --name alice  To verify that a host is properly installed for SCONE and contains the newest patched Docker engine and SGX driver, just execute:  scone host check --name alice  This command will issue an error unless the newest versions of the patched Docker engine and the patched SGX driver is installed.",
            "title": "Installation of a single host"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#installation-of-a-swarm",
            "text": "For a set of hosts to form a (Docker) swarm, you need to decide which hosts should be managers and which should be just members of the swarm. Say, you decided that  alice  and  bob  should be managers but  caroline  a non-manager, execute the following:  scone host install --name alice --as-manager\nscone host install --name bob --as-manager --join alice\nscone host install --name caroline  --join alice  Note that the hosts must be able to communicate with each other (i.e., not partitioned through firewalls). Docker recommends/expects  that they will be in the same local area network.  Checking your Installation  To test the installation, one can run a simple hello-world container:  sudo docker run hello-world",
            "title": "Installation of a swarm"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#background-information",
            "text": "Patched Docker Engine (Moby)  For an container to be able to use SGX, it has to have access to a device (/dev/isgx). This device permits the container to talk to the SGX driver. This driver is needed, for example, to create SGX enclaves.   Some docker commands (like  docker run ) support an option --device (i.e.,  --device /dev/isgx ) which allows us to give a container access to the SGX device. We need to point out that some docker commands (like  docker build ) do, however, not yet support the device option. Therefore, we maintain and install a slightly patched docker engine (i.e., a variant of moby): this engine ensures that each container has access to the SGX device (/dev/isgx).  With the help of this patched engine, we can use Dockerfiles to generate container images (see this  Tutorial ).  Right now we provide a patched version of the currently active branch of Moby (a.k.a., the Docker engine): 17.06.0-dev, build f9a45b7  Patched SGX Driver  We also maintain a patched version of the SGX driver. This version adds some additional monitoring like the number of  available  and  free  EPC (Extended Page Cache) pages.  Right now, we provide a patched version of the latest Intel SGX driver from August 3, 2017 (commit cd516380e5ffa008505dc0e86ddbf45276021219).  Author: Christof Fetzer, October 2017",
            "title": "Background Information"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/",
            "text": "SCONE SGX Toolchain\n\n\nSCONE comes with compiler support for popular languages: C, C++, GO, Rust as well as Fortran.\nThe objective of these (cross-) compilers are to compile applications - generally without source code changes - such that they can run inside of SGX enclaves.\n\n\nTo simplify the use of these (cross-) compilers, SCONE maintains curated container image that includes these cross-compilers.\n\n\nUsing the C/C++ compiler container\n\n\nHow to use the compiler:\n\n\n\n\n\n\nuse this as a base image and build your programs inside of a container (see \nDockerfiles\n), or \n\n\n\n\n\n\nmap volumes such that the compiler can compile files living outside the container (see \nSCONE Tutorial\n). This is probably only practical for small projects.\n\n\n\n\n\n\nCompiler variants\n\n\nDepending on if you want to generate a dynamically linked or a statically linked binary, you\ncan use a standard compiler (dynamic) or you need to use a cross compiler (static). The compiler can run on any system, i.e., does not require SGX to run.\n\n\nIndependently, if you use a dynamic or static linking, the hash of an enclave (MRENCLAVE) will encompass the whole code, i.e., includes all libraries. \n\n\nThe easiest to get started is to compile your program with gcc such that\n\n\n\n\n\n\nthe generated code is position independent (\n-fPIC\n),\n\n\n\n\n\n\nthe thread local storage model is global-dynamic (\n-ftls-model=global-dynamic\n),\n\n\n\n\n\n\nyour binary is dynamically linked (i.e., do not use \n-static\n), and\n\n\n\n\n\n\nlink against musl as your libc (i.e., not glibc or any other libc).\n\n\n\n\n\n\nTo simplify the compiling of your programs for scone, we provide a docker image \nsconecuratedimages/muslgcc\n with \ngcc\n and \ng++\n support. The options will by default be set as shown above. You need, however,\nto make sure that you do not overwrite this options.\n\n\nExample\n\n\nOne can use the above compiler by giving it access to external files as follows. Say, your code is\nin file \nmyapp.c\n in your current directory (\n$PWD\n). You can compile this code as follows:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc myapp.c\n\n\n\n\nThis call will generate a binary \na.out\n in your working directory. This binary will be linked against musl:\n\n\n# ldd a.out \n    /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)\n    libc.musl-x86_64.so.1 => /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)\n\n\n\n\nThis binary can run natively only if you have musl installed at the correct position in your development machine (and your development machine runs Linux). Alternatively, you can run the binary in a container:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc ./a.out\n\n\n\n\nTo run this inside of SGX enclaves with SCONE, you need access to the SCONE runtime systems - which is not publicly available. Send me an email if you want to evaluate SCONE. \n\n\nFor more details, see our \nhello world\n in Section \nSCONE Tutorial\n. This is kind of awkward and hence, we provide a simpler version with the help of \nDockerfiles\n. \n\n\nDebugger support\n\n\nWe also support \ngdb\n to debug applications running inside of enclaves. For the start, we would recommend that you first ensure that your program runs natively linked against musl. Most programs will do - after all, the whole Alpine Linux distribution is based on musl.\n\n\nAuthor: Christof Fetzer, October 2017",
            "title": "SCONE SGX toolchain"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#scone-sgx-toolchain",
            "text": "SCONE comes with compiler support for popular languages: C, C++, GO, Rust as well as Fortran.\nThe objective of these (cross-) compilers are to compile applications - generally without source code changes - such that they can run inside of SGX enclaves.  To simplify the use of these (cross-) compilers, SCONE maintains curated container image that includes these cross-compilers.",
            "title": "SCONE SGX Toolchain"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#using-the-cc-compiler-container",
            "text": "How to use the compiler:    use this as a base image and build your programs inside of a container (see  Dockerfiles ), or     map volumes such that the compiler can compile files living outside the container (see  SCONE Tutorial ). This is probably only practical for small projects.",
            "title": "Using the C/C++ compiler container"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#compiler-variants",
            "text": "Depending on if you want to generate a dynamically linked or a statically linked binary, you\ncan use a standard compiler (dynamic) or you need to use a cross compiler (static). The compiler can run on any system, i.e., does not require SGX to run.  Independently, if you use a dynamic or static linking, the hash of an enclave (MRENCLAVE) will encompass the whole code, i.e., includes all libraries.   The easiest to get started is to compile your program with gcc such that    the generated code is position independent ( -fPIC ),    the thread local storage model is global-dynamic ( -ftls-model=global-dynamic ),    your binary is dynamically linked (i.e., do not use  -static ), and    link against musl as your libc (i.e., not glibc or any other libc).    To simplify the compiling of your programs for scone, we provide a docker image  sconecuratedimages/muslgcc  with  gcc  and  g++  support. The options will by default be set as shown above. You need, however,\nto make sure that you do not overwrite this options.",
            "title": "Compiler variants"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#example",
            "text": "One can use the above compiler by giving it access to external files as follows. Say, your code is\nin file  myapp.c  in your current directory ( $PWD ). You can compile this code as follows:  docker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc myapp.c  This call will generate a binary  a.out  in your working directory. This binary will be linked against musl:  # ldd a.out \n    /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)\n    libc.musl-x86_64.so.1 => /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)  This binary can run natively only if you have musl installed at the correct position in your development machine (and your development machine runs Linux). Alternatively, you can run the binary in a container:  docker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc ./a.out  To run this inside of SGX enclaves with SCONE, you need access to the SCONE runtime systems - which is not publicly available. Send me an email if you want to evaluate SCONE.   For more details, see our  hello world  in Section  SCONE Tutorial . This is kind of awkward and hence, we provide a simpler version with the help of  Dockerfiles .",
            "title": "Example"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#debugger-support",
            "text": "We also support  gdb  to debug applications running inside of enclaves. For the start, we would recommend that you first ensure that your program runs natively linked against musl. Most programs will do - after all, the whole Alpine Linux distribution is based on musl.  Author: Christof Fetzer, October 2017",
            "title": "Debugger support"
        },
        {
            "location": "/SCONE_Curated_Images/",
            "text": "SCONE Curated Images\n\n\nWe provide a set of curated SCONE container images on a (private) repositories on Docker hub:\n\n\n\n\nsconecuratedimages/sconedocu\n: contains containers related to our SCONE documentation \n\n\nsconecuratedimages/crosscompilers\n: contains container images of the SCONE cross compilers \n\n\nsconecuratedimages/tutorial\n: contains containers related to our SCONE tutorial \n\n\n\n\nScone Documentation\n\n\nTo run a local copy of the SCONE documentation, just perform the following steps:\n\n\ndocker pull sconecuratedimages/sconedocu\ndocker run -d -p 8080:80  sconecuratedimages/sconedocu\n\n\n\n\nView the documentation in your browser at http://127.0.0.1:8080 .\nOn a MAC, just type:\n\n\nopen http://127.0.0.1:8080\n\n\n\n\nto view this docu.\n\n\nLogin in\n\n\nAccess to some SCONE images is still restricted. First, get access\nto the images by sending email to scone.containers@gmail.com. \nSecond, log into to docker hub via:\n\n\ndocker login\n\n\n\n\nbefore you pull any of the curated images.\n\n\nScone Cross-Compilers\n\n\nTo run a local copy of the SCONE cross compilers, just pull the appropriate image on your computer.\n\n\nIn case you do not have SGX CPU extension / no SGX driver installed on your computer,\nyou can use our simulation environment. This runs the SCONE software but provides \nno protection\nof the confidentiality nor integrity\n of your application:\n\n\nsudo docker pull sconecuratedimages/crosscompilers:gcc-sim\n\n\n\n\nTo install our standard scone C / C++ cross compiler, just perform the following\nsteps.\n\n\nsudo docker pull sconecuratedimages/crosscompilers\n\n\n\n\nScone Hello World\n\n\nYou can pull the following image:\n\n\nsudo docker pull sconecuratedimages/helloworld\n\n\n\n\nand run the helloworld program inside of an enclave via\n\n\n> sudo docker run --device=/dev/isgx sconecuratedimages/helloworld\nHello World\n\n\n\n\nthis will fail, in case you do not provide the container with the sgx device:\n\n\n> sudo docker run sconecuratedimages/helloworld\nerror opening sgx device: No such file or directory\n\n\n\n\nNote, if you installed the modified Docker Engine that we provide, a container gets\nby default access to device \n/dev/isgx\n, i.e., in this case no error would occur.\n\n\nAuthor: Christof Fetzer, 2017",
            "title": "SCONE Curated Images"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-curated-images",
            "text": "We provide a set of curated SCONE container images on a (private) repositories on Docker hub:   sconecuratedimages/sconedocu : contains containers related to our SCONE documentation   sconecuratedimages/crosscompilers : contains container images of the SCONE cross compilers   sconecuratedimages/tutorial : contains containers related to our SCONE tutorial",
            "title": "SCONE Curated Images"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-documentation",
            "text": "To run a local copy of the SCONE documentation, just perform the following steps:  docker pull sconecuratedimages/sconedocu\ndocker run -d -p 8080:80  sconecuratedimages/sconedocu  View the documentation in your browser at http://127.0.0.1:8080 .\nOn a MAC, just type:  open http://127.0.0.1:8080  to view this docu.",
            "title": "Scone Documentation"
        },
        {
            "location": "/SCONE_Curated_Images/#login-in",
            "text": "Access to some SCONE images is still restricted. First, get access\nto the images by sending email to scone.containers@gmail.com. \nSecond, log into to docker hub via:  docker login  before you pull any of the curated images.",
            "title": "Login in"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-cross-compilers",
            "text": "To run a local copy of the SCONE cross compilers, just pull the appropriate image on your computer.  In case you do not have SGX CPU extension / no SGX driver installed on your computer,\nyou can use our simulation environment. This runs the SCONE software but provides  no protection\nof the confidentiality nor integrity  of your application:  sudo docker pull sconecuratedimages/crosscompilers:gcc-sim  To install our standard scone C / C++ cross compiler, just perform the following\nsteps.  sudo docker pull sconecuratedimages/crosscompilers",
            "title": "Scone Cross-Compilers"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-hello-world",
            "text": "You can pull the following image:  sudo docker pull sconecuratedimages/helloworld  and run the helloworld program inside of an enclave via  > sudo docker run --device=/dev/isgx sconecuratedimages/helloworld\nHello World  this will fail, in case you do not provide the container with the sgx device:  > sudo docker run sconecuratedimages/helloworld\nerror opening sgx device: No such file or directory  Note, if you installed the modified Docker Engine that we provide, a container gets\nby default access to device  /dev/isgx , i.e., in this case no error would occur.  Author: Christof Fetzer, 2017",
            "title": "Scone Hello World"
        },
        {
            "location": "/SCONE_TUTORIAL/",
            "text": "SCONE Tutorial\n\n\nPrerequisites\n\n\nEnsure that the sgx driver is installed\n\n\n> ls /dev/isgx \n/dev/isgx\n\n\n\n\nIf the driver is not installed, read Section \nSCONE Host Setup\n to learn how to install the SGX driver.\n\n\nInstall sgxmusl cross compiler image\n\n\nEnsure that you installed the sgxmusl:draft container image:\n\n\n> docker image ls sconecuratedimages/crosscompilers\nREPOSITORY                          TAG                 IMAGE ID            CREATED             SIZE\nsconecuratedimages/crosscompilers   gcc-sim             e5cabb3682d6        17 hours ago        1.18 GB\nsconecuratedimages/crosscompilers   gcc-sync            a4768b000fcc        18 hours ago        1.18 GB\n\n\n\n\nIf the cross compiler image is not yet installed, read Section \nSCONE Curated Container Images\n to learn how to install the SCONE cross compiler image.\n\n\nInstall the tutorial\n\n\nClone the tutorial: \n\n\ngit clone https://github.com/christoffetzer/SCONE_TUTORIAL.git\n\n\n\n\nNative Hello World\n\n\nEnsure that \nhello world\n runs natively on your machine:\n\n\ncd SCONE_TUTORIAL/HelloWorld/\ngcc hello_world.c  -o native_hello_world\n./native_hello_world\nHello World\n\n\n\n\nSIM Hello World\n\n\nNow, let us compile \nhello world\n with the help of a cross compiler image that creates binaries that include all SCONE software \nbut the services run actually outside of enclave. We call this variant \nsim\n and made available in image \nsconecuratedimages/crosscompilers:gcc-sim\n\nthat you can pull from docker hub.\n\n\nThe sim variant simplifies debugging. \nsim\n is, however, not 100% identical with the \nasync\n branch (i.e., the recommended branch to run applications inside of enclaves).\nHence, debugging using \nsim\n might not be possible for all bugs. \n\n\nsudo docker run --rm -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers:gcc-sim sgxmusl-sim-gcc /usr/src/myapp/hello_world.c  -o sim_hello_world\n./sim_hello_world\nHello World\n\n\n\n\nNote that the generated executable, i.e., \nsim_hello_world\n, will only run on Linux. \n\n\nSGX ASYNC Hello World\n\n\nThe default cross compiler variant that runs \nhello world\n inside of an enclave is \nsgxmusl-hw-async-gcc\n and you can find this in container \nsconecuratedimages/crosscompilers\n. \nThis variant requires access to the SGX device. \nIn Linux, the SGX device is made available as \n/dev/isgx\n and we can give the cross compiler inside of an container access via option \n--device=/dev/isgx\n:\n\n\nsudo docker run --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers sgxmusl-hw-async-gcc /usr/src/myapp/hello_world.c  -o sgx_hello_world\n./sgx_hello_world\nHello World\n\n\n\n\nThe compilation as well as the hello world program will fail in case you do not have the appropriate driver installed.\n\n\nRun STRACE\n\n\nLets see how we can trace the program. Say, you have compile the program as shown above. After that you enter a cross compiler container and strace hello world as follows:\n\n\nsudo docker run --cap-add SYS_PTRACE -it --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers bash\nstrace  -f /usr/src/myapp/sgx_sync_hello_world\n\n\n\n\nRun ShellScript\n\n\nAuthor: Christof Fetzer, April 2017",
            "title": "SCONE Tutorial"
        },
        {
            "location": "/SCONE_TUTORIAL/#scone-tutorial",
            "text": "",
            "title": "SCONE Tutorial"
        },
        {
            "location": "/SCONE_TUTORIAL/#prerequisites",
            "text": "Ensure that the sgx driver is installed  > ls /dev/isgx \n/dev/isgx  If the driver is not installed, read Section  SCONE Host Setup  to learn how to install the SGX driver.  Install sgxmusl cross compiler image  Ensure that you installed the sgxmusl:draft container image:  > docker image ls sconecuratedimages/crosscompilers\nREPOSITORY                          TAG                 IMAGE ID            CREATED             SIZE\nsconecuratedimages/crosscompilers   gcc-sim             e5cabb3682d6        17 hours ago        1.18 GB\nsconecuratedimages/crosscompilers   gcc-sync            a4768b000fcc        18 hours ago        1.18 GB  If the cross compiler image is not yet installed, read Section  SCONE Curated Container Images  to learn how to install the SCONE cross compiler image.",
            "title": "Prerequisites"
        },
        {
            "location": "/SCONE_TUTORIAL/#install-the-tutorial",
            "text": "Clone the tutorial:   git clone https://github.com/christoffetzer/SCONE_TUTORIAL.git",
            "title": "Install the tutorial"
        },
        {
            "location": "/SCONE_TUTORIAL/#native-hello-world",
            "text": "Ensure that  hello world  runs natively on your machine:  cd SCONE_TUTORIAL/HelloWorld/\ngcc hello_world.c  -o native_hello_world\n./native_hello_world\nHello World",
            "title": "Native Hello World"
        },
        {
            "location": "/SCONE_TUTORIAL/#sim-hello-world",
            "text": "Now, let us compile  hello world  with the help of a cross compiler image that creates binaries that include all SCONE software \nbut the services run actually outside of enclave. We call this variant  sim  and made available in image  sconecuratedimages/crosscompilers:gcc-sim \nthat you can pull from docker hub.  The sim variant simplifies debugging.  sim  is, however, not 100% identical with the  async  branch (i.e., the recommended branch to run applications inside of enclaves).\nHence, debugging using  sim  might not be possible for all bugs.   sudo docker run --rm -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers:gcc-sim sgxmusl-sim-gcc /usr/src/myapp/hello_world.c  -o sim_hello_world\n./sim_hello_world\nHello World  Note that the generated executable, i.e.,  sim_hello_world , will only run on Linux.",
            "title": "SIM Hello World"
        },
        {
            "location": "/SCONE_TUTORIAL/#sgx-async-hello-world",
            "text": "The default cross compiler variant that runs  hello world  inside of an enclave is  sgxmusl-hw-async-gcc  and you can find this in container  sconecuratedimages/crosscompilers . \nThis variant requires access to the SGX device. \nIn Linux, the SGX device is made available as  /dev/isgx  and we can give the cross compiler inside of an container access via option  --device=/dev/isgx :  sudo docker run --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers sgxmusl-hw-async-gcc /usr/src/myapp/hello_world.c  -o sgx_hello_world\n./sgx_hello_world\nHello World  The compilation as well as the hello world program will fail in case you do not have the appropriate driver installed.",
            "title": "SGX ASYNC Hello World"
        },
        {
            "location": "/SCONE_TUTORIAL/#run-strace",
            "text": "Lets see how we can trace the program. Say, you have compile the program as shown above. After that you enter a cross compiler container and strace hello world as follows:  sudo docker run --cap-add SYS_PTRACE -it --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers bash\nstrace  -f /usr/src/myapp/sgx_sync_hello_world",
            "title": "Run STRACE"
        },
        {
            "location": "/SCONE_TUTORIAL/#run-shellscript",
            "text": "Author: Christof Fetzer, April 2017",
            "title": "Run ShellScript"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/",
            "text": "Generating Container Image with SCONE\n\n\nWe show how to generate a Docker image that contains our \nhello world\n running inside of an enclave and pushing this to docker hub. We show this \n\n\nPrerequisites\n\n\nCheck that all prerequisites from \nSCONE Tutorial\n are satisfied. \nClone the SCONE_TUTORIAL before you start creating a \nhello world\n image.\n\n\nGenerate HelloWorld image\n\n\nWe generate a \nhello world\n container image. \n\n\ncd SCONE_TUTORIAL/CreateImage\n\n\n\n\nYou can either execute all step manually by copy&pasting all instructions or you can just execute\n\n\ndocker login\nsudo ./Dockerfile.sh\n\n\n\n\nand watch the outputs.\n\n\nPlease change the image name to a repository on docker hub to which you can write:\n\n\nexport TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloworld\"\n\n\n\n\nWe generate container and compile hello world inside of this container with the help of our standard SCONE cross compiler:\n\n\n\nCONTAINER_ID=`docker run -d -it --device=/dev/isgx  -v $(pwd):/mnt sconecuratedimages/crosscompilers bash -c \"\nset -e\nsgxmusl-hw-async-gcc /mnt/hello_world.c  -o /usr/local/bin/sgx_hello_world\n\"`\n\n\n\n\nNote that above will fail if you do not have access to the SGX device \n/dev/isgx\n.\n\n\nTurn the container into an image:\n\n\nIMAGE_ID=$(docker commit -p -c 'CMD sgx_hello_world' $CONTAINER_ID $IMAGE_NAME:$TAG)\n\n\n\n\nYou can run this image by executing:\n\n\nsudo docker run --device=/dev/isgx $IMAGE_NAME:$TAG\n\n\n\n\nYou can push this image to Docker. However, ensure that you first login to docker:\n\n\nsudo docker login\n\n\n\n\nbefore you push the image to docker hub:\n\n\nsudo docker push $IMAGE_NAME:$TAG\n\n\n\n\nNote: this will fail in case you do not have the permission to push to this repository. \n\n\nAuthor: Christof Fetzer, April 2017",
            "title": "SCONE Create Image"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/#generating-container-image-with-scone",
            "text": "We show how to generate a Docker image that contains our  hello world  running inside of an enclave and pushing this to docker hub. We show this",
            "title": "Generating Container Image with SCONE"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/#prerequisites",
            "text": "Check that all prerequisites from  SCONE Tutorial  are satisfied. \nClone the SCONE_TUTORIAL before you start creating a  hello world  image.",
            "title": "Prerequisites"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/#generate-helloworld-image",
            "text": "We generate a  hello world  container image.   cd SCONE_TUTORIAL/CreateImage  You can either execute all step manually by copy&pasting all instructions or you can just execute  docker login\nsudo ./Dockerfile.sh  and watch the outputs.  Please change the image name to a repository on docker hub to which you can write:  export TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloworld\"  We generate container and compile hello world inside of this container with the help of our standard SCONE cross compiler:  \nCONTAINER_ID=`docker run -d -it --device=/dev/isgx  -v $(pwd):/mnt sconecuratedimages/crosscompilers bash -c \"\nset -e\nsgxmusl-hw-async-gcc /mnt/hello_world.c  -o /usr/local/bin/sgx_hello_world\n\"`  Note that above will fail if you do not have access to the SGX device  /dev/isgx .  Turn the container into an image:  IMAGE_ID=$(docker commit -p -c 'CMD sgx_hello_world' $CONTAINER_ID $IMAGE_NAME:$TAG)  You can run this image by executing:  sudo docker run --device=/dev/isgx $IMAGE_NAME:$TAG  You can push this image to Docker. However, ensure that you first login to docker:  sudo docker login  before you push the image to docker hub:  sudo docker push $IMAGE_NAME:$TAG  Note: this will fail in case you do not have the permission to push to this repository.   Author: Christof Fetzer, April 2017",
            "title": "Generate HelloWorld image"
        },
        {
            "location": "/SCONE_Dockerfile/",
            "text": "Dockerfile\n\n\nWe show how to generate a Docker image with the help of a Dockerfile.\n\n\nPrerequisites\n\n\nEnsure that the sgx driver is installed\n\n\n> ls /dev/isgx \n/dev/isgx\n\n\n\n\nIf the driver is not installed, read Section \nSCONE Host Setup\n to learn how to install the SGX driver.\n\n\nEnsure that the patched docker engine is installed\n\n\nWe need \ndocker build\n in this example. This command does not permit to map devices in the newly created containers. Hence, we provide a patched Docker engine \nSCONE Host Setup\n.\n\n\nInstall the tutorial\n\n\nClone the tutorial: \n\n\ngit clone https://github.com/christoffetzer/SCONE_TUTORIAL.git\n\n\n\n\nAccess to SCONE Curated Images\n\n\nRight now, access to the curated images is still restricted. Please, send email to scone.containers@gmail.com to request access.\n\n\nGenerate HelloAgain image\n\n\nWe generate a \nhello again\n container image. \n\n\ncd SCONE_TUTORIAL/Dockerfile\n\n\n\n\nThe Dockerfile looks, feels like a standard docker image:\n\n\nFROM sconecuratedimages/crosscompilers:sgxmusl-hw-async-gcc\n\nMAINTAINER Christof Fetzer \"christof.fetzer@gmail.com\"\n\nRUN mkdir /hello\n\nCOPY hello_again.c /hello/\n\nRUN cd /hello && gcc hello_again.c -o again\n\nCMD [\"/hello/again\"]\n\n\n\n\nYou can either execute all step manually (see below) or you can just execute\n\n\ndocker login\n./generate.sh\n\n\n\n\nand watch the outputs. The push of the image should fail since you should not have the access rights to push the image to Docker hub.\n\n\nWe define the image name and tag that we want to generate:\n\n\nexport TAG=\"again\"\nexport FULLTAG=\"sconecuratedimages/helloworld:$TAG\"\n\n\n\n\nWe build the image:\n\n\ndocker build --pull -t $FULLTAG .\n\n\n\n\nWe push it to docker hub (will fail unless you have the right to push \n$FULLTAG\n):\n\n\ndocker push $FULLTAG\n\n\n\n\nPlease change the image name to a repository on docker hub to which you can write:\n\n\nexport TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloAgain\"\n\n\n\n\nAuthor: Christof Fetzer, 2017",
            "title": "SCONE Dockerfile"
        },
        {
            "location": "/SCONE_Dockerfile/#dockerfile",
            "text": "We show how to generate a Docker image with the help of a Dockerfile.",
            "title": "Dockerfile"
        },
        {
            "location": "/SCONE_Dockerfile/#prerequisites",
            "text": "Ensure that the sgx driver is installed  > ls /dev/isgx \n/dev/isgx  If the driver is not installed, read Section  SCONE Host Setup  to learn how to install the SGX driver.  Ensure that the patched docker engine is installed  We need  docker build  in this example. This command does not permit to map devices in the newly created containers. Hence, we provide a patched Docker engine  SCONE Host Setup .  Install the tutorial  Clone the tutorial:   git clone https://github.com/christoffetzer/SCONE_TUTORIAL.git  Access to SCONE Curated Images  Right now, access to the curated images is still restricted. Please, send email to scone.containers@gmail.com to request access.",
            "title": "Prerequisites"
        },
        {
            "location": "/SCONE_Dockerfile/#generate-helloagain-image",
            "text": "We generate a  hello again  container image.   cd SCONE_TUTORIAL/Dockerfile  The Dockerfile looks, feels like a standard docker image:  FROM sconecuratedimages/crosscompilers:sgxmusl-hw-async-gcc\n\nMAINTAINER Christof Fetzer \"christof.fetzer@gmail.com\"\n\nRUN mkdir /hello\n\nCOPY hello_again.c /hello/\n\nRUN cd /hello && gcc hello_again.c -o again\n\nCMD [\"/hello/again\"]  You can either execute all step manually (see below) or you can just execute  docker login\n./generate.sh  and watch the outputs. The push of the image should fail since you should not have the access rights to push the image to Docker hub.  We define the image name and tag that we want to generate:  export TAG=\"again\"\nexport FULLTAG=\"sconecuratedimages/helloworld:$TAG\"  We build the image:  docker build --pull -t $FULLTAG .  We push it to docker hub (will fail unless you have the right to push  $FULLTAG ):  docker push $FULLTAG  Please change the image name to a repository on docker hub to which you can write:  export TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloAgain\"  Author: Christof Fetzer, 2017",
            "title": "Generate HelloAgain image"
        },
        {
            "location": "/SCONE_Swarm/",
            "text": "SCONE SWARM\n\n\nInstallation\n\n\nOur \nSCONE Host Setup\n script will typically set up a docker swarm. You can skip this section, if you have already a swarm running. \n\n\nTo manually set up a Docker swarm, log into designated manage node and execute:\n\n\nexport MANAGER_IP=`hostname --ip-address`\ndocker swarm init --advertise-addr $MANAGER_IP\n\n\n\n\nWe determine the address of the swarm manager and the token to join the swarm as follows\n\n\nexport manager_addr=`docker info --format '{{(index .Swarm.RemoteManagers 0).Addr}}'`\nexport token=`docker swarm join-token -q worker`\necho export token=$token\necho export manager_addr=$manager_addr\n\n\n\n\nOn each node that should join the swarm, ensure that you installed our patched Docker engine (which makes the isgx device available to all containers).\n\n\nAdd a new node to the swarm by setting \n$token\n  and \n$manager_addr\n to the values determined above and\nexecute on the new node:\n\n\ndocker swarm join --token $token $manager_addr\n\n\n\n\nSetting Node Labels\n\n\nDocker Swarm supports the labeling of nodes. In our case, we define a label \n\"sgx\"\n that permits us to determine if a node supports sgx and what version of sgx. \n\n\nWe define the following node labels:\n\n\n\n\n\n\nsgx == \"0\" iff the node does not support sgx\n\n\n\n\n\n\nsgx == \"1\" iff the node supports sgx version 1\n\n\n\n\n\n\nsgx == \"2\" iff the node supports sgx version 2 (which is not yet available)\n\n\n\n\n\n\nTo assign a label, we need to figure out the node ID. An easy way to do so, is via the following command:\n\n\n> docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n91a1vvex4dgozfrzy1y136gmg *   alice               Ready               Active              Leader\nocwyg135npgpsrpe2ncuw542x     beatrix             Ready               Active              \n\n\n\n\n\nOne can now manually update a label as follows:\n\n\n> docker node update --label-add sgx=\"1\" 91a1vvex4dgozfrzy1y136gmg\n91a1vvex4dgozfrzy1y136gmg\n\n\n\n\nFor large clusters, we can automate the labeling\nas described in the next subsection.\n\n\nAssign labels to all nodes\n\n\nDocker swarm keeps listing nodes nodes that are down - even if the host running the node has in meantime rejoined as a new node.\n\n\nTo purge all down nodes, execute the following:\n\n\ndocker node rm $(docker node ls -q)\n\n\n\n\nAssuming that all nodes in your swarm support sgx, we assign SGX label \"1\" to all (remaining) nodes:\n\n\nexport nodes=$(docker node ls -q)\nfor node in $nodes ; do\n    docker node update --label-add sgx=\"1\" $node\ndone\n\n\n\n\nWe can check that all sgx labels are \"1\" by executing the following:\n\n\ndocker inspect --format '{{(index  .Spec.Labels \"sgx\")}}' $nodes\n\n\n\n\nAuthor: Christof Fetzer, 2017",
            "title": "SCONE Swarm"
        },
        {
            "location": "/SCONE_Swarm/#scone-swarm",
            "text": "",
            "title": "SCONE SWARM"
        },
        {
            "location": "/SCONE_Swarm/#installation",
            "text": "Our  SCONE Host Setup  script will typically set up a docker swarm. You can skip this section, if you have already a swarm running.   To manually set up a Docker swarm, log into designated manage node and execute:  export MANAGER_IP=`hostname --ip-address`\ndocker swarm init --advertise-addr $MANAGER_IP  We determine the address of the swarm manager and the token to join the swarm as follows  export manager_addr=`docker info --format '{{(index .Swarm.RemoteManagers 0).Addr}}'`\nexport token=`docker swarm join-token -q worker`\necho export token=$token\necho export manager_addr=$manager_addr  On each node that should join the swarm, ensure that you installed our patched Docker engine (which makes the isgx device available to all containers).  Add a new node to the swarm by setting  $token   and  $manager_addr  to the values determined above and\nexecute on the new node:  docker swarm join --token $token $manager_addr",
            "title": "Installation"
        },
        {
            "location": "/SCONE_Swarm/#setting-node-labels",
            "text": "Docker Swarm supports the labeling of nodes. In our case, we define a label  \"sgx\"  that permits us to determine if a node supports sgx and what version of sgx.   We define the following node labels:    sgx == \"0\" iff the node does not support sgx    sgx == \"1\" iff the node supports sgx version 1    sgx == \"2\" iff the node supports sgx version 2 (which is not yet available)    To assign a label, we need to figure out the node ID. An easy way to do so, is via the following command:  > docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n91a1vvex4dgozfrzy1y136gmg *   alice               Ready               Active              Leader\nocwyg135npgpsrpe2ncuw542x     beatrix             Ready               Active                One can now manually update a label as follows:  > docker node update --label-add sgx=\"1\" 91a1vvex4dgozfrzy1y136gmg\n91a1vvex4dgozfrzy1y136gmg  For large clusters, we can automate the labeling\nas described in the next subsection.",
            "title": "Setting Node Labels"
        },
        {
            "location": "/SCONE_Swarm/#assign-labels-to-all-nodes",
            "text": "Docker swarm keeps listing nodes nodes that are down - even if the host running the node has in meantime rejoined as a new node.  To purge all down nodes, execute the following:  docker node rm $(docker node ls -q)  Assuming that all nodes in your swarm support sgx, we assign SGX label \"1\" to all (remaining) nodes:  export nodes=$(docker node ls -q)\nfor node in $nodes ; do\n    docker node update --label-add sgx=\"1\" $node\ndone  We can check that all sgx labels are \"1\" by executing the following:  docker inspect --format '{{(index  .Spec.Labels \"sgx\")}}' $nodes  Author: Christof Fetzer, 2017",
            "title": "Assign labels to all nodes"
        },
        {
            "location": "/SCONE_Swarm_Example/",
            "text": "Starting a SCONE Application on a Swarm\n\n\n docker service create --name \"ha\" --detach=true -p 80:80 -p 443:443 --constraint 'node.labels.sgx != 0'  sconecuratedimages/nginx:noshielding\n\n\n\n\nIf this fails, you get a status as follows: \n\n\n> docker service ps ha\nID                  NAME                IMAGE                      NODE                DESIRED STATE       CURRENT STATE           ERROR                       PORTS\nf65id6ow5n6w        ha.1                sconecuratedimages/nginx   beatrix             Ready               Ready 1 second ago                                  \njt6wj5e3lso4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 3 seconds ago    \"task: non-zero exit (1)\"   \nsspou3mcis8m         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 9 seconds ago    \"task: non-zero exit (1)\"   \np3bw780pu63b         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 15 seconds ago   \"task: non-zero exit (1)\"   \n75zjsesil5k4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 22 seconds ago   \"task: non-zero exit (1)\"   \n\n\n\n\nReasons for failures might be that you do have access to the sgx device. Did you indeed install the patched docker version? Did you indeed label the nodes correctly?\n\n\nIn case service correctly starts up, you will see a status like this: \n\n\n> docker service ps ha\ndocker service ps nginx_service\nID                  NAME       IMAGE                                  NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTS\nx2xq1c3aede7        ha.1       sconecuratedimages/nginx:noshielding   alice               Running             Running 8 minutes ago         \n\n\n\n\nStopping the service\n\n\nStop the service via:\n\n\ndocker service rm ha\n\n\n\n\nScalable Fault-Tolerant Service\n\n\nWe start a nginx service this time with the scontain.com website. We start two replicas, each\nof these need to run on  a SGXv1 machines:\n\n\n> docker service create --name \"sconeweb\" --detach=true  --publish 80:80 --publish 443:443 --constraint 'node.labels.sgx == 1'  --replicas=2 sconecuratedimages/sconetainer:noshielding\n\n\n\n\nIf the image is not available on one of the nodes, you might see the following status:\n\n\n> docker service ps sconeweb\nID                  NAME                IMAGE                                        NODE                DESIRED STATE       CURRENT STATE          ERROR                              PORTS\no79714pw2fpn        sconeweb.1          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago                                       \nt0byepte0fzj         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nmg4xdq868syq         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nry1pqen9jgan         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nq05ti7gkxc7r         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nzxj74inh2zdf        sconeweb.2          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago                                       \n\n\n\n\nFor the next steps, make sure that all nodes have access to image \nsconecuratedimages/sconetainer:noshielding\n \nby executing on all nodes:\n\n\ndocker pull sconecuratedimages/sconetainer:noshielding\n\n\n\n\nDraining a node\n\n\nTo be able to drain all containers from a node, we need to figure out the node's id. We can do this manually by executing the following command:\n\n\n> docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n91a1vvex4dgozfrzy1y136gmg *   alice               Ready               Active              Leader\njhrayos9ylu02egwvkxpqtbwb     beatrix             Ready               Active              \n\n\n\n\nYou can now take node \nalice\n out of service by executing:\n\n\n> docker node update --availability drain 91a1vvex4dgozfrzy1y136gmg\n\n\n\n\nThe status of service might now be as follows:\n\n\n> docker service ps sconeweb\nID                  NAME                IMAGE                                        NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTS\nqaekdszhm8ua        sconeweb.1          sconecuratedimages/sconetainer:noshielding   beatrix             Running             Running 5 seconds ago                                       \no79714pw2fpn         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   alice               Shutdown            Shutdown 7 seconds ago                                      \nt0byepte0fzj         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago     \"No such image: sconecuratedim\u2026\"   \nmg4xdq868syq         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago     \"No such image: sconecuratedim\u2026\"   \nry1pqen9jgan         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago     \"No such image: sconecuratedim\u2026\"   \nkheb76bceupz        sconeweb.2          sconecuratedimages/sconetainer:noshielding   beatrix             Running             Running 6 seconds ago                                       \nzxj74inh2zdf         \\_ sconeweb.2      sconecuratedimages/sconetainer:noshielding   alice               Shutdown            Shutdown 7 seconds ago       \n\n\n\n\nTo put the node back in service, execute:\n\n\ndocker node update --availability active 91a1vvex4dgozfrzy1y136gmg\n\n\n\n\nRunning your own registry\n\n\nIn the above example, we have seen that we had to pull images explicitly from docker hub on each node. This is of course not satisfactory solution. Instead, we should run our own local registry with a copy of the image. You can do this as follows: \n\n\ndocker service create --name registry --detach=true  --publish 5000:5000 --publish 443:443 --replicas=1 registry\n\n\n\n\nNow the our local registry is running, we need to pull the images that we want to store in this registry first. Then, we tag the pulled image with the name of our local registry:\n\n\ndocker pull sconecuratedimages/sconetainer:noshielding\ndocker tag sconecuratedimages/sconetainer:noshielding localhost:5000/sconetainer\n\n\n\n\nWe then push the tagged image to our local registry:\n\n\ndocker push localhost:5000/sconetainer\n\n\n\n\nWe can now create a service using the image stored in the local registry:\n\n\ndocker service create --name \"ha\" --detach=true  --publish 9080:80 --publish 9443:9443 --constraint 'node.labels.sgx != 0'  --replicas=2 localhost:5000/sconetainer\n\n\n\n\nUpdating the image of a service\n\n\nSay, there is a new version of the sconetainer image available. We can update this image in our local registry\nas follows:\n\n\ndocker pull sconecuratedimages/sconetainer:noshielding\ndocker tag sconecuratedimages/sconetainer:noshielding localhost:5000/sconetainer\ndocker push localhost:5000/sconetainer\n\n\n\n\nWe can now update the service as follows:\n\n\ndocker service update --image  localhost:5000/sconetainer ha\n\n\n\n\nAuthor: Christof Fetzer,  2017",
            "title": "SCONE Swarm Example"
        },
        {
            "location": "/SCONE_Swarm_Example/#starting-a-scone-application-on-a-swarm",
            "text": "docker service create --name \"ha\" --detach=true -p 80:80 -p 443:443 --constraint 'node.labels.sgx != 0'  sconecuratedimages/nginx:noshielding  If this fails, you get a status as follows:   > docker service ps ha\nID                  NAME                IMAGE                      NODE                DESIRED STATE       CURRENT STATE           ERROR                       PORTS\nf65id6ow5n6w        ha.1                sconecuratedimages/nginx   beatrix             Ready               Ready 1 second ago                                  \njt6wj5e3lso4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 3 seconds ago    \"task: non-zero exit (1)\"   \nsspou3mcis8m         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 9 seconds ago    \"task: non-zero exit (1)\"   \np3bw780pu63b         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 15 seconds ago   \"task: non-zero exit (1)\"   \n75zjsesil5k4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 22 seconds ago   \"task: non-zero exit (1)\"     Reasons for failures might be that you do have access to the sgx device. Did you indeed install the patched docker version? Did you indeed label the nodes correctly?  In case service correctly starts up, you will see a status like this:   > docker service ps ha\ndocker service ps nginx_service\nID                  NAME       IMAGE                                  NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTS\nx2xq1c3aede7        ha.1       sconecuratedimages/nginx:noshielding   alice               Running             Running 8 minutes ago",
            "title": "Starting a SCONE Application on a Swarm"
        },
        {
            "location": "/SCONE_Swarm_Example/#stopping-the-service",
            "text": "Stop the service via:  docker service rm ha",
            "title": "Stopping the service"
        },
        {
            "location": "/SCONE_Swarm_Example/#scalable-fault-tolerant-service",
            "text": "We start a nginx service this time with the scontain.com website. We start two replicas, each\nof these need to run on  a SGXv1 machines:  > docker service create --name \"sconeweb\" --detach=true  --publish 80:80 --publish 443:443 --constraint 'node.labels.sgx == 1'  --replicas=2 sconecuratedimages/sconetainer:noshielding  If the image is not available on one of the nodes, you might see the following status:  > docker service ps sconeweb\nID                  NAME                IMAGE                                        NODE                DESIRED STATE       CURRENT STATE          ERROR                              PORTS\no79714pw2fpn        sconeweb.1          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago                                       \nt0byepte0fzj         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nmg4xdq868syq         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nry1pqen9jgan         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nq05ti7gkxc7r         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nzxj74inh2zdf        sconeweb.2          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago                                         For the next steps, make sure that all nodes have access to image  sconecuratedimages/sconetainer:noshielding  \nby executing on all nodes:  docker pull sconecuratedimages/sconetainer:noshielding",
            "title": "Scalable Fault-Tolerant Service"
        },
        {
            "location": "/SCONE_Swarm_Example/#draining-a-node",
            "text": "To be able to drain all containers from a node, we need to figure out the node's id. We can do this manually by executing the following command:  > docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n91a1vvex4dgozfrzy1y136gmg *   alice               Ready               Active              Leader\njhrayos9ylu02egwvkxpqtbwb     beatrix             Ready               Active                You can now take node  alice  out of service by executing:  > docker node update --availability drain 91a1vvex4dgozfrzy1y136gmg  The status of service might now be as follows:  > docker service ps sconeweb\nID                  NAME                IMAGE                                        NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTS\nqaekdszhm8ua        sconeweb.1          sconecuratedimages/sconetainer:noshielding   beatrix             Running             Running 5 seconds ago                                       \no79714pw2fpn         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   alice               Shutdown            Shutdown 7 seconds ago                                      \nt0byepte0fzj         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago     \"No such image: sconecuratedim\u2026\"   \nmg4xdq868syq         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago     \"No such image: sconecuratedim\u2026\"   \nry1pqen9jgan         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago     \"No such image: sconecuratedim\u2026\"   \nkheb76bceupz        sconeweb.2          sconecuratedimages/sconetainer:noshielding   beatrix             Running             Running 6 seconds ago                                       \nzxj74inh2zdf         \\_ sconeweb.2      sconecuratedimages/sconetainer:noshielding   alice               Shutdown            Shutdown 7 seconds ago         To put the node back in service, execute:  docker node update --availability active 91a1vvex4dgozfrzy1y136gmg",
            "title": "Draining a node"
        },
        {
            "location": "/SCONE_Swarm_Example/#running-your-own-registry",
            "text": "In the above example, we have seen that we had to pull images explicitly from docker hub on each node. This is of course not satisfactory solution. Instead, we should run our own local registry with a copy of the image. You can do this as follows:   docker service create --name registry --detach=true  --publish 5000:5000 --publish 443:443 --replicas=1 registry  Now the our local registry is running, we need to pull the images that we want to store in this registry first. Then, we tag the pulled image with the name of our local registry:  docker pull sconecuratedimages/sconetainer:noshielding\ndocker tag sconecuratedimages/sconetainer:noshielding localhost:5000/sconetainer  We then push the tagged image to our local registry:  docker push localhost:5000/sconetainer  We can now create a service using the image stored in the local registry:  docker service create --name \"ha\" --detach=true  --publish 9080:80 --publish 9443:9443 --constraint 'node.labels.sgx != 0'  --replicas=2 localhost:5000/sconetainer",
            "title": "Running your own registry"
        },
        {
            "location": "/SCONE_Swarm_Example/#updating-the-image-of-a-service",
            "text": "Say, there is a new version of the sconetainer image available. We can update this image in our local registry\nas follows:  docker pull sconecuratedimages/sconetainer:noshielding\ndocker tag sconecuratedimages/sconetainer:noshielding localhost:5000/sconetainer\ndocker push localhost:5000/sconetainer  We can now update the service as follows:  docker service update --image  localhost:5000/sconetainer ha  Author: Christof Fetzer,  2017",
            "title": "Updating the image of a service"
        },
        {
            "location": "/SCONE_Compose/",
            "text": "SCONE stack\n\n\n NOTE: THIS FUNCTIONALITY WILL ONLY BECOME AVAILABLE FOR EVALUATION IN LATE 2017. The interface is still subject to change. \n\n\nNote that we decided to extend Docker stack file instead of a Docker compose file. One reason is that Docker stack supports device mappings while new compose files (v3) do not support this anymore.\n\n\nSCONE implements extensions of the standard Docker stack file \n[reference]\n. A stack file is a YAML file that is used to build \nstack\n, i.e., an application consisting of a collection of containers. The main objective of the SCONE extensions is to enable stacks consisting of secure and standard containers. To secure containers, we need to be able to pass confidential data - like configuration files - without this data being visible to Docker or any other system software. Actually, we recommend that this information is not even visible to the programmer writing the stack file. For example, by having no secrets in the stack file, one can reuse the stack files in different contexts. Moreover, one does not need to change the keys in the stack file if some person that had access to the stack file leaves the company.  \n\n\nTo avoid keys inside of extended stack files, our extensions support the use of a key storage. One can automatically generate new keys or can reuse old keys - say after an update of a compose file. Also, one can share keys between different stacks. \n\n\nThe extended stack file is split by SCONE into a standard compose file and a configuration information that is stored in the key store\n\n\n\n\nThe command line is similar to that of Docker:\n\n\nscone stack deploy [OPTIONS] STACK\n\n\n\n\nwhere STACK is the name of the stack file.\n\n\nNote that the key storage can only be accessed by command \nscone stack deploy\n and by the enclaved process. \nThe enclaved process needs to show the proper certificate showing that it runs inside an enclave as well as\nbelong to the same stack. Each stack has a unique ID which is passed - in the clear - to the started secure container. \n\n\nConfidentiality and Integrity\n\n\nWe set defaults such that we can use a standard Docker stack file and we will start it that all data is encrypted\nby default. A developer can opt-out from these defaults, for example, by not encrypting data that is already encrypted by the application code.  \n\n\nimage (required)\n\n\nA stack is a collection of \nservices\n and for each service in a \nstack\n, one \nimage\n key must be defined.  To run an secure service (i.e., a service running inside an enclave), we need to specify an enclave certificate. Only a service running inside an enclave matching this certificate can access the environment, arguments and configuration data.\n\n\nScone stack will retrieve this certificate from the key store\nusing the certificate in directory \nimages\n matching the image name:\n\n\nimage: sconecontainers.com/mysql:latest\n\n\n\n\nIn this case, the certificate would be retrieved from the key store via name \nimages/sconecontainers.com/mysql:latest\n. If this certificate is not found or does not match the actual enclave certificate, this service will not be able to start up. \n\n\nWe evaluate the following scone stack extensions.\n\n\nThe stack file can specify the enclave certificate explicitly:\n\n\nimage: sconecontainers.com/mysql:latest\n  enclave-certificate: Base64encoded\n\n\n\n\nAlternatively, the stack file can specify an alternative key to retrieve the certificate from the\nkey storage:\n\n\nimage: sconecontainers.com/mysql:latest\n  enclave-certificate: \\(myimage_certificates/sconecontainers.com/mysql:latest)\n\n\n\n\nTo mix secure and standard containers, one can optionally also provide the key \ninsecure-image\n:\n\n\nimage: mysql\n  insecure-image\n\n\n\n\nSummary:\n the first version of \nscone stack\n will only support certificates that are implicitly loaded from the key store.\nExplicit keys inside the stack file or alternative certificate locations, might be supported in future versions of \nscone stack\n \n\n\ndevices\n\n\nWe need to make sure that \n/dev/isgx\n is mapped into secure containers. Hence, by default \n\nscone stack deploy\n will add the follow device mapping to all secure containers. \n\n\ndevices:\n  - \"/dev/isgx:/dev/isgx\"\n\n\n\n\nNote:\n In case this mapping already exists in the stack file, this device mapping is only added once. While Docker compose version 3 does not support device option anymore, stack files do support a device option.\n\n\nenvironment\n\n\nOne can define environment variables that are not visible to docker and are passed in a secure fashion to\nthe applications. These definitions overwrite the environment variables given in the container image.\n\n\nExample:\n\n\nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET=\"blabla\"\n\n\n\n\nWe can retrieve sensitive entries from the key store before passing this to the application:\n\n\nenclave-environment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET=\\(vault.{namespace}.MYSQL_ROOT_PASSWORD)\n\n\n\n\nThe evaluation is performed at the time when the program starts up.\n\n\npid\n\n\nSome applications use the pid to compute random numbers. This is of course not a good idea. Instead of requiring\nto change these applications we have an option to set a random pid.  \n\n\npid: \"random\"\n\n\n\n\nWe have also support fixed pids, i.e., one can set the pid of this process. To set the process\nto 42, just specify:\n\n\npid: \"42\"\n\n\n\n\nSCONE supports also the \npid\n options of Docker like \"host\"  \n\n\nenclave-tmpfs\n\n\nMounts a temporary file system. SCONE supports an encrypted temporary file system. \nThe key for the temporary file system is randomly chosen:\n\n\nenclaved-tmpfs: /run\nenclaved-tmpfs:\n  - /run\n  - /tmp\n\n\n\n\nenclave-env_file\n\n\nWe do not support an enclaced version of env_file yet. Please use enclave-environment instead.\n\n\nenclave-extra_hosts:\n\n\nAdd extra entries to /etc/hosts in a secure fashion:\n\n\nextra_hosts:\n - \"somehost:162.242.195.82\"\n - \"otherhost:50.31.209.229\"\n\n\n\n\nfile-protection\n\n\nfile-protection:\n  fail-on-r-unencrypted;\n  fail-on-w-unauthenticated;\n\n\n\n\nsecure-file-inject\n\n\nOne can inject files from the compose host into the image.\n\nsecure-file-inject\n injects files that are not encrypted on the compose host\nbut must be encrypted in the container. Since sensitive files on the compose host \nshould be encrypted too, use this variant only for debugging.\n\n\nsecure-file-inject:\n  .git-credentials:.git-credentials\n\n\n\n\nThe preferred use of \nsecure-file-inject\n is to retrieve the file content from \na key store. The following variant retrieves the content of an injected file from the key store.\nThis requires to specify a \nkey\n. This key is used to retrieve the content.\nThe key is prefixed by the unique key of the \ndeployed stack\n.\n\n\nsecure-file-inject:\n  vault:\n    key: git-credentials\n    file:.git-credentials\n\n\n\n\nimage\n\n\nspecify signer of an image and the version of the image.\n\n\n image: curated_mysql\n     enclave-signer: SCONE-LTD.COM\n     enclave-version: 2.1-\n\n\n\n\ntty\n\n\ntty: true\n    tty-encryption-key:  tty-passwd\n\n\n\n\ntty: true\n    tty-encryption-key:  \\(TTY-KEY)\n\n\n\n\nSyntactic sugar for ..:\n\n\nenclave-tty: true\n\n\n\n\nstdin_open\n\n\nstdin_open: true\n tty-encryption-key:  in-pswd\n\n\n\n\nfile-encryption\n\n\nsocket-encryption\n\n\nlease management\n\n\nWe use leases to perform to address the following two problems:\n\n\n\n\n\n\nwe might need to enforce some periodic rekeying of keys that are included in configuration files\n\n\n\n\n\n\nwe might need to ensure that the number of replicas is bounded, for example, we might only permit one replica of a service. \n\n\n\n\n\n\nTo solve these two problems we permit to define per service how many leases are permitted and \n\n\nHence, we would need to reread all configuration files periodically. \n\n\nAuthor: Christof Fetzer, January 2017",
            "title": "SCONE Compose"
        },
        {
            "location": "/SCONE_Compose/#scone-stack",
            "text": "NOTE: THIS FUNCTIONALITY WILL ONLY BECOME AVAILABLE FOR EVALUATION IN LATE 2017. The interface is still subject to change.   Note that we decided to extend Docker stack file instead of a Docker compose file. One reason is that Docker stack supports device mappings while new compose files (v3) do not support this anymore.  SCONE implements extensions of the standard Docker stack file  [reference] . A stack file is a YAML file that is used to build  stack , i.e., an application consisting of a collection of containers. The main objective of the SCONE extensions is to enable stacks consisting of secure and standard containers. To secure containers, we need to be able to pass confidential data - like configuration files - without this data being visible to Docker or any other system software. Actually, we recommend that this information is not even visible to the programmer writing the stack file. For example, by having no secrets in the stack file, one can reuse the stack files in different contexts. Moreover, one does not need to change the keys in the stack file if some person that had access to the stack file leaves the company.    To avoid keys inside of extended stack files, our extensions support the use of a key storage. One can automatically generate new keys or can reuse old keys - say after an update of a compose file. Also, one can share keys between different stacks.   The extended stack file is split by SCONE into a standard compose file and a configuration information that is stored in the key store   The command line is similar to that of Docker:  scone stack deploy [OPTIONS] STACK  where STACK is the name of the stack file.  Note that the key storage can only be accessed by command  scone stack deploy  and by the enclaved process. \nThe enclaved process needs to show the proper certificate showing that it runs inside an enclave as well as\nbelong to the same stack. Each stack has a unique ID which is passed - in the clear - to the started secure container.",
            "title": "SCONE stack"
        },
        {
            "location": "/SCONE_Compose/#confidentiality-and-integrity",
            "text": "We set defaults such that we can use a standard Docker stack file and we will start it that all data is encrypted\nby default. A developer can opt-out from these defaults, for example, by not encrypting data that is already encrypted by the application code.",
            "title": "Confidentiality and Integrity"
        },
        {
            "location": "/SCONE_Compose/#image-required",
            "text": "A stack is a collection of  services  and for each service in a  stack , one  image  key must be defined.  To run an secure service (i.e., a service running inside an enclave), we need to specify an enclave certificate. Only a service running inside an enclave matching this certificate can access the environment, arguments and configuration data.  Scone stack will retrieve this certificate from the key store\nusing the certificate in directory  images  matching the image name:  image: sconecontainers.com/mysql:latest  In this case, the certificate would be retrieved from the key store via name  images/sconecontainers.com/mysql:latest . If this certificate is not found or does not match the actual enclave certificate, this service will not be able to start up.   We evaluate the following scone stack extensions.  The stack file can specify the enclave certificate explicitly:  image: sconecontainers.com/mysql:latest\n  enclave-certificate: Base64encoded  Alternatively, the stack file can specify an alternative key to retrieve the certificate from the\nkey storage:  image: sconecontainers.com/mysql:latest\n  enclave-certificate: \\(myimage_certificates/sconecontainers.com/mysql:latest)  To mix secure and standard containers, one can optionally also provide the key  insecure-image :  image: mysql\n  insecure-image  Summary:  the first version of  scone stack  will only support certificates that are implicitly loaded from the key store.\nExplicit keys inside the stack file or alternative certificate locations, might be supported in future versions of  scone stack",
            "title": "image (required)"
        },
        {
            "location": "/SCONE_Compose/#devices",
            "text": "We need to make sure that  /dev/isgx  is mapped into secure containers. Hence, by default  scone stack deploy  will add the follow device mapping to all secure containers.   devices:\n  - \"/dev/isgx:/dev/isgx\"  Note:  In case this mapping already exists in the stack file, this device mapping is only added once. While Docker compose version 3 does not support device option anymore, stack files do support a device option.",
            "title": "devices"
        },
        {
            "location": "/SCONE_Compose/#environment",
            "text": "One can define environment variables that are not visible to docker and are passed in a secure fashion to\nthe applications. These definitions overwrite the environment variables given in the container image.  Example:  environment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET=\"blabla\"  We can retrieve sensitive entries from the key store before passing this to the application:  enclave-environment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET=\\(vault.{namespace}.MYSQL_ROOT_PASSWORD)  The evaluation is performed at the time when the program starts up.",
            "title": "environment"
        },
        {
            "location": "/SCONE_Compose/#pid",
            "text": "Some applications use the pid to compute random numbers. This is of course not a good idea. Instead of requiring\nto change these applications we have an option to set a random pid.    pid: \"random\"  We have also support fixed pids, i.e., one can set the pid of this process. To set the process\nto 42, just specify:  pid: \"42\"  SCONE supports also the  pid  options of Docker like \"host\"",
            "title": "pid"
        },
        {
            "location": "/SCONE_Compose/#enclave-tmpfs",
            "text": "Mounts a temporary file system. SCONE supports an encrypted temporary file system. \nThe key for the temporary file system is randomly chosen:  enclaved-tmpfs: /run\nenclaved-tmpfs:\n  - /run\n  - /tmp",
            "title": "enclave-tmpfs"
        },
        {
            "location": "/SCONE_Compose/#enclave-env_file",
            "text": "We do not support an enclaced version of env_file yet. Please use enclave-environment instead.",
            "title": "enclave-env_file"
        },
        {
            "location": "/SCONE_Compose/#enclave-extra_hosts",
            "text": "Add extra entries to /etc/hosts in a secure fashion:  extra_hosts:\n - \"somehost:162.242.195.82\"\n - \"otherhost:50.31.209.229\"",
            "title": "enclave-extra_hosts:"
        },
        {
            "location": "/SCONE_Compose/#file-protection",
            "text": "file-protection:\n  fail-on-r-unencrypted;\n  fail-on-w-unauthenticated;",
            "title": "file-protection"
        },
        {
            "location": "/SCONE_Compose/#secure-file-inject",
            "text": "One can inject files from the compose host into the image. secure-file-inject  injects files that are not encrypted on the compose host\nbut must be encrypted in the container. Since sensitive files on the compose host \nshould be encrypted too, use this variant only for debugging.  secure-file-inject:\n  .git-credentials:.git-credentials  The preferred use of  secure-file-inject  is to retrieve the file content from \na key store. The following variant retrieves the content of an injected file from the key store.\nThis requires to specify a  key . This key is used to retrieve the content.\nThe key is prefixed by the unique key of the  deployed stack .  secure-file-inject:\n  vault:\n    key: git-credentials\n    file:.git-credentials",
            "title": "secure-file-inject"
        },
        {
            "location": "/SCONE_Compose/#image",
            "text": "specify signer of an image and the version of the image.   image: curated_mysql\n     enclave-signer: SCONE-LTD.COM\n     enclave-version: 2.1-",
            "title": "image"
        },
        {
            "location": "/SCONE_Compose/#tty",
            "text": "tty: true\n    tty-encryption-key:  tty-passwd  tty: true\n    tty-encryption-key:  \\(TTY-KEY)  Syntactic sugar for ..:  enclave-tty: true",
            "title": "tty"
        },
        {
            "location": "/SCONE_Compose/#stdin_open",
            "text": "stdin_open: true\n tty-encryption-key:  in-pswd",
            "title": "stdin_open"
        },
        {
            "location": "/SCONE_Compose/#file-encryption",
            "text": "",
            "title": "file-encryption"
        },
        {
            "location": "/SCONE_Compose/#socket-encryption",
            "text": "",
            "title": "socket-encryption"
        },
        {
            "location": "/SCONE_Compose/#lease-management",
            "text": "We use leases to perform to address the following two problems:    we might need to enforce some periodic rekeying of keys that are included in configuration files    we might need to ensure that the number of replicas is bounded, for example, we might only permit one replica of a service.     To solve these two problems we permit to define per service how many leases are permitted and   Hence, we would need to reread all configuration files periodically.   Author: Christof Fetzer, January 2017",
            "title": "lease management"
        },
        {
            "location": "/SCONE_OpenStack/",
            "text": "",
            "title": "SCONE OpenStack Support"
        },
        {
            "location": "/SCONE_Publications/",
            "text": "SCONE Related Publications\n\n\nSCONE: Secure Linux Containers with Intel SGX, USENIX, OSDI 2016\n\n\nThis paper describes how we support unmodified applications inside of enclaves. The focus is on our asynchronous system\n call interface.\n\n\n\n\n\n\nAuthors\n:  Sergei Arnautov, Bohdan Trach, Franz Gregor, Thomas Knauth, Andr\u00e9 Martin, Christian Priebe, Joshua Lind, Divya Muthukumaran, Daniel O'Keeffe, Mark L Stillwell, David Goltzsche, Dave Eyers, R\u00fcdiger Kapitza, Peter Pietzuch, Christof Fetzer\n\n\n\n\n\n\nMedia\n: \npdf\n, \nslides\n\n\naudio\n\n\n\n\n\n\nAbstract\n:  In multi-tenant environments, Linux containers managed by Docker or Kubernetes have a lower resource footprint, faster startup times, and higher I/O performance compared to virtual machines (VMs) on hypervisors. Yet their weaker isolation guarantees, enforced through software kernel mechanisms, make it easier for attackers to compromise the confidentiality and integrity of application data within containers.\nWe describe SCONE, a secure container mechanism for Docker that uses the SGX trusted execution support of Intel CPUs to protect container processes from outside attacks. The design of SCONE leads to (i) a small trusted computing base (TCB) and (ii) a low performance overhead: SCONE offers a secure C standard library interface that transparently encrypts/decrypts I/O data; to reduce the performance impact of thread synchronization and system calls within SGX enclaves, SCONE supports user-level threading and asynchronous system calls. Our evaluation shows that it protects unmodified applications with SGX, achieving 0.6x\u20131.2x of native throughput.\n\n\n\n\n\n\n SGXBounds: Memory Safety for Shielded Execution, EuroSys 2017\n\n\nTo protect the code running inside of an enclave, we implemented a novel bounds checker for enclaves. While we had expected\n to just be able to use MPX, we had to realized that MPX does not perform that well inside of enclaves. For details regarding\n the overheads,  please see this paper. \nThis won the best paper award of EuroSys 2017.\n\n\n\n\n\n\nAuthors\n: D. Kuvaiskii, O. Oleksenko, S. Arnautov, B. Trach, P. Bhatotia, P. Felber, C. Fetzer \n\n\n\n\n\n\nMedia\n: \npdf\n \n\n\n\n\n\n\nAbstract\n: Shielded execution based on Intel SGX provides strong security guarantees for legacy applications running on untrusted platforms. However, memory safety attacks such as Heartbleed can render the confidentiality and integrity properties of shielded execution completely ineffective. To prevent these attacks, the state-of-the-art memory-safety approaches can be used in the context of shielded execution. In this work, we first showcase that two prominent software- and hardware-based defenses, AddressSanitizer and Intel MPX respectively, are impractical for shielded execution due to high performance and memory overheads. This motivated our design of SGXBounds -- an efficient memory-safety approach for shielded execution exploiting the architectural features of Intel SGX. Our design is based on a simple combination of tagged pointers and compact memory layout. We implemented SGXBounds based on the LLVM compiler framework targeting unmodified multithreaded applications. Our evaluation using Phoenix, PARSEC, and RIPE benchmark suites shows that SGXBounds has performance and memory overheads of 18% and 0.1% respectively, while providing security guarantees similar to AddressSanitizer and Intel MPX. We have obtained similar results with four real-world case studies: SQLite, Memcached, Apache, and Nginx.\n\n\n\n\n\n\n FFQ: A Fast Single-Producer/Multiple-Consumer Concurrent FIFO Queue, IPDPS 2017\n\n\nThis paper describes our new lock-free queue for our asynchronous system calls.\n\n\n\n\n\n\nAuthors\n: Sergei Arnautov, Pascal Felber, Christof Fetzer and Bohdan Trach\n\n\n\n\n\n\nMedia\n: \nsorry, not yet available\n \n\n\n\n\n\n\nAbstract\n:  With the spreading of multi-core architectures, operating systems and applications are becoming increasingly more concurrent and their scalability is often limited by the primitives used to synchronize the different hardware threads. In this paper, we address the problem of how to optimize the throughput of a system with multiple producer and consumer threads. Such applications typically synchronize their threads via multi- producer/multi-consumer FIFO queues, but existing solutions have poor scalability, as we could observe when designing a secure application framework that requires high-throughput communication between many concurrent threads. In our target system, however, the items enqueued by different producers do not necessarily need to be FIFO ordered. Hence, we propose a fast FIFO queue, FFQ, that aims at maximizing throughput by specializing the algorithm for single-producer/multiple-consumer settings: each producer has its own queue from which multiple consumers can concurrently dequeue. Furthermore, while we pro- vide a wait-free interface for producers, we limit ourselves to lock-free consumers to eliminate the need for helping. We also propose a multi-producer variant to show which synchronization operations we were able to remove by focusing on a single producer variant. Our evaluation analyses the performance using micro- benchmarks and compares our results with other state-of-the-art solutions: FFQ exhibits excellent performance and scalability.\n\n\n\n\n\n\nAuthor: Christof Fetzer, 2017",
            "title": "SCONE Publications"
        },
        {
            "location": "/SCONE_Publications/#scone-related-publications",
            "text": "SCONE: Secure Linux Containers with Intel SGX, USENIX, OSDI 2016  This paper describes how we support unmodified applications inside of enclaves. The focus is on our asynchronous system\n call interface.    Authors :  Sergei Arnautov, Bohdan Trach, Franz Gregor, Thomas Knauth, Andr\u00e9 Martin, Christian Priebe, Joshua Lind, Divya Muthukumaran, Daniel O'Keeffe, Mark L Stillwell, David Goltzsche, Dave Eyers, R\u00fcdiger Kapitza, Peter Pietzuch, Christof Fetzer    Media :  pdf ,  slides  audio    Abstract :  In multi-tenant environments, Linux containers managed by Docker or Kubernetes have a lower resource footprint, faster startup times, and higher I/O performance compared to virtual machines (VMs) on hypervisors. Yet their weaker isolation guarantees, enforced through software kernel mechanisms, make it easier for attackers to compromise the confidentiality and integrity of application data within containers.\nWe describe SCONE, a secure container mechanism for Docker that uses the SGX trusted execution support of Intel CPUs to protect container processes from outside attacks. The design of SCONE leads to (i) a small trusted computing base (TCB) and (ii) a low performance overhead: SCONE offers a secure C standard library interface that transparently encrypts/decrypts I/O data; to reduce the performance impact of thread synchronization and system calls within SGX enclaves, SCONE supports user-level threading and asynchronous system calls. Our evaluation shows that it protects unmodified applications with SGX, achieving 0.6x\u20131.2x of native throughput.     SGXBounds: Memory Safety for Shielded Execution, EuroSys 2017  To protect the code running inside of an enclave, we implemented a novel bounds checker for enclaves. While we had expected\n to just be able to use MPX, we had to realized that MPX does not perform that well inside of enclaves. For details regarding\n the overheads,  please see this paper.  This won the best paper award of EuroSys 2017.    Authors : D. Kuvaiskii, O. Oleksenko, S. Arnautov, B. Trach, P. Bhatotia, P. Felber, C. Fetzer     Media :  pdf      Abstract : Shielded execution based on Intel SGX provides strong security guarantees for legacy applications running on untrusted platforms. However, memory safety attacks such as Heartbleed can render the confidentiality and integrity properties of shielded execution completely ineffective. To prevent these attacks, the state-of-the-art memory-safety approaches can be used in the context of shielded execution. In this work, we first showcase that two prominent software- and hardware-based defenses, AddressSanitizer and Intel MPX respectively, are impractical for shielded execution due to high performance and memory overheads. This motivated our design of SGXBounds -- an efficient memory-safety approach for shielded execution exploiting the architectural features of Intel SGX. Our design is based on a simple combination of tagged pointers and compact memory layout. We implemented SGXBounds based on the LLVM compiler framework targeting unmodified multithreaded applications. Our evaluation using Phoenix, PARSEC, and RIPE benchmark suites shows that SGXBounds has performance and memory overheads of 18% and 0.1% respectively, while providing security guarantees similar to AddressSanitizer and Intel MPX. We have obtained similar results with four real-world case studies: SQLite, Memcached, Apache, and Nginx.     FFQ: A Fast Single-Producer/Multiple-Consumer Concurrent FIFO Queue, IPDPS 2017  This paper describes our new lock-free queue for our asynchronous system calls.    Authors : Sergei Arnautov, Pascal Felber, Christof Fetzer and Bohdan Trach    Media :  sorry, not yet available      Abstract :  With the spreading of multi-core architectures, operating systems and applications are becoming increasingly more concurrent and their scalability is often limited by the primitives used to synchronize the different hardware threads. In this paper, we address the problem of how to optimize the throughput of a system with multiple producer and consumer threads. Such applications typically synchronize their threads via multi- producer/multi-consumer FIFO queues, but existing solutions have poor scalability, as we could observe when designing a secure application framework that requires high-throughput communication between many concurrent threads. In our target system, however, the items enqueued by different producers do not necessarily need to be FIFO ordered. Hence, we propose a fast FIFO queue, FFQ, that aims at maximizing throughput by specializing the algorithm for single-producer/multiple-consumer settings: each producer has its own queue from which multiple consumers can concurrently dequeue. Furthermore, while we pro- vide a wait-free interface for producers, we limit ourselves to lock-free consumers to eliminate the need for helping. We also propose a multi-producer variant to show which synchronization operations we were able to remove by focusing on a single producer variant. Our evaluation analyses the performance using micro- benchmarks and compares our results with other state-of-the-art solutions: FFQ exhibits excellent performance and scalability.    Author: Christof Fetzer, 2017",
            "title": "SCONE Related Publications"
        }
    ]
}