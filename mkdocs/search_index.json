{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to SCONE\n\n\nSCONE is a platform to \nbuild and run secure applications\n with the help of \nIntel SGX\n (Software Guard eXtensions). \nIn a nutshell, our objective is to run applications such that data is \nalways encrypted\n, i.e., all data at rest, all data on the wire as well as all data in main memory is encrypted.\n\n\nOur aim is it to make securing your application \nas easy as possible\n. Switching to SCONE is simple since applications do not need to be modified. Moreover, we provide a tight integration with Docker Swarm.  In case you are already using Docker \ncompose files\n, we provide a simple way to secure your services and applications.\n\n\nWhile SCONE focuses on securing containers and cloud-native applications, SCONE can help you to secure almost any program running on top of Linux.\n\n\nSo, what problems can SCONE help me to solve?\n\n\nSecure application configuration\n\n\nSCONE provides applications with secrets in a secure fashion. \nWhy is that a problem?\n  Say, you want to run MySQL and you configure MySQL to encrypt its data at rest. To do so, MySQL requires a key to decrypt and encrypt its files. One can store this key in the MySQL configuration file but this configuration file cannot be encrypted since MySQL would need a key to decrypt the file. SCONE helps developers to solve such configuration issues in the following ways:\n\n\n\n\n\n\nsecure configuration files\n. SCONE can transparently decrypt encrypted configuration files. It will give access to the plain text only to a given program, like, MySQL. No source code changes are needed for this to work.\n\n\n\n\n\n\nsecure environment variables\n. SCONE gives applications access to environment variables that are not visible to anybody else - even users with root access or the operating system. \nWhy would I need this?\n Consider the MySQL example from above. You can pass user passwords via environment variables like \nMYSQL_ROOT_PASSWORD\n and \nMYSQL_PASSWORD\n to the MySQL. We need to protect these environment variables to prevent unauthorized accesses to the MySQL database.\n\n\n\n\n\n\nsecure command line arguments\n. Some applications might not use environment variables but command line arguments to pass secrets to the application. SCONE provides a secure way to pass arguments to your application without other privileged parties, like the operating system, being able to see the arguments.\n\n\n\n\n\n\nTransparent attestation\n\n\nIn operations mode, \nSCONE will verify that the correct code is running\n before passing the configuration to the application. To ensure this, SCONE provides a \nlocal attestation and configuration service\n: this service provides only the code with the correct signature (\nMRENCLAVE\n) with its secrets. For debugging and development, you can run code inside of enclaves without attestation.\n\n\nSecure main memory\n\n\nAn adversary with root access can read the memory content of any process. In this way, an adversary can gain access to keys that an application is using, for example, the keys to protect its data at rest. SCONE helps to \nprotect the main memory\n:\n\n\n\n\n\n\nno access by adversaries - even those who have already gained root access,\n\n\n\n\n\n\nno access by the operating system - even if compromised,\n\n\n\n\n\n\nno access by the hypervisor - even if compromised, and\n\n\n\n\n\n\nno access by the cloud provider, and\n\n\n\n\n\n\nno access by evil maids - despite having physical access to the host.\n\n\n\n\n\n\nIntegration with secure key store\n\n\nEncryption keys must be protected. In many installations, one does not want humans to be able to see encryption keys. Hence, one generates keys and stores these in keystores. SCONE supports the integration with a keystore.\n\n\nTransparent TLS encryption\n\n\nSome popular applications like memcached do not support TLS out of the box. SCONE can transparently add TLS encryption to TCP connections. In SCONE, we never uses an external process for TLS termination. In this way, the plain text is never seen by the operating system or any adversary.\n\n\nTransparent file protection\n\n\nSCONE protects via \ntransparent file protection\n the integrity and confidentiality of not only configuration files but any file. This protection does not require any source code changes. A file can either be \nintegrity-protected\n only (i.e., the file is stored in plain text but modifications are detected) or \nconfidentiality-\n and \nintegrity-protected\n (i.e., the file is encrypted and modifications are detected).\n\n\nEase of use\n\n\nWe provide slightly \nextended Docker compose files\n to start an application consisting of a set of services inside of enclaves.\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "Introduction"
        },
        {
            "location": "/#welcome-to-scone",
            "text": "SCONE is a platform to  build and run secure applications  with the help of  Intel SGX  (Software Guard eXtensions). \nIn a nutshell, our objective is to run applications such that data is  always encrypted , i.e., all data at rest, all data on the wire as well as all data in main memory is encrypted.  Our aim is it to make securing your application  as easy as possible . Switching to SCONE is simple since applications do not need to be modified. Moreover, we provide a tight integration with Docker Swarm.  In case you are already using Docker  compose files , we provide a simple way to secure your services and applications.  While SCONE focuses on securing containers and cloud-native applications, SCONE can help you to secure almost any program running on top of Linux.",
            "title": "Welcome to SCONE"
        },
        {
            "location": "/#so-what-problems-can-scone-help-me-to-solve",
            "text": "Secure application configuration  SCONE provides applications with secrets in a secure fashion.  Why is that a problem?   Say, you want to run MySQL and you configure MySQL to encrypt its data at rest. To do so, MySQL requires a key to decrypt and encrypt its files. One can store this key in the MySQL configuration file but this configuration file cannot be encrypted since MySQL would need a key to decrypt the file. SCONE helps developers to solve such configuration issues in the following ways:    secure configuration files . SCONE can transparently decrypt encrypted configuration files. It will give access to the plain text only to a given program, like, MySQL. No source code changes are needed for this to work.    secure environment variables . SCONE gives applications access to environment variables that are not visible to anybody else - even users with root access or the operating system.  Why would I need this?  Consider the MySQL example from above. You can pass user passwords via environment variables like  MYSQL_ROOT_PASSWORD  and  MYSQL_PASSWORD  to the MySQL. We need to protect these environment variables to prevent unauthorized accesses to the MySQL database.    secure command line arguments . Some applications might not use environment variables but command line arguments to pass secrets to the application. SCONE provides a secure way to pass arguments to your application without other privileged parties, like the operating system, being able to see the arguments.    Transparent attestation  In operations mode,  SCONE will verify that the correct code is running  before passing the configuration to the application. To ensure this, SCONE provides a  local attestation and configuration service : this service provides only the code with the correct signature ( MRENCLAVE ) with its secrets. For debugging and development, you can run code inside of enclaves without attestation.  Secure main memory  An adversary with root access can read the memory content of any process. In this way, an adversary can gain access to keys that an application is using, for example, the keys to protect its data at rest. SCONE helps to  protect the main memory :    no access by adversaries - even those who have already gained root access,    no access by the operating system - even if compromised,    no access by the hypervisor - even if compromised, and    no access by the cloud provider, and    no access by evil maids - despite having physical access to the host.    Integration with secure key store  Encryption keys must be protected. In many installations, one does not want humans to be able to see encryption keys. Hence, one generates keys and stores these in keystores. SCONE supports the integration with a keystore.  Transparent TLS encryption  Some popular applications like memcached do not support TLS out of the box. SCONE can transparently add TLS encryption to TCP connections. In SCONE, we never uses an external process for TLS termination. In this way, the plain text is never seen by the operating system or any adversary.  Transparent file protection  SCONE protects via  transparent file protection  the integrity and confidentiality of not only configuration files but any file. This protection does not require any source code changes. A file can either be  integrity-protected  only (i.e., the file is stored in plain text but modifications are detected) or  confidentiality-  and  integrity-protected  (i.e., the file is encrypted and modifications are detected).  Ease of use  We provide slightly  extended Docker compose files  to start an application consisting of a set of services inside of enclaves.  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "So, what problems can SCONE help me to solve?"
        },
        {
            "location": "/outline/",
            "text": "Getting Started\n\n\nThe simplest way to get started with SCONE is to use it in \nsimulation\n mode.\nIn \nsimulation mode\n, you do not need to install any new software on your host - as long as you have already a Docker engine running.\nYou could start by looking at the introduction of the \nSCONE CLI\n. \n\n\nAfter that, you could try to compile a simple \nhello world\n program. For now, we have a light access control to some of the SCONE docker images - like the ones needed for compiling the hello world program. Just send an email with your free \nDocker ID\n to \ninfo@scontain.com\n. After gaining access, you can compile the hello world program as shown in the \nSCONE Tutorial\n. You can run the program in simulation mode.  After that,  check out how you could automate the compilation with the help of a \nDockerfile\n. Next would be to run an example application in a \nSwarm\n.\n\n\nHardware Mode\n\n\nIf you have access to a SGX-capable host, you can, of course, run your programs in Intel SGX enclaves. For ease of use, we create all Docker images used in this tutorial such that applications run inside of enclaves if available. Otherwise, they run in simulation mode, i.e., outside of an enclave but all SCONE software running. When running your software in operations, you would of course force the programs to run only inside of enclaves. We show later how this can be enforced with the help of SCONE remote attestation.\n\n\nTo be able to use hardware mode, programs need access to the SGX device. If your hosts have already a Intel SGX driver installed, you are all set. Otherwise, SCONE can help you to install a lightly patched SGX driver that provides some more monitoring information - like the number of free EPC pages of a host (\nSCONE Host Setup\n).\n\n\nIf you want to run your programs in containers across multiple hosts with the help of a Docker swarm, you need to give access to the sgx device. Right now, Docker Swarm does not support mapping a device on all hosts. We have a simple patched version that gives access to the sgx device to all containers across all hosts. \nSCONE Host Setup\n installs this patched Docker engine.\n\n\nAfter having installed the SGX driver, you can run different applications inside of enclaves. In addition to \nC\n, C++, \nGO\n, Fortran and Rust (as part of SCONE crosscompiler image \nssconecuratedimages/crosscompilers:scone\n ), we also support \nPython\n and soon Node.js.\n\n\nOutline\n\n\nThe SCONE platform technical documentation is structured as follows:\n\n\n\n\n\n\nSCONE Application-Oriented Security\n: a short introduction into SCONE's unique security approach.\n\n\n\n\n\n\nSCONE Background\n: a short introduction into why good systems security is difficult to achieve and how SCONE helps to complement systems security.\n\n\n\n\n\n\nSCONE CLI\n: introduces the SCONE command line interface and how to install the SCONE CLI.\n\n\n\n\n\n\nSCONE Host Setup\n: to run secure containers, we need to configure each host to run a Linux SGX driver and also a (for convenience, a patched) Docker engine.\n\n\n\n\n\n\nSCONE SGX Toolchain\n: SCONE supports cross-compilers (C, C++, more to come soon) to compile and build  applications for SGX enclaves.\n\n\n\n\n\n\nSCONE Curated Container Images\n: we will support a set of secure container images to simplify the use of SCONE.\n\n\n\n\n\n\nSCONE Tutorial\n: we show how to compile simple example applications with the help of the SCONE SGX Toolchain.\n\n\n\n\n\n\nSCONE Create Image\n: we show how to create a container image for Docker hub.\n\n\n\n\n\n\nSCONE Dockerfile\n: we support the use of Dockerfiles to generate Docker images that contain services running inside of SGX enclaves (this requires a \npatched Docker Engine\n).\n\n\n\n\n\n\nSCONE Swarm\n: show how to setup a Docker Swarm usable for SCONE.\n\n\n\n\n\n\nSCONE Swarm Example\n: shows an example of how to start SCONE services on top of a Docker Swarm.\n\n\n\n\n\n\nSCONE File Protection\n: we show how to transparently encrypt or authenticate files in the file system.\n\n\n\n\n\n\nGO inside Enclave\n: shows how to run GO programs inside of enclaves.\n\n\n\n\n\n\nPython inside Enclave\n: shows how to run simple Python applications inside of enclaves.\n\n\n\n\n\n\nSCONE Environment variables\n: short description of the SCONE environment variables.\n\n\n\n\n\n\nPublications\n:  some of the technical aspects of SCONE have been published in scientific papers. We provide a short summary of the papers and links to the pdfs.\n\n\n\n\n\n\nGlossary\n:  definition of terms used within the SCONE technical documentation.\n\n\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "Getting Started"
        },
        {
            "location": "/outline/#getting-started",
            "text": "The simplest way to get started with SCONE is to use it in  simulation  mode.\nIn  simulation mode , you do not need to install any new software on your host - as long as you have already a Docker engine running.\nYou could start by looking at the introduction of the  SCONE CLI .   After that, you could try to compile a simple  hello world  program. For now, we have a light access control to some of the SCONE docker images - like the ones needed for compiling the hello world program. Just send an email with your free  Docker ID  to  info@scontain.com . After gaining access, you can compile the hello world program as shown in the  SCONE Tutorial . You can run the program in simulation mode.  After that,  check out how you could automate the compilation with the help of a  Dockerfile . Next would be to run an example application in a  Swarm .",
            "title": "Getting Started"
        },
        {
            "location": "/outline/#hardware-mode",
            "text": "If you have access to a SGX-capable host, you can, of course, run your programs in Intel SGX enclaves. For ease of use, we create all Docker images used in this tutorial such that applications run inside of enclaves if available. Otherwise, they run in simulation mode, i.e., outside of an enclave but all SCONE software running. When running your software in operations, you would of course force the programs to run only inside of enclaves. We show later how this can be enforced with the help of SCONE remote attestation.  To be able to use hardware mode, programs need access to the SGX device. If your hosts have already a Intel SGX driver installed, you are all set. Otherwise, SCONE can help you to install a lightly patched SGX driver that provides some more monitoring information - like the number of free EPC pages of a host ( SCONE Host Setup ).  If you want to run your programs in containers across multiple hosts with the help of a Docker swarm, you need to give access to the sgx device. Right now, Docker Swarm does not support mapping a device on all hosts. We have a simple patched version that gives access to the sgx device to all containers across all hosts.  SCONE Host Setup  installs this patched Docker engine.  After having installed the SGX driver, you can run different applications inside of enclaves. In addition to  C , C++,  GO , Fortran and Rust (as part of SCONE crosscompiler image  ssconecuratedimages/crosscompilers:scone  ), we also support  Python  and soon Node.js.",
            "title": "Hardware Mode"
        },
        {
            "location": "/outline/#outline",
            "text": "The SCONE platform technical documentation is structured as follows:    SCONE Application-Oriented Security : a short introduction into SCONE's unique security approach.    SCONE Background : a short introduction into why good systems security is difficult to achieve and how SCONE helps to complement systems security.    SCONE CLI : introduces the SCONE command line interface and how to install the SCONE CLI.    SCONE Host Setup : to run secure containers, we need to configure each host to run a Linux SGX driver and also a (for convenience, a patched) Docker engine.    SCONE SGX Toolchain : SCONE supports cross-compilers (C, C++, more to come soon) to compile and build  applications for SGX enclaves.    SCONE Curated Container Images : we will support a set of secure container images to simplify the use of SCONE.    SCONE Tutorial : we show how to compile simple example applications with the help of the SCONE SGX Toolchain.    SCONE Create Image : we show how to create a container image for Docker hub.    SCONE Dockerfile : we support the use of Dockerfiles to generate Docker images that contain services running inside of SGX enclaves (this requires a  patched Docker Engine ).    SCONE Swarm : show how to setup a Docker Swarm usable for SCONE.    SCONE Swarm Example : shows an example of how to start SCONE services on top of a Docker Swarm.    SCONE File Protection : we show how to transparently encrypt or authenticate files in the file system.    GO inside Enclave : shows how to run GO programs inside of enclaves.    Python inside Enclave : shows how to run simple Python applications inside of enclaves.    SCONE Environment variables : short description of the SCONE environment variables.    Publications :  some of the technical aspects of SCONE have been published in scientific papers. We provide a short summary of the papers and links to the pdfs.    Glossary :  definition of terms used within the SCONE technical documentation.    \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Outline"
        },
        {
            "location": "/appsecurity/",
            "text": "Application-Oriented Security\n\n\nSCONE supports developers and \nservice providers\n (i.e., companies operating applications accessible via the Internet)\nto protect the confidentiality and integrity of their applications - even when running in environments that\ncannot be completely trusted. SCONE's focus is on supporting the development of programs running inside of containers like \nmicroservice-based applications\n as well as \ncloud-native applications\n. However, SCONE can protect most programs running on top of Linux.\n\n\n\n\nSCONE supports developers and service providers to ensure end-to-end encryption in the sense that \ndata is always encrypted\n, i.e., while being transmitted,\nwhile being at rest and even while being processed. The latter has only recently become possible with the help of a novel CPU extension by Intel (SGX). To reduce the required computing resources, a service provider can decide what to protect and what not to protect.  For example, a service that operates only on encrypted data might not need to be protected with SGX.\n\n\nOur general recommendation is, however, that developers should protect all parts of an application. The cost of computing resources have been dropping dramatically and hence, the reduction in cost might not be justified when compared with the potential costs - and also loss of reputation - by data breaches. SCONE supports horizontal scalability, i.e., throughput and latency can typically be controlled via the number of instances of a service.\n\n\nEase of Use\n\n\nSCONE supports strong application-oriented security with a workflow like Docker, i.e., SCONE supports \nDockerfiles\n as well as extended Docker \ncompose\n files. This simplifies the construction and operation of applications consisting of a set of containers. This fits, in particular, modern cloud-native applications consisting of microservices and each microservice runs either in a standard or a secure container.\n\n\nThe Docker Engine itself is not protected. The Docker Engine, like the operating system, never sees any plain text data. This facilitates that the Docker Engine or the Docker Swarm can be managed by a cloud provider. SCONE helps a service providers to ensure the confidentiality and integrity of the application data while the cloud provider will ensure the availability of the service. For example, with the help of Docker Swarm, failed containers will automatically be restarted on an appropriate host.\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "Application-oriented security"
        },
        {
            "location": "/appsecurity/#application-oriented-security",
            "text": "SCONE supports developers and  service providers  (i.e., companies operating applications accessible via the Internet)\nto protect the confidentiality and integrity of their applications - even when running in environments that\ncannot be completely trusted. SCONE's focus is on supporting the development of programs running inside of containers like  microservice-based applications  as well as  cloud-native applications . However, SCONE can protect most programs running on top of Linux.   SCONE supports developers and service providers to ensure end-to-end encryption in the sense that  data is always encrypted , i.e., while being transmitted,\nwhile being at rest and even while being processed. The latter has only recently become possible with the help of a novel CPU extension by Intel (SGX). To reduce the required computing resources, a service provider can decide what to protect and what not to protect.  For example, a service that operates only on encrypted data might not need to be protected with SGX.  Our general recommendation is, however, that developers should protect all parts of an application. The cost of computing resources have been dropping dramatically and hence, the reduction in cost might not be justified when compared with the potential costs - and also loss of reputation - by data breaches. SCONE supports horizontal scalability, i.e., throughput and latency can typically be controlled via the number of instances of a service.",
            "title": "Application-Oriented Security"
        },
        {
            "location": "/appsecurity/#ease-of-use",
            "text": "SCONE supports strong application-oriented security with a workflow like Docker, i.e., SCONE supports  Dockerfiles  as well as extended Docker  compose  files. This simplifies the construction and operation of applications consisting of a set of containers. This fits, in particular, modern cloud-native applications consisting of microservices and each microservice runs either in a standard or a secure container.  The Docker Engine itself is not protected. The Docker Engine, like the operating system, never sees any plain text data. This facilitates that the Docker Engine or the Docker Swarm can be managed by a cloud provider. SCONE helps a service providers to ensure the confidentiality and integrity of the application data while the cloud provider will ensure the availability of the service. For example, with the help of Docker Swarm, failed containers will automatically be restarted on an appropriate host.  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Ease of Use"
        },
        {
            "location": "/background/",
            "text": "SCONE Background\n\n\n\n\nCloud Security\n. The objective of SCONE is to help service providers to build secure applications for public, private or hybrid clouds. This means that the focus of SCONE is on application-oriented security and not on the security of the underlying cloud system. Of course, SCONE-based applications benefit from strong security properties of the underlying cloud because this minimizes, for example, the attack surface of SCONE-based applications and by providing higher availability. SCONE helps to ensure the security of an application, i.e., the application's integrity and confidentiality, even if the security of the underlying cloud or system software would be compromised. The security of applications is ensured with the help of Intel SGX enclaves. \n\n\n\n\n\n\n\n\nWorkflow\n. SCONE combines strong security with the ease of use of Docker. SCONE supports a workflow very similar to that of Docker. It supports the construction of applications consisting of multiple containers while ensuring end-to-end encryption between all application components in the sense that all network traffic, all files and even all computation is encrypted. A service provider can ensure the confidentiality and integrity of all application data. In particular, SCONE supports the construction of applications such that no higher privileged software like the operating system or the hypervisor, nor any system administrator with root access nor cold boot attacks can gain access to application data.\n\n\n\n\n\n\n\n\nSide Channel Attacks\n. Side Channel attacks on Intel SGX are the focus of a several recent research papers. First, mounting a successful side-channels is much more difficult than just dumping the memory of an existing application. In SCONE, we provide scheduling within enclaves which makes it more difficult for an attacker to determine which core is executing what function. Moreover, we are working on a compiler extension that will harden applications against side channel attacks. Until will release this extension, a pragmatic solution would be to run applications that might be suceptible to side channel attacks either on \nisolated hosts\n or on \nbaremetal clouds\n.\n\n\n\n\nProblem: Defender's Dilemma\n\n\nTraditionally, one ensures the security of an application by ensuring that the system software, i.e., the hypervisor, operating system and cloud software is trustworthy. This not only protects the integrity and confidentiality of the system data but also protects the security of the applications. A service provider running applications in the cloud must trust all system software and also all administrators who have root or physical access to these systems.\n\n\nA popular way to intrude into a system is to steal the credentials of a system administrator. With these root credentials, one gains access to all data being processed in this system as well as all keys that are kept in main memory or in some plain text files. If stealing credentials would be too difficult, an attacker will look for other ways to attack a system, like, exploiting known code vulnerabilities.\n\n\nFor an attacker, it might be sufficient to exploit a single vulnerability in either the application or the system software to violate the application security. The problem is that the defenders must protect against the exploitation of all code vulnerabilities that might exist in the source code. A service provider might not have access to all source code of the system software that the cloud provider uses to operate the cloud. Even if the source code were available, this will typically be too large to be inspected.\n\n\nTo show that this is a difficult problem, let's look at the number of lines of source code of common system software components. While lines of source code is not an ideal  indicator for the number of vulnerabilities, it gives some indication of the problem we are facing. Some security researchers state that given the current state of the art, only code with up to 10,000s of lines of code can be reasonably inspected. Just the system software itself contains millions of lines of code. This is orders of magnitudes more than we can reasonably expect to be able to inspect.\n\n\nSCONE runs on top of Linux - which contains millions of lines of code and is still growing in size with each release:\n\n\n\n\nLinux Lines of Code (StefanPohl, CC0, \noriginal\n}\n\n\nOpenStack is a popular open source software to manage clouds. OpenStack - despite being relatively young - has been growing dramatically over the years that it has already reached 5 million lines of code (including comments and blank lines):\n\n\n\n\nOpenStack Lines of Code (OpenHub \noriginal\n)\n\n\nTo manage containers, we need an engine like Docker. Docker is younger than OpenStack but has nevertheless reached already more than 180,000 lines of code:\n\n\n\n\nDocker Lines of Code (OpenHub \noriginal\n)\n\n\nCode complexity\n.There is no one-to-one correlation between lines of codes and bugs. Static analysis of open source code repositories indicates approximately 0.61 defects per 1,000 LOC. A recent analysis of Linux shows that, despite an increasing number of defects being fixed, there are always approximately 5,000 defects waiting to be fixed. Not all of these defects can, however, be exploited for security attacks. Another analysis found that approximately 500 security-relevant bugs were fixed in Linux over the past five years - bugs that had been in the kernel for five years before being discovered and fixed. Commercial code had a slightly higher defect density than open source projects. Hence, we need to expect vulnerabilities in commercial software too.\n\n\nSCONE Approach\n\n\nThe approach of SCONE is to partition the code and to place essential components of an application into separate enclaves. Practically, it is quite difficult to split an existing code base of a single process into one component that runs inside an enclave and a component that runs outside of an enclave. However, many modern applications - like cloud-native applications - are already partitioned in several components running in separate address spaces. These components are typically called microservices. This partitioning facilitates a more intelligent scaling of services as well as a scaling of the development team.\n\n\nA large application might consist of a variety of microservices. Not all microservices of an application need to run inside enclaves to protect the application\u2019s integrity and confidentiality. For example, some services might only process encrypted data, like encrypted log data, and do not need to run inside enclaves.  Also, the resource manager does not need to run in an enclave either. However, we recommend that each microservice that has the credential to send requests to at least one microservice running inside an enclave, should itself also run inside of an enclave to restrict the access to enclaved microservices.\n\n\nCurrent SGX-capable CPUs have a limited EPC (Extended Page Cache) size. If the working set of a microservice does not fit inside the EPC, overheads can become high. The usage of microservices supports horizontal scalability. This helps to cope with limited EPC (extended page cache) by spreading secure microservices across different hosts.\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Background"
        },
        {
            "location": "/background/#scone-background",
            "text": "Cloud Security . The objective of SCONE is to help service providers to build secure applications for public, private or hybrid clouds. This means that the focus of SCONE is on application-oriented security and not on the security of the underlying cloud system. Of course, SCONE-based applications benefit from strong security properties of the underlying cloud because this minimizes, for example, the attack surface of SCONE-based applications and by providing higher availability. SCONE helps to ensure the security of an application, i.e., the application's integrity and confidentiality, even if the security of the underlying cloud or system software would be compromised. The security of applications is ensured with the help of Intel SGX enclaves.      Workflow . SCONE combines strong security with the ease of use of Docker. SCONE supports a workflow very similar to that of Docker. It supports the construction of applications consisting of multiple containers while ensuring end-to-end encryption between all application components in the sense that all network traffic, all files and even all computation is encrypted. A service provider can ensure the confidentiality and integrity of all application data. In particular, SCONE supports the construction of applications such that no higher privileged software like the operating system or the hypervisor, nor any system administrator with root access nor cold boot attacks can gain access to application data.     Side Channel Attacks . Side Channel attacks on Intel SGX are the focus of a several recent research papers. First, mounting a successful side-channels is much more difficult than just dumping the memory of an existing application. In SCONE, we provide scheduling within enclaves which makes it more difficult for an attacker to determine which core is executing what function. Moreover, we are working on a compiler extension that will harden applications against side channel attacks. Until will release this extension, a pragmatic solution would be to run applications that might be suceptible to side channel attacks either on  isolated hosts  or on  baremetal clouds .",
            "title": "SCONE Background"
        },
        {
            "location": "/background/#problem-defenders-dilemma",
            "text": "Traditionally, one ensures the security of an application by ensuring that the system software, i.e., the hypervisor, operating system and cloud software is trustworthy. This not only protects the integrity and confidentiality of the system data but also protects the security of the applications. A service provider running applications in the cloud must trust all system software and also all administrators who have root or physical access to these systems.  A popular way to intrude into a system is to steal the credentials of a system administrator. With these root credentials, one gains access to all data being processed in this system as well as all keys that are kept in main memory or in some plain text files. If stealing credentials would be too difficult, an attacker will look for other ways to attack a system, like, exploiting known code vulnerabilities.  For an attacker, it might be sufficient to exploit a single vulnerability in either the application or the system software to violate the application security. The problem is that the defenders must protect against the exploitation of all code vulnerabilities that might exist in the source code. A service provider might not have access to all source code of the system software that the cloud provider uses to operate the cloud. Even if the source code were available, this will typically be too large to be inspected.  To show that this is a difficult problem, let's look at the number of lines of source code of common system software components. While lines of source code is not an ideal  indicator for the number of vulnerabilities, it gives some indication of the problem we are facing. Some security researchers state that given the current state of the art, only code with up to 10,000s of lines of code can be reasonably inspected. Just the system software itself contains millions of lines of code. This is orders of magnitudes more than we can reasonably expect to be able to inspect.  SCONE runs on top of Linux - which contains millions of lines of code and is still growing in size with each release:   Linux Lines of Code (StefanPohl, CC0,  original }  OpenStack is a popular open source software to manage clouds. OpenStack - despite being relatively young - has been growing dramatically over the years that it has already reached 5 million lines of code (including comments and blank lines):   OpenStack Lines of Code (OpenHub  original )  To manage containers, we need an engine like Docker. Docker is younger than OpenStack but has nevertheless reached already more than 180,000 lines of code:   Docker Lines of Code (OpenHub  original )  Code complexity .There is no one-to-one correlation between lines of codes and bugs. Static analysis of open source code repositories indicates approximately 0.61 defects per 1,000 LOC. A recent analysis of Linux shows that, despite an increasing number of defects being fixed, there are always approximately 5,000 defects waiting to be fixed. Not all of these defects can, however, be exploited for security attacks. Another analysis found that approximately 500 security-relevant bugs were fixed in Linux over the past five years - bugs that had been in the kernel for five years before being discovered and fixed. Commercial code had a slightly higher defect density than open source projects. Hence, we need to expect vulnerabilities in commercial software too.",
            "title": "Problem: Defender's Dilemma"
        },
        {
            "location": "/background/#scone-approach",
            "text": "The approach of SCONE is to partition the code and to place essential components of an application into separate enclaves. Practically, it is quite difficult to split an existing code base of a single process into one component that runs inside an enclave and a component that runs outside of an enclave. However, many modern applications - like cloud-native applications - are already partitioned in several components running in separate address spaces. These components are typically called microservices. This partitioning facilitates a more intelligent scaling of services as well as a scaling of the development team.  A large application might consist of a variety of microservices. Not all microservices of an application need to run inside enclaves to protect the application\u2019s integrity and confidentiality. For example, some services might only process encrypted data, like encrypted log data, and do not need to run inside enclaves.  Also, the resource manager does not need to run in an enclave either. However, we recommend that each microservice that has the credential to send requests to at least one microservice running inside an enclave, should itself also run inside of an enclave to restrict the access to enclaved microservices.  Current SGX-capable CPUs have a limited EPC (Extended Page Cache) size. If the working set of a microservice does not fit inside the EPC, overheads can become high. The usage of microservices supports horizontal scalability. This helps to cope with limited EPC (extended page cache) by spreading secure microservices across different hosts.  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "SCONE Approach"
        },
        {
            "location": "/SCONE_CLI/",
            "text": "SCONE CLI\n\n\nWe maintain a single unified command line interface (CLI) \nscone\n that helps to to start and stop secure containers as well as secure applications. \nscone\n also provides functionality to install and monitor SCONE hosts.\n\n\nThe \nscone\n command is structured similar as the \ndocker\n CLI or the \ninfinit\n CLI:\n\n\n\n\nOne needs to specify an \nobject\n (like \nhost\n) and a \ncommand\n (like \ninstall\n) and some options. For some commands, some of the options are actually not optional but mandatory.\n\n\nSee below how to install scone on Ubuntu. Instead of installing \nscone\n in a VM or a host, you could just start it in a container. Assuming\nthat you have docker installed, you try the following examples by running the following container:\n\n\ndocker run -it  sconecuratedimages/sconecli\n\n\n\n\nTo simplify ssh setup, you might want map your ssh configuration into the container. Since you probably have a different user ID inside and outside the container, you might want to copy the original ssh configuration:\n\n\ndocker run -it -v $HOME/.ssh:/root/.xssh  sconecuratedimages/sconecli\n\n\n\n\nInside the container, copy the external ssh configuration:\n\n\ncp -r $HOME/.xssh/* $HOME/.ssh/\n\n\n\n\nNote\n\n\nThe \nscone\n utility requires \nssh\n connectivity to your SGX hosts. See \nSCONE host setup\n for some more\ninformation on how to set up ssh.\n\n\nHelp\n\n\nscone\n has a built in help. To get a list of all \nobjects\n, just type:\n\n\nscone --help\n\n\n\n\nTo get a list of all \ncommands\n for a given \nobject\n (like host), execute:\n\n\nscone host --help\n\n\n\n\nTo get a list of all options for a given \nobject\n and \ncommand\n (e.g., host install) and some examples, just execute:\n\n\nscone host install --help\n\n\n\n\nbash auto-completion\n\n\nIf you are using \nbash\n as your shell, \nscone\n supports auto-completion. This means that instead you can use the \nTAB\n key to see the options. For example,\n\n\nscone <TAB>\n\n\n\n\nwill show all available objects. If you have already specified an object, auto-completion helps you to list all commands:\n\n\nscone host <TAB>\n\n\n\n\nIf you also specified an command, it will provide you with a list of options (that you have not specified yet):\n\n\nscone host install <TAB>\n\n\n\n\nOf course, it also supports auto-completion:\n\n\nscone host install -n<TAB>\n\n\n\n\nwill result in \n\n\nscone host install -name\n\n\n\n\nInstallation of scone\n\n\nOn Ubuntu platform, you can just execute\n\n\ncurl -L https://sconecontainers.github.io/install.sh | bash\n\n\n\n\nYou could alternatively first download the above installation script and store it as file \ninstall.sh\n, inspect it and then run it \n./install.sh\"\n.\n\n\nThe \nscone\n command is located in directory \n/opt/scone/bin/\n. You might want this directory to add this to you \nPATH\n\n\nPATH=/opt/scone/bin/:$PATH\n\n\n\n\nFor convenience, you might want to add above statement to your \n.bashrc\n script (- in case you are using bash).\n\n\nManual installation of SCONE Deb Package\n\n\nYou can execute the following commands (these are the same as in the above installation script):\n\n\nKEYNAME=\"96B9BADB\"\nREPO=\"deb https://sconecontainers.github.io/SCONE ./\"\n\nsudo apt-get update\nsudo apt-get install -y linux-image-extra-$(uname -r) linux-image-extra-virtual\n\nsudo sudo apt-get install -y apt-transport-https ca-certificates\nsudo apt-key adv \\\n  --keyserver hkp://ha.pool.sks-keyservers.net:80 \\\n  --recv-keys $KEYNAME\n\necho $REPO | sudo tee /etc/apt/sources.list.d/scone.list\n\nsudo apt-get clean\nsudo apt-get update\n\napt-cache policy scone\n\nsudo apt-get install -y scone\n\n\n\n\nThe \nscone\n utility will be installed at \n/opt/scone/bin\n. Hence, it makes sense to add this path to your \nPATH\n:\n\n\nexport PATH=/opt/scone/bin:$PATH\n\n\n\n\nYou can then execute some scone commands to see if the installation was successful:\n\n\nscone --version\nscone --help\nscone volume --help\n\n\n\n\nScreencast\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE CLI"
        },
        {
            "location": "/SCONE_CLI/#scone-cli",
            "text": "We maintain a single unified command line interface (CLI)  scone  that helps to to start and stop secure containers as well as secure applications.  scone  also provides functionality to install and monitor SCONE hosts.  The  scone  command is structured similar as the  docker  CLI or the  infinit  CLI:   One needs to specify an  object  (like  host ) and a  command  (like  install ) and some options. For some commands, some of the options are actually not optional but mandatory.  See below how to install scone on Ubuntu. Instead of installing  scone  in a VM or a host, you could just start it in a container. Assuming\nthat you have docker installed, you try the following examples by running the following container:  docker run -it  sconecuratedimages/sconecli  To simplify ssh setup, you might want map your ssh configuration into the container. Since you probably have a different user ID inside and outside the container, you might want to copy the original ssh configuration:  docker run -it -v $HOME/.ssh:/root/.xssh  sconecuratedimages/sconecli  Inside the container, copy the external ssh configuration:  cp -r $HOME/.xssh/* $HOME/.ssh/",
            "title": "SCONE CLI"
        },
        {
            "location": "/SCONE_CLI/#note",
            "text": "The  scone  utility requires  ssh  connectivity to your SGX hosts. See  SCONE host setup  for some more\ninformation on how to set up ssh.",
            "title": "Note"
        },
        {
            "location": "/SCONE_CLI/#help",
            "text": "scone  has a built in help. To get a list of all  objects , just type:  scone --help  To get a list of all  commands  for a given  object  (like host), execute:  scone host --help  To get a list of all options for a given  object  and  command  (e.g., host install) and some examples, just execute:  scone host install --help",
            "title": "Help"
        },
        {
            "location": "/SCONE_CLI/#bash-auto-completion",
            "text": "If you are using  bash  as your shell,  scone  supports auto-completion. This means that instead you can use the  TAB  key to see the options. For example,  scone <TAB>  will show all available objects. If you have already specified an object, auto-completion helps you to list all commands:  scone host <TAB>  If you also specified an command, it will provide you with a list of options (that you have not specified yet):  scone host install <TAB>  Of course, it also supports auto-completion:  scone host install -n<TAB>  will result in   scone host install -name",
            "title": "bash auto-completion"
        },
        {
            "location": "/SCONE_CLI/#installation-of-scone",
            "text": "On Ubuntu platform, you can just execute  curl -L https://sconecontainers.github.io/install.sh | bash  You could alternatively first download the above installation script and store it as file  install.sh , inspect it and then run it  ./install.sh\" .  The  scone  command is located in directory  /opt/scone/bin/ . You might want this directory to add this to you  PATH  PATH=/opt/scone/bin/:$PATH  For convenience, you might want to add above statement to your  .bashrc  script (- in case you are using bash).",
            "title": "Installation of scone"
        },
        {
            "location": "/SCONE_CLI/#manual-installation-of-scone-deb-package",
            "text": "You can execute the following commands (these are the same as in the above installation script):  KEYNAME=\"96B9BADB\"\nREPO=\"deb https://sconecontainers.github.io/SCONE ./\"\n\nsudo apt-get update\nsudo apt-get install -y linux-image-extra-$(uname -r) linux-image-extra-virtual\n\nsudo sudo apt-get install -y apt-transport-https ca-certificates\nsudo apt-key adv \\\n  --keyserver hkp://ha.pool.sks-keyservers.net:80 \\\n  --recv-keys $KEYNAME\n\necho $REPO | sudo tee /etc/apt/sources.list.d/scone.list\n\nsudo apt-get clean\nsudo apt-get update\n\napt-cache policy scone\n\nsudo apt-get install -y scone  The  scone  utility will be installed at  /opt/scone/bin . Hence, it makes sense to add this path to your  PATH :  export PATH=/opt/scone/bin:$PATH  You can then execute some scone commands to see if the installation was successful:  scone --version\nscone --help\nscone volume --help",
            "title": "Manual installation of SCONE Deb Package"
        },
        {
            "location": "/SCONE_CLI/#screencast",
            "text": "\u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Screencast"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/",
            "text": "SCONE: Host Installation Guide\n\n\nThis page describes how\n\n\n\n\n\n\nto set up a host such that it can run SCONE secure containers, i.e., containers in which processes run inside of SGX enclaves, and\n\n\n\n\n\n\nwe remind you of how to set up your \nssh\n configuration to be able to use your scone CLI.\n\n\n\n\n\n\nDuring this setup, we\n\n\n\n\n\n\ninstall a \npatched\n Intel SGX driver - required for better monitoring support,\n\n\n\n\n\n\ninstall a \npatched\n docker engine - to ensure that all containers have access to SGX, and\n\n\n\n\n\n\nstart or join a docker swarm - if requested by command line options.\n\n\n\n\n\n\nPrerequisite\n:\n\n\n\n\n\n\nWe assume that you have set up the \nscone\n \ncommand line interface\n.\nThe \nscone\n CLI can run on your developer machine, a virtual machine or inside a container.\nThe easiest way to get started is to run \nscone\n in a Docker container.\nNo matter where \nscone\n is running, it requires that \nssh\n be properly installed.\n\n\n\n\n\n\nWe recommend to install Ubuntu 17.04 or Ubuntu 17.10 on the Swarm machines. For older versions of Ubuntu, some minor manual fixing might be needed during installation of the SGX drivers and the Docker engine. The screencast below shows some of the issues one faces on older Ubuntu versions. The secure containers are mostly based on Ubuntu or Alpine Linux (smaller image size).\n\n\n\n\n\n\nNOTE\n This host setup will enable the execution of \nSCONE secure containers\n on SGX-enabled machines. These containers can run one or more \nsecure programs\n, i.e., programs that are executed inside SGX enclaves.   The secure programs of secure containers can be statically-linked or dynamically-linked (see \nSCONE SGX Toolchain\n). The host itself runs statically-linked secure programs only - this is to avoid failures do to library versioning issues.\n\n\nSSH\n\n\nThe \nscone\n utility executes commands via \nssh\n on the SGX-capable machine that should be installed.\n\n\n\n\nSince we potentially execute many \nssh\n commands, you need to configure \nssh\n such that\n\n\n\n\n\n\nyou can log into the SGX machines \nwithout\n  having to type a password,\n\n\n\n\n\n\nyou can use the basename of your SGX machines to log in , and\n\n\n\n\n\n\nssh is permitted to reuse connections to reduce the execution time of the \nscone\n commands.\n\n\n\n\n\n\nPasswordless ssh\n\n\nTo set up passwordless ssh authentication, you need to ensure that you have a pair of authentication keys. If there exists no public key \n$HOME/.ssh/id_rsa.pub\n (often the case if you use a container), you can generate a new pair by executing:\n\n\nssh-keygen -b 4096 -t rsa\n\n\n\n\nAppend the generated public key \n$HOME/.ssh/id_rsa.pub\n to file \n$HOME/.ssh/authorized_keys\n on the SGX hosts for which you to be able to log in without a password.\n\n\nAdditionally, you need to start a ssh-agent (on your developer machine):\n\n\nSA=`ssh-agent`\neval \"$SA\"\n\n\n\n\nand add your authentication keys by executing:\n\n\nssh-add\n\n\n\n\nHost alias\n\n\nTo reduce your typing overhead, you can use the basename of a host - if you configure ssh appropriately. For example, instead of typing \nnode2.my.very.long.domain.com\n, you could configure  \nssh\n such that \nnode2\n refers to \nnode2.my.very.long.domain.com\n.\n\n\nAs a caveat, this basename must be sufficient for other hosts in the \nsame swarm\n to reach \nnode2\n. In the above figure, \nmanager\n must be able to resolve \nnode2\n to the IP address of \nnode2.my.very.long.domain.com\n.\n\n\nTo add an alias for \nnode2.my.very.long.domain.com\n, you could add the following lines to your \nssh config\n (stored in \n$HOME/.ssh/config\n):\n\n\nHost node2\n     HostName node2.my.very.long.domain.com\n     Port 22\n     User scone\n     IdentityFile ~/.ssh/id_rsa\n\n\n\n\nssh connection reuse\n\n\nTo be able to reuse a ssh connection, you must configure ssh appropriately. You should set \nControlMaster\n to \nauto\n and you have to specify a control path via option \nControlPath\n. You can define a generic path like \n~/.ssh/ssh_mux_%h_%p_%r\n - this can be the same for all hosts. For example, for some host \nalice\n you might add the following lines to \n$HOME/.ssh/config\n:\n\n\nHost alice\n        ControlMaster auto\n        ControlPath ~/.ssh/ssh_mux_%h_%p_%r\n        user ubuntu\n        port 10101\n        hostname sshproxy.cloudprovider.com\n\n\n\n\nInstallation of a single host\n\n\nAfter you set up the \nscone CLI\n and your passwordless ssh works, you can install the scone related software on a new host, say, \nalice\n as follows:\n\n\nscone host install --name alice\n\n\n\n\nTo verify that a host is properly installed for SCONE and contains the newest patched Docker engine and SGX driver, just execute:\n\n\nscone host check --name alice\n\n\n\n\nThis command will issue an error unless the newest versions of the patched Docker engine and the patched SGX driver is installed.\n\n\nInstallation of a swarm\n\n\nFor a set of hosts to form a (Docker) swarm, you need to decide which hosts should be managers and which should be just members of the swarm. Say, you decided that \nalice\n and \nbob\n should be managers but \ncaroline\n a non-manager, execute the following:\n\n\nscone host install --name alice --as-manager\nscone host install --name bob --as-manager --join alice\nscone host install --name caroline  --join alice\n\n\n\n\nNote that the hosts must be able to communicate with each other (i.e., not partitioned through firewalls). Docker recommends/expects  that they will be in the same local area network.\n\n\nChecking your Installation\n\n\nTo test the installation, one can run a simple hello-world container:\n\n\nsudo docker run hello-world\n\n\n\n\nBackground Information\n\n\nPatched Docker Engine (Moby)\n\n\nFor an container to be able to use SGX, it has to have access to a device (/dev/isgx). This device permits the container to talk to the SGX driver. This driver is needed, in particular, to create SGX enclaves. \n\n\nSome docker commands (like \ndocker run\n) support an option --device (i.e., \n--device /dev/isgx\n) which allows us to give a container access to the SGX device. We need to point out that some docker commands (like \ndocker build\n) do, however, not yet support the device option. Therefore, we maintain and install a slightly patched docker engine (i.e., a variant of moby): this engine ensures that each container has access to the SGX device (/dev/isgx).  With the help of this patched engine, we can use Dockerfiles to generate container images (see this \nTutorial\n).\n\n\nRight now we provide a patched version of the currently active branch of Moby (a.k.a., the Docker engine): 17.05.0-ce, build 89658be (November 11, 2017).\n\n\nPatched SGX Driver\n\n\nWe also maintain a patched version of the SGX driver. This version adds some additional monitoring like the number of \navailable\n and \nfree\n EPC (Extended Page Cache) pages.\n\n\nRight now, we provide a patched version of the latest Intel SGX driver (November 11, 2017).\n\n\nScreencast\n\n\nThis screencast shows the installation of three machines SGX-capable hosts. In this screencast, we show the installation on machines that run older versions of Ubuntu (sgx2 = 14.04, sgx3 = 14.04 with custom kernel, and sgx4 = 16.04). In this case, we will see some warnings since \nscone host\n depends on \nsystemd\n to start the swarm. In case \nsystemd\n is not available, \nscone host\n will still be able to install the patched SGX driver and the patched Docker engine.\n\n\nAnother issue that one sometimes faces is that an older SGX drivers is already installed but cannot be offloaded and replaced by the patched driver by \nscone host\n. The reason for that is that typically that some process is still using the \n/dev/isgx\n device. This needs to be manually fixed by stopping the process or by rebooting the machine. Alternatively, one can use the existing SGX driver. However, the monitoring of the used EPC pages will not be provided in this case.\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Host Setup"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#scone-host-installation-guide",
            "text": "This page describes how    to set up a host such that it can run SCONE secure containers, i.e., containers in which processes run inside of SGX enclaves, and    we remind you of how to set up your  ssh  configuration to be able to use your scone CLI.    During this setup, we    install a  patched  Intel SGX driver - required for better monitoring support,    install a  patched  docker engine - to ensure that all containers have access to SGX, and    start or join a docker swarm - if requested by command line options.    Prerequisite :    We assume that you have set up the  scone   command line interface .\nThe  scone  CLI can run on your developer machine, a virtual machine or inside a container.\nThe easiest way to get started is to run  scone  in a Docker container.\nNo matter where  scone  is running, it requires that  ssh  be properly installed.    We recommend to install Ubuntu 17.04 or Ubuntu 17.10 on the Swarm machines. For older versions of Ubuntu, some minor manual fixing might be needed during installation of the SGX drivers and the Docker engine. The screencast below shows some of the issues one faces on older Ubuntu versions. The secure containers are mostly based on Ubuntu or Alpine Linux (smaller image size).    NOTE  This host setup will enable the execution of  SCONE secure containers  on SGX-enabled machines. These containers can run one or more  secure programs , i.e., programs that are executed inside SGX enclaves.   The secure programs of secure containers can be statically-linked or dynamically-linked (see  SCONE SGX Toolchain ). The host itself runs statically-linked secure programs only - this is to avoid failures do to library versioning issues.",
            "title": "SCONE: Host Installation Guide"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#ssh",
            "text": "The  scone  utility executes commands via  ssh  on the SGX-capable machine that should be installed.   Since we potentially execute many  ssh  commands, you need to configure  ssh  such that    you can log into the SGX machines  without   having to type a password,    you can use the basename of your SGX machines to log in , and    ssh is permitted to reuse connections to reduce the execution time of the  scone  commands.    Passwordless ssh  To set up passwordless ssh authentication, you need to ensure that you have a pair of authentication keys. If there exists no public key  $HOME/.ssh/id_rsa.pub  (often the case if you use a container), you can generate a new pair by executing:  ssh-keygen -b 4096 -t rsa  Append the generated public key  $HOME/.ssh/id_rsa.pub  to file  $HOME/.ssh/authorized_keys  on the SGX hosts for which you to be able to log in without a password.  Additionally, you need to start a ssh-agent (on your developer machine):  SA=`ssh-agent`\neval \"$SA\"  and add your authentication keys by executing:  ssh-add  Host alias  To reduce your typing overhead, you can use the basename of a host - if you configure ssh appropriately. For example, instead of typing  node2.my.very.long.domain.com , you could configure   ssh  such that  node2  refers to  node2.my.very.long.domain.com .  As a caveat, this basename must be sufficient for other hosts in the  same swarm  to reach  node2 . In the above figure,  manager  must be able to resolve  node2  to the IP address of  node2.my.very.long.domain.com .  To add an alias for  node2.my.very.long.domain.com , you could add the following lines to your  ssh config  (stored in  $HOME/.ssh/config ):  Host node2\n     HostName node2.my.very.long.domain.com\n     Port 22\n     User scone\n     IdentityFile ~/.ssh/id_rsa  ssh connection reuse  To be able to reuse a ssh connection, you must configure ssh appropriately. You should set  ControlMaster  to  auto  and you have to specify a control path via option  ControlPath . You can define a generic path like  ~/.ssh/ssh_mux_%h_%p_%r  - this can be the same for all hosts. For example, for some host  alice  you might add the following lines to  $HOME/.ssh/config :  Host alice\n        ControlMaster auto\n        ControlPath ~/.ssh/ssh_mux_%h_%p_%r\n        user ubuntu\n        port 10101\n        hostname sshproxy.cloudprovider.com",
            "title": "SSH"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#installation-of-a-single-host",
            "text": "After you set up the  scone CLI  and your passwordless ssh works, you can install the scone related software on a new host, say,  alice  as follows:  scone host install --name alice  To verify that a host is properly installed for SCONE and contains the newest patched Docker engine and SGX driver, just execute:  scone host check --name alice  This command will issue an error unless the newest versions of the patched Docker engine and the patched SGX driver is installed.",
            "title": "Installation of a single host"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#installation-of-a-swarm",
            "text": "For a set of hosts to form a (Docker) swarm, you need to decide which hosts should be managers and which should be just members of the swarm. Say, you decided that  alice  and  bob  should be managers but  caroline  a non-manager, execute the following:  scone host install --name alice --as-manager\nscone host install --name bob --as-manager --join alice\nscone host install --name caroline  --join alice  Note that the hosts must be able to communicate with each other (i.e., not partitioned through firewalls). Docker recommends/expects  that they will be in the same local area network.  Checking your Installation  To test the installation, one can run a simple hello-world container:  sudo docker run hello-world",
            "title": "Installation of a swarm"
        },
        {
            "location": "/SCONE_HOSTINSTALLER_README/#background-information",
            "text": "Patched Docker Engine (Moby)  For an container to be able to use SGX, it has to have access to a device (/dev/isgx). This device permits the container to talk to the SGX driver. This driver is needed, in particular, to create SGX enclaves.   Some docker commands (like  docker run ) support an option --device (i.e.,  --device /dev/isgx ) which allows us to give a container access to the SGX device. We need to point out that some docker commands (like  docker build ) do, however, not yet support the device option. Therefore, we maintain and install a slightly patched docker engine (i.e., a variant of moby): this engine ensures that each container has access to the SGX device (/dev/isgx).  With the help of this patched engine, we can use Dockerfiles to generate container images (see this  Tutorial ).  Right now we provide a patched version of the currently active branch of Moby (a.k.a., the Docker engine): 17.05.0-ce, build 89658be (November 11, 2017).  Patched SGX Driver  We also maintain a patched version of the SGX driver. This version adds some additional monitoring like the number of  available  and  free  EPC (Extended Page Cache) pages.  Right now, we provide a patched version of the latest Intel SGX driver (November 11, 2017).  Screencast  This screencast shows the installation of three machines SGX-capable hosts. In this screencast, we show the installation on machines that run older versions of Ubuntu (sgx2 = 14.04, sgx3 = 14.04 with custom kernel, and sgx4 = 16.04). In this case, we will see some warnings since  scone host  depends on  systemd  to start the swarm. In case  systemd  is not available,  scone host  will still be able to install the patched SGX driver and the patched Docker engine.  Another issue that one sometimes faces is that an older SGX drivers is already installed but cannot be offloaded and replaced by the patched driver by  scone host . The reason for that is that typically that some process is still using the  /dev/isgx  device. This needs to be manually fixed by stopping the process or by rebooting the machine. Alternatively, one can use the existing SGX driver. However, the monitoring of the used EPC pages will not be provided in this case.   \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Background Information"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/",
            "text": "SCONE SGX Toolchain\n\n\nSCONE comes with compiler support for popular languages: C, C++, GO, Rust as well as Fortran.\nThe objective of these (cross-) compilers are to compile applications - generally without source code changes - such that they can run inside of SGX enclaves.\n\n\nTo simplify the use of these (cross-) compilers, SCONE maintains curated container image that includes these cross-compilers.\n\n\nCompiler variants\n\n\nDepending on if you want to generate a \ndynamically-linked\n or a \nstatically-linked\n binary, you\ncan use a standard compiler (dynamic) or you need to use a cross compiler (static). The compiler can run on any system, i.e., does not require SGX to run. To generate a statically-linked binary, you need to run on a SGX-enabled machine (for now).\n\n\nNote\n Independently, if you use a dynamic or static linking, the hash of an enclave (MRENCLAVE) will encompass the whole code, i.e., includes all libraries. Any updates of a library on your host might prevent the execution of a SCONE binary because of a wrong MRENCLAVE. Hence, we recommend to use only statically-linked programs on the host. In containers, which have a more controlled environment, we support both statically as well as dynamically linked binaries. The main advantage of dynamic linking is that for many programs we do not change the build process when moved to SCONE.\n\n\nNote\n also that SCONE supports the loading of dynamic libraries after a program has already started inside of an enclave. This feature is required by modern languages like Java. Enabling general loading of dynamic library introduces the risk that one could load malicious code inside of an enclave. Hence, we switch this feature off by default. For debugging programs, you can enable this feature via an environment variable (\nexport SCONE_ALLOW_DLOPEN=2).\n For production enclaves, you will need to protect the integrity of the shared libraries with the help of the \nSCONE file shield\n.\n\n\nDynamically-Linked Binaries\n\n\nThe easiest to get started is to compile your programs such that\n\n\n\n\n\n\nthe generated code is position independent (\n-fPIC\n),\n\n\n\n\n\n\nthe thread local storage model is global-dynamic (\n-ftls-model=global-dynamic\n),\n\n\n\n\n\n\nyour binary is dynamically linked (i.e., do not use \n-static\n), and\n\n\n\n\n\n\nlink against musl as your libc (i.e., not glibc or any other libc).\n\n\n\n\n\n\n\n\nWhen a program is started, SCONE uses its own dynamic link loader to replace libc by a SCONE libc. The SCONE dynamic linker will load the program inside a new SGX enclave and SCONE libc will enable programs to run inside the SGX enclaves, e.g., execute system calls and protect them from attacks via shields like the \nfile system shield\n.\n\n\nTo simplify the compiling of your programs for scone, we make available a docker image \nsconecuratedimages/muslgcc\n which includes \ngcc\n and \ng++\n support. The options will by default be set as shown above. You need, however, to make sure that your Makefiles will not overwrite these options.\n\n\nStatically-Linked Binaries\n\n\nFor statically linked binaries, we make available a (private) docker image \nsconecuratedimages/crosscompilers:scone\n which can produce statically linked binaries. In the statically linked binaries, we replace the interface to the operating system (i.e., libc) by a variant that enables programs to run inside Intel SGX enclaves.\n\n\n\n\nNote that a statically linked binaries might look like a dynamically-linked binary. For example, if you look at a statically-linked program \nweb-srv-go\n, you will still see dynamic dependencies:\n\n\nldd web-srv-go \n    linux-vdso.so.1 =>  (0x00007ffe423fd000)\n    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007effa344f000)\n    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007effa3085000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007effa366c000)\n\n\n\n\nThe reason for that is that the statically linked binary that runs inside of an enclave is wrapped in a dynamically linked \nloader\n program. The loader program creates the enclave, moves the program code inside the enclave and starts threads that will enter the enclave. The code that is moved inside the enclave is, however, statically linked.\n\n\nUsing the cross compiler container\n\n\nHow to use the compiler:\n\n\n\n\n\n\nuse this as a base image and build your programs inside of a container we a  \nDockerfile\n), or\n\n\n\n\n\n\nmap volumes such that the compiler can compile files living outside the container (see \nSCONE Tutorial\n).\n\n\n\n\n\n\nFor an example how to use the crosscompilers, see how to compile a programs written in \nGO\n.\n\n\nExample\n\n\nNote\n  on some systems you will need to run \ndocker\n with root permissions, i.e., in this case you should prefix a \n\n\ndocker ...\n\n\n\n\ncommand with \nsudo\n, i.e., you execute \n\n\nsudo docker ...\n\n\n\n\nOne can run the above compiler inside of a container while the compiled files reside outside the container. Say, your code is\nin file \nmyapp.c\n in your current directory (\n$PWD\n). You can compile this code as follows:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc myapp.c\n\n\n\n\nThis call will generate a binary \na.out\n in your working directory. This binary is dynamically linked against musl:\n\n\n# ldd a.out \n    /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)\n    libc.musl-x86_64.so.1 => /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)\n\n\n\n\nThis binary can run natively only if you have musl installed at the correct position in your development machine (and your development machine runs Linux). Alternatively, you can run the binary in a container:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc ./a.out\n\n\n\n\nTo run this inside of SGX enclaves with SCONE, you need access to the SCONE runtime systems. For more details, see our \nhello world\n in Section \nSCONE Tutorial\n. This is not very convenient and hence, we provide a) a simpler version with the help of \nDockerfiles\n. \n\n\nIn most cases, you might just set to use one of our crosscompilers in your \nconfigure\n script or \nMakefile\n. A simple way is to use the Docker image \nsconecuratedimages/crosscompilers:scone\n as a base image and then clone your code inside the container and set one or more of our compilers (\nscone-gcc, scone-g++, scone-gccgo, scone-gfortran, and scone-rustc\n) to be used in your build. For Rust, we support also our variant of \ncargo\n which is \nscone-cargo\n.\n\n\nDebugger support\n\n\nWe also support \ngdb\n to debug applications running inside of enclaves. To get started, we recommend that you first ensure that your program runs natively linked against musl. Most programs will do - after all, the Alpine Linux distribution is completely based on musl. The debugger is available in image \nsconecuratedimages/crosscompilers:scone\n as \nscone-gdb\n.\n\n\nFor example on how to use the debugger, see how to debug a program written in  \nGO\n.\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE SGX toolchain"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#scone-sgx-toolchain",
            "text": "SCONE comes with compiler support for popular languages: C, C++, GO, Rust as well as Fortran.\nThe objective of these (cross-) compilers are to compile applications - generally without source code changes - such that they can run inside of SGX enclaves.  To simplify the use of these (cross-) compilers, SCONE maintains curated container image that includes these cross-compilers.",
            "title": "SCONE SGX Toolchain"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#compiler-variants",
            "text": "Depending on if you want to generate a  dynamically-linked  or a  statically-linked  binary, you\ncan use a standard compiler (dynamic) or you need to use a cross compiler (static). The compiler can run on any system, i.e., does not require SGX to run. To generate a statically-linked binary, you need to run on a SGX-enabled machine (for now).  Note  Independently, if you use a dynamic or static linking, the hash of an enclave (MRENCLAVE) will encompass the whole code, i.e., includes all libraries. Any updates of a library on your host might prevent the execution of a SCONE binary because of a wrong MRENCLAVE. Hence, we recommend to use only statically-linked programs on the host. In containers, which have a more controlled environment, we support both statically as well as dynamically linked binaries. The main advantage of dynamic linking is that for many programs we do not change the build process when moved to SCONE.  Note  also that SCONE supports the loading of dynamic libraries after a program has already started inside of an enclave. This feature is required by modern languages like Java. Enabling general loading of dynamic library introduces the risk that one could load malicious code inside of an enclave. Hence, we switch this feature off by default. For debugging programs, you can enable this feature via an environment variable ( export SCONE_ALLOW_DLOPEN=2).  For production enclaves, you will need to protect the integrity of the shared libraries with the help of the  SCONE file shield .  Dynamically-Linked Binaries  The easiest to get started is to compile your programs such that    the generated code is position independent ( -fPIC ),    the thread local storage model is global-dynamic ( -ftls-model=global-dynamic ),    your binary is dynamically linked (i.e., do not use  -static ), and    link against musl as your libc (i.e., not glibc or any other libc).     When a program is started, SCONE uses its own dynamic link loader to replace libc by a SCONE libc. The SCONE dynamic linker will load the program inside a new SGX enclave and SCONE libc will enable programs to run inside the SGX enclaves, e.g., execute system calls and protect them from attacks via shields like the  file system shield .  To simplify the compiling of your programs for scone, we make available a docker image  sconecuratedimages/muslgcc  which includes  gcc  and  g++  support. The options will by default be set as shown above. You need, however, to make sure that your Makefiles will not overwrite these options.  Statically-Linked Binaries  For statically linked binaries, we make available a (private) docker image  sconecuratedimages/crosscompilers:scone  which can produce statically linked binaries. In the statically linked binaries, we replace the interface to the operating system (i.e., libc) by a variant that enables programs to run inside Intel SGX enclaves.   Note that a statically linked binaries might look like a dynamically-linked binary. For example, if you look at a statically-linked program  web-srv-go , you will still see dynamic dependencies:  ldd web-srv-go \n    linux-vdso.so.1 =>  (0x00007ffe423fd000)\n    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007effa344f000)\n    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007effa3085000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007effa366c000)  The reason for that is that the statically linked binary that runs inside of an enclave is wrapped in a dynamically linked  loader  program. The loader program creates the enclave, moves the program code inside the enclave and starts threads that will enter the enclave. The code that is moved inside the enclave is, however, statically linked.",
            "title": "Compiler variants"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#using-the-cross-compiler-container",
            "text": "How to use the compiler:    use this as a base image and build your programs inside of a container we a   Dockerfile ), or    map volumes such that the compiler can compile files living outside the container (see  SCONE Tutorial ).    For an example how to use the crosscompilers, see how to compile a programs written in  GO .",
            "title": "Using the cross compiler container"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#example",
            "text": "Note   on some systems you will need to run  docker  with root permissions, i.e., in this case you should prefix a   docker ...  command with  sudo , i.e., you execute   sudo docker ...  One can run the above compiler inside of a container while the compiled files reside outside the container. Say, your code is\nin file  myapp.c  in your current directory ( $PWD ). You can compile this code as follows:  docker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc myapp.c  This call will generate a binary  a.out  in your working directory. This binary is dynamically linked against musl:  # ldd a.out \n    /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)\n    libc.musl-x86_64.so.1 => /lib/ld-musl-x86_64.so.1 (0x7fb0379f9000)  This binary can run natively only if you have musl installed at the correct position in your development machine (and your development machine runs Linux). Alternatively, you can run the binary in a container:  docker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc ./a.out  To run this inside of SGX enclaves with SCONE, you need access to the SCONE runtime systems. For more details, see our  hello world  in Section  SCONE Tutorial . This is not very convenient and hence, we provide a) a simpler version with the help of  Dockerfiles .   In most cases, you might just set to use one of our crosscompilers in your  configure  script or  Makefile . A simple way is to use the Docker image  sconecuratedimages/crosscompilers:scone  as a base image and then clone your code inside the container and set one or more of our compilers ( scone-gcc, scone-g++, scone-gccgo, scone-gfortran, and scone-rustc ) to be used in your build. For Rust, we support also our variant of  cargo  which is  scone-cargo .",
            "title": "Example"
        },
        {
            "location": "/SCONE_COMPILER_CONTAINER_README/#debugger-support",
            "text": "We also support  gdb  to debug applications running inside of enclaves. To get started, we recommend that you first ensure that your program runs natively linked against musl. Most programs will do - after all, the Alpine Linux distribution is completely based on musl. The debugger is available in image  sconecuratedimages/crosscompilers:scone  as  scone-gdb .  For example on how to use the debugger, see how to debug a program written in   GO .  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Debugger support"
        },
        {
            "location": "/SCONE_Curated_Images/",
            "text": "SCONE Curated Images\n\n\nWe provide a set of curated SCONE container images on a (partially private) repositories on Docker hub:\n\n\n Private images:\n (i.e., you need to send me email to get access)\n\n\n\n\nsconecuratedimages/crosscompilers:scone\n: a container image with all the SCONE crosscompilers.\n\n\nsconecuratedimages/crosscompilers:runtime\n: a container image that can run dynamically linked applications inside of an enclave.\n\n\nsconecuratedimages/crosscompilers:python27\n: a container image including a \npython interpreter\n running inside of an enclave.\n\n\n\n\nsconecuratedimages/crosscompilers:node-4.8.6\n: a container image for \nnode\n running inside an enclave.\n\n\n\n\n\n\nsconecuratedimages/helloworld: a simple hello world example that runs inside of an enclave.\n\n\n\n\n\n\n Public images:\n\n\n\n\nsconecuratedimages/muslgcc\n: public container image to compile programs ready to be used by SCONE\n\n\nsconecuratedimages/tutorial\n: contains container images related to our SCONE tutorial\n\n\nsconecuratedimages/sconedocu\n: public container image containing a copy of the SCONE documentation\n\n\n\n\nScone Documentation\n\n\nTo run a local copy of the SCONE documentation, just perform the following steps:\n\n\ndocker pull sconecuratedimages/sconedocu\ndocker run -d -p 8080:80  sconecuratedimages/sconedocu\n\n\n\n\nView the documentation in your browser at http://127.0.0.1:8080 .\nOn a MAC, just type:\n\n\nopen http://127.0.0.1:8080\n\n\n\n\nto view this docu.\n\n\nLogin in\n\n\nAccess to some SCONE images is still restricted. First, get access\nto the private images by sending email to scontain.ceo@gmail.com. \nSecond, log into to docker hub via:\n\n\ndocker login\n\n\n\n\nbefore you will be able to pull any of the private curated images.\n\n\nScone Compilers\n\n\nTo run a local copy of the SCONE (cross-)compilers, just pull the appropriate image on your computer.\n\n\nDynamically-Linked Binaries\n\n\nEven if you have no SGX CPU extension / no SGX driver installed on your computer,\nyou can use a standard gcc compiler - as long as the requirements mentioned in \nSGX ToolChain\n are satisfied.\n\n\ndocker pull sconecuratedimages/muslgcc\n\n\n\n\nNote that the binaries generated with the above image are just native binaries, i.e., they run \noutside of enclaves\n. To be able to run the binary inside of an enclave, you need to have installed the SCONE runtime library.\n\n\nTo run a dynamically-linked binary, one needs a special runtime environment. We provide this in form of a (private) container image:\n\n\ndocker pull sconecuratedimages/crosscompilers:runtime\n\n\n\n\nStatically-Linked Binaries\n\n\nTo generate statically-linked secure binaries you need a cross compiler. You can pull\nthis image from Docker hub (you need to be granted access rights for that):\n\n\ndocker pull sconecuratedimages/crosscompilers:scone\n\n\n\n\nScone Hello World\n\n\nYou can pull the following (private) image:\n\n\ndocker pull sconecuratedimages/helloworld\n\n\n\n\nIf you installed the patched Docker engine (see \nSCONE Host Setup\n), run the helloworld program inside of an enclave via\n\n\ndocker run sconecuratedimages/helloworld\nHello World\n\n\n\n\nThis command will fail in case you have the standard Docker engine installed:\n\n\n> sudo docker run sconecuratedimages/helloworld\nerror opening sgx device: No such file or directory\n\n\n\n\nYou can run on the standard Docker engine - if you have the SGX driver installed:\n\n\ndocker run --device=/dev/isgx sconecuratedimages/helloworld\nHello World\n\n\n\n\nIf you do not have the SGX driver installed, you get an error message:\n\n\ndocker run --device=/dev/isgx sconecuratedimages/helloworld\ndocker: Error response from daemon: linux runtime spec devices: error gathering device information while adding custom device \"/dev/isgx\": no such file or directory.\n\n\n\n\nIn this case, install the SGX driver and the patched Docker engine as described in\n\nSCONE Host Setup\n. This installation will fail in case you disabled SGX in the BIOS or your CPU is not SGX-enabled.\n\n\nScreencast\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Curated Images"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-curated-images",
            "text": "We provide a set of curated SCONE container images on a (partially private) repositories on Docker hub:   Private images:  (i.e., you need to send me email to get access)   sconecuratedimages/crosscompilers:scone : a container image with all the SCONE crosscompilers.  sconecuratedimages/crosscompilers:runtime : a container image that can run dynamically linked applications inside of an enclave.  sconecuratedimages/crosscompilers:python27 : a container image including a  python interpreter  running inside of an enclave.   sconecuratedimages/crosscompilers:node-4.8.6 : a container image for  node  running inside an enclave.    sconecuratedimages/helloworld: a simple hello world example that runs inside of an enclave.     Public images:   sconecuratedimages/muslgcc : public container image to compile programs ready to be used by SCONE  sconecuratedimages/tutorial : contains container images related to our SCONE tutorial  sconecuratedimages/sconedocu : public container image containing a copy of the SCONE documentation",
            "title": "SCONE Curated Images"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-documentation",
            "text": "To run a local copy of the SCONE documentation, just perform the following steps:  docker pull sconecuratedimages/sconedocu\ndocker run -d -p 8080:80  sconecuratedimages/sconedocu  View the documentation in your browser at http://127.0.0.1:8080 .\nOn a MAC, just type:  open http://127.0.0.1:8080  to view this docu.",
            "title": "Scone Documentation"
        },
        {
            "location": "/SCONE_Curated_Images/#login-in",
            "text": "Access to some SCONE images is still restricted. First, get access\nto the private images by sending email to scontain.ceo@gmail.com. \nSecond, log into to docker hub via:  docker login  before you will be able to pull any of the private curated images.",
            "title": "Login in"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-compilers",
            "text": "To run a local copy of the SCONE (cross-)compilers, just pull the appropriate image on your computer.",
            "title": "Scone Compilers"
        },
        {
            "location": "/SCONE_Curated_Images/#dynamically-linked-binaries",
            "text": "Even if you have no SGX CPU extension / no SGX driver installed on your computer,\nyou can use a standard gcc compiler - as long as the requirements mentioned in  SGX ToolChain  are satisfied.  docker pull sconecuratedimages/muslgcc  Note that the binaries generated with the above image are just native binaries, i.e., they run  outside of enclaves . To be able to run the binary inside of an enclave, you need to have installed the SCONE runtime library.  To run a dynamically-linked binary, one needs a special runtime environment. We provide this in form of a (private) container image:  docker pull sconecuratedimages/crosscompilers:runtime",
            "title": "Dynamically-Linked Binaries"
        },
        {
            "location": "/SCONE_Curated_Images/#statically-linked-binaries",
            "text": "To generate statically-linked secure binaries you need a cross compiler. You can pull\nthis image from Docker hub (you need to be granted access rights for that):  docker pull sconecuratedimages/crosscompilers:scone",
            "title": "Statically-Linked Binaries"
        },
        {
            "location": "/SCONE_Curated_Images/#scone-hello-world",
            "text": "You can pull the following (private) image:  docker pull sconecuratedimages/helloworld  If you installed the patched Docker engine (see  SCONE Host Setup ), run the helloworld program inside of an enclave via  docker run sconecuratedimages/helloworld\nHello World  This command will fail in case you have the standard Docker engine installed:  > sudo docker run sconecuratedimages/helloworld\nerror opening sgx device: No such file or directory  You can run on the standard Docker engine - if you have the SGX driver installed:  docker run --device=/dev/isgx sconecuratedimages/helloworld\nHello World  If you do not have the SGX driver installed, you get an error message:  docker run --device=/dev/isgx sconecuratedimages/helloworld\ndocker: Error response from daemon: linux runtime spec devices: error gathering device information while adding custom device \"/dev/isgx\": no such file or directory.  In this case, install the SGX driver and the patched Docker engine as described in SCONE Host Setup . This installation will fail in case you disabled SGX in the BIOS or your CPU is not SGX-enabled.",
            "title": "Scone Hello World"
        },
        {
            "location": "/SCONE_Curated_Images/#screencast",
            "text": "\u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Screencast"
        },
        {
            "location": "/SCONE_TUTORIAL/",
            "text": "SCONE Tutorial\n\n\nPrerequisites\n\n\nEnsure that the SGX driver is installed\n\n\nCheck on the host as well as inside your containers that the SGX device \n/dev/isgx\n is visible:\n\n\nls /dev/isgx \n/dev/isgx\n\n\n\n\nIf the driver is not installed, read Section \nSCONE Host Setup\n to learn how to install the SGX driver.\n\n\nChecking availability of SGX device inside of containers\n\n\nSometimes, Docker does not automatically map the SGX device inside of containers. We provide a patched Docker engine and a patched SGX driver that together permit to automatically open the sgx device inside of containers.\n\n\nIf your node is part of a Docker swarm, we provide a simple check as part of the \nscone CLI\n. Say, the leader node of your swarm  is called \nbeatrix\n, then you could just execute:\n\n\nscone swarm check --verbose --manager beatrix\n\n\n\n\nIn case your node is not part of a Docker swarm, you can run the checks manually. For that, we provide a container image\nthat helps to check if the SGX device can be accessed from inside a container. Just execute the following commands to check if your containers have access to the SGX device:\n\n\n# preferred alternative: required for swarms to work: SGX device is available in all containers by default\nsudo docker run --rm sconecuratedimages/checksgx || echo \"SGX device is not automatically mapped inside of container\"\n# alternative: use --device option without --privileged flag\nsudo docker run --device=/dev/isgx --rm sconecuratedimages/checksgx || echo \"--device=/dev/isgx: not sufficient to access SGX device inside of container\"\n# last alternative: use --device option without --privileged flag\nsudo docker run -v /dev/isgx:/dev/isgx --privileged  --rm sconecuratedimages/checksgx || echo \"SGX device NOT available inside of container\"\n\n\n\n\nUse the first alternative that works in your installation to give containers access to the SGX device.\n\n\nInstall sgxmusl cross compiler image\n\n\nEnsure that you installed the various sconecuratedimages/crosscompilers container image:\n\n\ndocker image ls sconecuratedimages/*\nREPOSITORY                          TAG                    IMAGE ID            CREATED             SIZE\nsconecuratedimages/crosscompilers   latest                 dff7975b7f32        7 hours ago         1.57GB\nsconecuratedimages/crosscompilers   scone                  dff7975b7f32        7 hours ago         1.57GB\n\n\n\n\nIf the cross compiler image is not yet installed, read Section \nSCONE Curated Container Images\n to learn how to install the SCONE cross compiler image.\n\n\nIf the docker command fails, please ensure that docker is indeed installed (see \nSCONE Host Setup\n. Also, on some systems you might need to use \nsodo\n to run docker commands.\n\n\nInstall the tutorial\n\n\nClone the tutorial:\n\n\ngit clone https://github.com/christoffetzer/SCONE_TUTORIAL.git\n\n\n\n\nNative Hello World\n\n\nEnsure that \nhello world\n runs natively on your machine:\n\n\ncd SCONE_TUTORIAL/HelloWorld/\ngcc hello_world.c  -o native_hello_world\n./native_hello_world\nHello World\n\n\n\n\nNote that the generated executable, i.e., \nsim_hello_world\n, will only run on Linux.\n\n\nStatically-Linked Hello World\n\n\nThe default cross compiler variant that runs \nhello world\n inside of an enclave is \nscone gcc\n and you can find this in container \nsconecuratedimages/crosscompilers:scone\n.\nThis variant requires access to the SGX device. \nIn Linux, the SGX device is made available as \n/dev/isgx\n and we can give the cross compiler inside of an container access via option \n--device=/dev/isgx\n:\n\n\ndocker run --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers:scone scone-gcc hello_world.c  -o sgx_hello_world\n\n\n\n\nThis generates a statically linked binary. However, as we mentioned above, the binary looks like a dynamically\nlinked binary since it is wrapped in a dynamically linked loader program:\n\n\nldd ./sgx_hello_world \n    linux-vdso.so.1 =>  (0x00007ffcf73ad000)\n    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f7c2a0e9000)\n    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f7c29d1f000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007f7c2a306000)\n\n\n\n\nEnsure that file \n/etc/sgx-musl.conf\n exists. If not, store some default file like:\n\n\nsudo printf 'Q 1\\ne 0 0 0\\ns 1 0 0\\n' > /etc/sgx-musl.conf\n\n\n\n\nTo run \nsgx_hello_world\n, in an enclave, just execute:\n\n\n./sgx_hello_world\nHello World\n\n\n\n\nTo see some more debug messages, set environment variable \nSCONE_VERSION=1\n:\n\n\nSCONE_VERSION=1 ./sgx_hello_world\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=no\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl\n\nHello World\n\n\n\n\nThe debug outputs \nSCONE_MODE=hw\n shows that \nsgx_hello_world\n runs in hardware mode, i.e., inside an SGX enclave.\n\n\nNote.\n The compilation as well as the hello world program will fail in case you do not have an SGX driver installed.\n\n\nDynamically-Linked Hello World\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc  hello_world.c -o dyn_hello_world\n\n\n\n\nTo run this natively, just execute the following:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc ./dyn_hello_world\n\n\n\n\nTo run a dynamically-linked binary in an enclave, you need to run this in a special runtime environment. In this environment you can ask binaries to run inside of enclaves by setting environment \nSCONE_ALPINE=1\n. To indicate that we are indeed running inside an enclave, we ask to issue some debug messages from inside the enclave by setting environment variable \nSCONE_VERSION=1\n:\n\n\nHardware Mode vs Simulation Mode\n\n\nFor debugging, we support three different modes for execution: \nhardware, simulation, and automatic\n:\n\n\n\n\n\n\nhardware\n: by setting environment variable to \nSCONE_MODE=HW\n, SCONE will enforce running this application inside an SGX enclave.\n\n\n\n\n\n\nsimulation\n: by setting environment variable to \nSCONE_MODE=SIM\n, SCONE will enforce running this application in native mode (i.e., outside of an enclave). This will run all SCONE functionality but outside enclaves. This is intended for development and debugging on machines that are not SGX-capable.\n\n\n\n\n\n\nautomatic\n: by setting environment variable to \nSCONE_MODE=AUTO\n, SCONE will run the application inside of an SGX enclave if available and otherwise in simulation mode. (This is the default mode)\n\n\n\n\n\n\nNOTE\n: In production mode, you must only permit running in hardware mode. Scone ensures this with the help of \nremote attestation\n: the SCONE configuration and attestation service (CAS) will only provide configuration information and secrets to an application only after it has proven (with the help of SGX CPU extensions) that it is indeed running inside an SGX enclave.\n\n\nExecution on a SGX-capable machine\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=HW -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime /usr/src/myapp/dyn_hello_world\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nConfigure parameters: \n1.1.15\nHello World\n\n\n\n\nExecution on a non-SGX machine\n\n\nIf you run this inside a container without access to SGX (/dev/isgx), for example, when running on a Mac, you will see the following error message:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=HW -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime /usr/src/myapp/dyn_hello_world\n[Error] Could not create enclave: Error opening SGX device\n\n\n\n\nYou could run this in simulation mode as follows:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=SIM -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime /usr/src/myapp/dyn_hello_world\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=sim\nConfigure parameters: \n1.1.15\nHello World\n\n\n\n\nAlternatively, you could run this program in automatic mode:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=AUTO -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime \nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=sim\nConfigure parameters:\n1.1.15\nHelloWorld\n\n\n\n\nRun STRACE\n\n\nLets see how we can trace the program. Say, you have compile the program as shown above. After that you enter a cross compiler container and strace hello world as follows:\n\n\ndocker run --cap-add SYS_PTRACE -it --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers strace  -f /usr/src/myapp/sgx_hello_world > strace.log\nHello World\nhead strace.log\nexecve(\"/usr/src/myapp/sgx_hello_world\", [\"/usr/src/myapp/sgx_hello_world\"], [/* 10 vars */]) = 0\nbrk(NULL)                               = 0x10e8000\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nmmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f17f07f1000\naccess(\"/etc/ld.so.preload\", R_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\nfstat(3, {st_mode=S_IFREG|0644, st_size=18506, ...}) = 0\nmmap(NULL, 18506, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f17f07ec000\nclose(3)                                = 0\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\n\n\n\n\nScreencast\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Tutorial"
        },
        {
            "location": "/SCONE_TUTORIAL/#scone-tutorial",
            "text": "",
            "title": "SCONE Tutorial"
        },
        {
            "location": "/SCONE_TUTORIAL/#prerequisites",
            "text": "Ensure that the SGX driver is installed  Check on the host as well as inside your containers that the SGX device  /dev/isgx  is visible:  ls /dev/isgx \n/dev/isgx  If the driver is not installed, read Section  SCONE Host Setup  to learn how to install the SGX driver.  Checking availability of SGX device inside of containers  Sometimes, Docker does not automatically map the SGX device inside of containers. We provide a patched Docker engine and a patched SGX driver that together permit to automatically open the sgx device inside of containers.  If your node is part of a Docker swarm, we provide a simple check as part of the  scone CLI . Say, the leader node of your swarm  is called  beatrix , then you could just execute:  scone swarm check --verbose --manager beatrix  In case your node is not part of a Docker swarm, you can run the checks manually. For that, we provide a container image\nthat helps to check if the SGX device can be accessed from inside a container. Just execute the following commands to check if your containers have access to the SGX device:  # preferred alternative: required for swarms to work: SGX device is available in all containers by default\nsudo docker run --rm sconecuratedimages/checksgx || echo \"SGX device is not automatically mapped inside of container\"\n# alternative: use --device option without --privileged flag\nsudo docker run --device=/dev/isgx --rm sconecuratedimages/checksgx || echo \"--device=/dev/isgx: not sufficient to access SGX device inside of container\"\n# last alternative: use --device option without --privileged flag\nsudo docker run -v /dev/isgx:/dev/isgx --privileged  --rm sconecuratedimages/checksgx || echo \"SGX device NOT available inside of container\"  Use the first alternative that works in your installation to give containers access to the SGX device.  Install sgxmusl cross compiler image  Ensure that you installed the various sconecuratedimages/crosscompilers container image:  docker image ls sconecuratedimages/*\nREPOSITORY                          TAG                    IMAGE ID            CREATED             SIZE\nsconecuratedimages/crosscompilers   latest                 dff7975b7f32        7 hours ago         1.57GB\nsconecuratedimages/crosscompilers   scone                  dff7975b7f32        7 hours ago         1.57GB  If the cross compiler image is not yet installed, read Section  SCONE Curated Container Images  to learn how to install the SCONE cross compiler image.  If the docker command fails, please ensure that docker is indeed installed (see  SCONE Host Setup . Also, on some systems you might need to use  sodo  to run docker commands.",
            "title": "Prerequisites"
        },
        {
            "location": "/SCONE_TUTORIAL/#install-the-tutorial",
            "text": "Clone the tutorial:  git clone https://github.com/christoffetzer/SCONE_TUTORIAL.git",
            "title": "Install the tutorial"
        },
        {
            "location": "/SCONE_TUTORIAL/#native-hello-world",
            "text": "Ensure that  hello world  runs natively on your machine:  cd SCONE_TUTORIAL/HelloWorld/\ngcc hello_world.c  -o native_hello_world\n./native_hello_world\nHello World  Note that the generated executable, i.e.,  sim_hello_world , will only run on Linux.",
            "title": "Native Hello World"
        },
        {
            "location": "/SCONE_TUTORIAL/#statically-linked-hello-world",
            "text": "The default cross compiler variant that runs  hello world  inside of an enclave is  scone gcc  and you can find this in container  sconecuratedimages/crosscompilers:scone .\nThis variant requires access to the SGX device. \nIn Linux, the SGX device is made available as  /dev/isgx  and we can give the cross compiler inside of an container access via option  --device=/dev/isgx :  docker run --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers:scone scone-gcc hello_world.c  -o sgx_hello_world  This generates a statically linked binary. However, as we mentioned above, the binary looks like a dynamically\nlinked binary since it is wrapped in a dynamically linked loader program:  ldd ./sgx_hello_world \n    linux-vdso.so.1 =>  (0x00007ffcf73ad000)\n    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f7c2a0e9000)\n    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f7c29d1f000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007f7c2a306000)  Ensure that file  /etc/sgx-musl.conf  exists. If not, store some default file like:  sudo printf 'Q 1\\ne 0 0 0\\ns 1 0 0\\n' > /etc/sgx-musl.conf  To run  sgx_hello_world , in an enclave, just execute:  ./sgx_hello_world\nHello World  To see some more debug messages, set environment variable  SCONE_VERSION=1 :  SCONE_VERSION=1 ./sgx_hello_world\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=no\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl\n\nHello World  The debug outputs  SCONE_MODE=hw  shows that  sgx_hello_world  runs in hardware mode, i.e., inside an SGX enclave.  Note.  The compilation as well as the hello world program will fail in case you do not have an SGX driver installed.",
            "title": "Statically-Linked Hello World"
        },
        {
            "location": "/SCONE_TUTORIAL/#dynamically-linked-hello-world",
            "text": "docker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc  hello_world.c -o dyn_hello_world  To run this natively, just execute the following:  docker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc ./dyn_hello_world  To run a dynamically-linked binary in an enclave, you need to run this in a special runtime environment. In this environment you can ask binaries to run inside of enclaves by setting environment  SCONE_ALPINE=1 . To indicate that we are indeed running inside an enclave, we ask to issue some debug messages from inside the enclave by setting environment variable  SCONE_VERSION=1 :  Hardware Mode vs Simulation Mode  For debugging, we support three different modes for execution:  hardware, simulation, and automatic :    hardware : by setting environment variable to  SCONE_MODE=HW , SCONE will enforce running this application inside an SGX enclave.    simulation : by setting environment variable to  SCONE_MODE=SIM , SCONE will enforce running this application in native mode (i.e., outside of an enclave). This will run all SCONE functionality but outside enclaves. This is intended for development and debugging on machines that are not SGX-capable.    automatic : by setting environment variable to  SCONE_MODE=AUTO , SCONE will run the application inside of an SGX enclave if available and otherwise in simulation mode. (This is the default mode)    NOTE : In production mode, you must only permit running in hardware mode. Scone ensures this with the help of  remote attestation : the SCONE configuration and attestation service (CAS) will only provide configuration information and secrets to an application only after it has proven (with the help of SGX CPU extensions) that it is indeed running inside an SGX enclave.  Execution on a SGX-capable machine  docker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=HW -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime /usr/src/myapp/dyn_hello_world\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nConfigure parameters: \n1.1.15\nHello World  Execution on a non-SGX machine  If you run this inside a container without access to SGX (/dev/isgx), for example, when running on a Mac, you will see the following error message:  docker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=HW -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime /usr/src/myapp/dyn_hello_world\n[Error] Could not create enclave: Error opening SGX device  You could run this in simulation mode as follows:  docker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=SIM -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime /usr/src/myapp/dyn_hello_world\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=sim\nConfigure parameters: \n1.1.15\nHello World  Alternatively, you could run this program in automatic mode:  docker run --rm  -v \"$PWD\":/usr/src/myapp -e SCONE_MODE=AUTO -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:runtime \nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=sim\nConfigure parameters:\n1.1.15\nHelloWorld",
            "title": "Dynamically-Linked Hello World"
        },
        {
            "location": "/SCONE_TUTORIAL/#run-strace",
            "text": "Lets see how we can trace the program. Say, you have compile the program as shown above. After that you enter a cross compiler container and strace hello world as follows:  docker run --cap-add SYS_PTRACE -it --rm --device=/dev/isgx -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers strace  -f /usr/src/myapp/sgx_hello_world > strace.log\nHello World\nhead strace.log\nexecve(\"/usr/src/myapp/sgx_hello_world\", [\"/usr/src/myapp/sgx_hello_world\"], [/* 10 vars */]) = 0\nbrk(NULL)                               = 0x10e8000\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nmmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f17f07f1000\naccess(\"/etc/ld.so.preload\", R_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\nfstat(3, {st_mode=S_IFREG|0644, st_size=18506, ...}) = 0\nmmap(NULL, 18506, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f17f07ec000\nclose(3)                                = 0\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)",
            "title": "Run STRACE"
        },
        {
            "location": "/SCONE_TUTORIAL/#screencast",
            "text": "\u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Screencast"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/",
            "text": "Generating Container Image with SCONE\n\n\nWe show how to generate a Docker image that contains our \nhello world\n running inside of an enclave and pushing this to docker hub. We only show this for the statically-linked binary. You can see that this code is quite awkward. It is much easier to generate images with a Dockerfile - which we show in the next section.\n\n\nPrerequisites\n\n\nCheck that all prerequisites from \nSCONE Tutorial\n are satisfied. \nClone the SCONE_TUTORIAL before you start creating a \nhello world\n image.\n\n\nGenerate HelloWorld image\n\n\nWe generate a \nhello world\n container image. \n\n\ncd SCONE_TUTORIAL/CreateImage\n\n\n\n\nYou can either execute all step manually by copy&pasting all instructions or you can just execute\n\n\ndocker login\nsudo ./Dockerfile.sh\n\n\n\n\nand watch the outputs.\n\n\nPlease change the image name to a repository on docker hub to which you can write:\n\n\nexport TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloworld\"\n\n\n\n\nWe generate container and compile hello world inside of this container with the help of our standard SCONE cross compiler:\n\n\n\nCONTAINER_ID=`docker run -d -it --device=/dev/isgx  -v $(pwd):/mnt sconecuratedimages/crosscompilers:scone bash -c \"\nset -e\nprintf 'Q 1\\ne 0 0 0\\ns 1 0 0\\n' > /etc/sgx-musl.conf\nsgxmusl-hw-async-gcc /mnt/hello_world.c  -o /usr/local/bin/sgx_hello_world\n\"`\n\n\n\n\nNote that above will fail if you do not have access to the SGX device \n/dev/isgx\n.\n\n\nTurn the container into an image:\n\n\nIMAGE_ID=$(docker commit -p -c 'CMD sgx_hello_world' $CONTAINER_ID $IMAGE_NAME:$TAG)\n\n\n\n\nYou can run this image by executing:\n\n\nsudo docker run --device=/dev/isgx $IMAGE_NAME:$TAG\n\n\n\n\nYou can push this image to Docker. However, ensure that you first login to docker:\n\n\nsudo docker login\n\n\n\n\nbefore you push the image to docker hub:\n\n\nsudo docker push $IMAGE_NAME:$TAG\n\n\n\n\nNote: this will fail in case you do not have the permission to push to this repository. \n\n\nScreencast\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Create Image"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/#generating-container-image-with-scone",
            "text": "We show how to generate a Docker image that contains our  hello world  running inside of an enclave and pushing this to docker hub. We only show this for the statically-linked binary. You can see that this code is quite awkward. It is much easier to generate images with a Dockerfile - which we show in the next section.",
            "title": "Generating Container Image with SCONE"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/#prerequisites",
            "text": "Check that all prerequisites from  SCONE Tutorial  are satisfied. \nClone the SCONE_TUTORIAL before you start creating a  hello world  image.",
            "title": "Prerequisites"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/#generate-helloworld-image",
            "text": "We generate a  hello world  container image.   cd SCONE_TUTORIAL/CreateImage  You can either execute all step manually by copy&pasting all instructions or you can just execute  docker login\nsudo ./Dockerfile.sh  and watch the outputs.  Please change the image name to a repository on docker hub to which you can write:  export TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloworld\"  We generate container and compile hello world inside of this container with the help of our standard SCONE cross compiler:  \nCONTAINER_ID=`docker run -d -it --device=/dev/isgx  -v $(pwd):/mnt sconecuratedimages/crosscompilers:scone bash -c \"\nset -e\nprintf 'Q 1\\ne 0 0 0\\ns 1 0 0\\n' > /etc/sgx-musl.conf\nsgxmusl-hw-async-gcc /mnt/hello_world.c  -o /usr/local/bin/sgx_hello_world\n\"`  Note that above will fail if you do not have access to the SGX device  /dev/isgx .  Turn the container into an image:  IMAGE_ID=$(docker commit -p -c 'CMD sgx_hello_world' $CONTAINER_ID $IMAGE_NAME:$TAG)  You can run this image by executing:  sudo docker run --device=/dev/isgx $IMAGE_NAME:$TAG  You can push this image to Docker. However, ensure that you first login to docker:  sudo docker login  before you push the image to docker hub:  sudo docker push $IMAGE_NAME:$TAG  Note: this will fail in case you do not have the permission to push to this repository.",
            "title": "Generate HelloWorld image"
        },
        {
            "location": "/SCONE_GENERATE_IMAGE/#screencast",
            "text": "\u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Screencast"
        },
        {
            "location": "/SCONE_Dockerfile/",
            "text": "Dockerfile\n\n\nWe show how to generate a first secure container image with the help of a Dockerfile.\n\n\nPrerequisites\n\n\nEnsure that the sgx driver is installed\n\n\n> ls /dev/isgx \n/dev/isgx\n\n\n\n\nIf the driver is not installed, read Section \nSCONE Host Setup\n to learn how to install the SGX driver.\n\n\nEnsure that the patched docker engine is installed\n\n\nWe need \ndocker build\n in this example. This command does not permit to map devices in the newly created containers. Hence, we provide a patched Docker engine \nSCONE Host Setup\n.\n\n\nInstall the tutorial\n\n\nClone the tutorial: \n\n\ngit clone https://github.com/christoffetzer/SCONE_TUTORIAL.git\n\n\n\n\nAccess to SCONE Curated Images\n\n\nRight now, access to the curated images is still restricted. Please, send email to scontain.ceo@gmail.com to request access.\n\n\nGenerate HelloAgain image (dynamically-linked)\n\n\nWe first generate a \nhello again\n container image with a dynamically-linked secure program:\n\n\ncd SCONE_TUTORIAL/DLDockerFile\n\n\n\n\nThe Dockerfile to generate the new image looks like this:\n\n\nFROM sconecuratedimages/crosscompilers:runtime\n\nMAINTAINER Christof Fetzer \"christof.fetzer@gmail.com\"\n\nRUN mkdir /hello\n\nCOPY dyn_hello_again /hello/\n\n\nCMD SCONE_MODE=HW SCONE_ALPINE=1 SCONE_VERSION=1 /hello/dyn_hello_again\n\n\n\n\nThis assumes that we already generated the dynamically linked binary with\nan appropriately configured gcc. We generate this with the provided gcc image:\n\n\ndocker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc  hello_again.c -o dyn_hello_again\n\n\n\n\nWe provide a little script that generates the image and pushes it to Docker hub (which should fail since you should not have the credentials):\n\n\n./generate.sh\n\n\n\n\nYou can run this program inside of enclave (with the output of debug messages):\n\n\ndocker run -it sconecuratedimages/helloworld:dynamic\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nConfigure parameters: \n1.1.15\nHello Again\n\n\n\n\nThis image is nicely small (only 11MB) since it only contains the runtime environment and no development environment.\n\n\nRunning on a docker engine without access to SGX, we get an error message:\n\n\ndocker run -it sconecuratedimages/helloworld:dynamic\n[Error] Could not create enclave: Error opening SGX device \n\n\n\n\nScreencast\n\n\n\n\nGenerate HelloAgain image (statically-linked)\n\n\nWe generate a \nhello again\n container image. \n\n\ncd SCONE_TUTORIAL/DockerFile\n\n\n\n\nThe Dockerfile is quite straight forward:\n\n\nFROM sconecuratedimages/crosscompilers:scone\n\nMAINTAINER Christof Fetzer \"christof.fetzer@gmail.com\"\n\nRUN mkdir /hello\n\nCOPY hello_again.c /hello/\n\nRUN cd /hello && scone-gcc hello_again.c -o again\n\nCMD [\"/hello/again\"]\n\n\n\n\nYou can either execute all step manually (see below) or you can just execute\n\n\ndocker login\n./generate.sh\n\n\n\n\nand watch the outputs. The push of the image should fail since you should not have the access rights to push the image to Docker hub.\n\n\nWe define the image name and tag that we want to generate:\n\n\nexport TAG=\"again\"\nexport FULLTAG=\"sconecuratedimages/helloworld:$TAG\"\n\n\n\n\nWe build the image:\n\n\ndocker build --pull -t $FULLTAG .\n\n\n\n\ndocker run -it $FULLTAG\n\n\n\n\nWe push it to docker hub (will fail unless you have the right to push \n$FULLTAG\n):\n\n\ndocker push $FULLTAG\n\n\n\n\nPlease change the image name to a repository on docker hub to which you can write:\n\n\nexport TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloAgain\"\n\n\n\n\nScreencast\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Dockerfile"
        },
        {
            "location": "/SCONE_Dockerfile/#dockerfile",
            "text": "We show how to generate a first secure container image with the help of a Dockerfile.",
            "title": "Dockerfile"
        },
        {
            "location": "/SCONE_Dockerfile/#prerequisites",
            "text": "Ensure that the sgx driver is installed  > ls /dev/isgx \n/dev/isgx  If the driver is not installed, read Section  SCONE Host Setup  to learn how to install the SGX driver.  Ensure that the patched docker engine is installed  We need  docker build  in this example. This command does not permit to map devices in the newly created containers. Hence, we provide a patched Docker engine  SCONE Host Setup .  Install the tutorial  Clone the tutorial:   git clone https://github.com/christoffetzer/SCONE_TUTORIAL.git  Access to SCONE Curated Images  Right now, access to the curated images is still restricted. Please, send email to scontain.ceo@gmail.com to request access.",
            "title": "Prerequisites"
        },
        {
            "location": "/SCONE_Dockerfile/#generate-helloagain-image-dynamically-linked",
            "text": "We first generate a  hello again  container image with a dynamically-linked secure program:  cd SCONE_TUTORIAL/DLDockerFile  The Dockerfile to generate the new image looks like this:  FROM sconecuratedimages/crosscompilers:runtime\n\nMAINTAINER Christof Fetzer \"christof.fetzer@gmail.com\"\n\nRUN mkdir /hello\n\nCOPY dyn_hello_again /hello/\n\n\nCMD SCONE_MODE=HW SCONE_ALPINE=1 SCONE_VERSION=1 /hello/dyn_hello_again  This assumes that we already generated the dynamically linked binary with\nan appropriately configured gcc. We generate this with the provided gcc image:  docker run --rm  -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/muslgcc gcc  hello_again.c -o dyn_hello_again  We provide a little script that generates the image and pushes it to Docker hub (which should fail since you should not have the credentials):  ./generate.sh  You can run this program inside of enclave (with the output of debug messages):  docker run -it sconecuratedimages/helloworld:dynamic\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=67108864\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nConfigure parameters: \n1.1.15\nHello Again  This image is nicely small (only 11MB) since it only contains the runtime environment and no development environment.  Running on a docker engine without access to SGX, we get an error message:  docker run -it sconecuratedimages/helloworld:dynamic\n[Error] Could not create enclave: Error opening SGX device   Screencast",
            "title": "Generate HelloAgain image (dynamically-linked)"
        },
        {
            "location": "/SCONE_Dockerfile/#generate-helloagain-image-statically-linked",
            "text": "We generate a  hello again  container image.   cd SCONE_TUTORIAL/DockerFile  The Dockerfile is quite straight forward:  FROM sconecuratedimages/crosscompilers:scone\n\nMAINTAINER Christof Fetzer \"christof.fetzer@gmail.com\"\n\nRUN mkdir /hello\n\nCOPY hello_again.c /hello/\n\nRUN cd /hello && scone-gcc hello_again.c -o again\n\nCMD [\"/hello/again\"]  You can either execute all step manually (see below) or you can just execute  docker login\n./generate.sh  and watch the outputs. The push of the image should fail since you should not have the access rights to push the image to Docker hub.  We define the image name and tag that we want to generate:  export TAG=\"again\"\nexport FULLTAG=\"sconecuratedimages/helloworld:$TAG\"  We build the image:  docker build --pull -t $FULLTAG .  docker run -it $FULLTAG  We push it to docker hub (will fail unless you have the right to push  $FULLTAG ):  docker push $FULLTAG  Please change the image name to a repository on docker hub to which you can write:  export TAG=\"latest\"\nexport IMAGE_NAME=\"sconecuratedimages/helloAgain\"  Screencast   \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Generate HelloAgain image (statically-linked)"
        },
        {
            "location": "/SCONE_Swarm/",
            "text": "SCONE SWARM\n\n\nInstallation\n\n\nTypically, you might want to set up a docker swarm with the \nscone host\n command.\n\n\nNode Labels\n\n\nDocker Swarm supports the labeling of nodes. SCONE labels the nodes of a Docker swarm with several labels:\n\n\n\n\n\n\nsgx\n: let's us determine if and what version of SGX the CPU of this node supports.\n\n\n\n\n\n\nsgxdriver\n: shows the version of the SGX driver. It says \nSCONE\n if the node runs the latest patched SGX driver. Otherwise, it shows the version reported by the SGX driver.\n\n\n\n\n\n\ndockerversion\n shows the version of the docker engine. If it is the latest version of the SCONE patched Docker engine, it will say \"SCONE\".\n\n\n\n\n\n\nnodeno\n. All nodes have a unique number between 1 and the number of nodes in the swarm.\n\n\n\n\n\n\nInitialising and Checking Labels\n\n\nTo set these labels an to check the labels and fix these if not properly set, just run the following command - assuming that the manager of your swarm is called \nalice\n:\n\n\nscone swarm check --verbose --manager alice\n\n\n\n\nTo list all labels of the nodes managed by host \nsgx2\n, just execute the following command:\n\n\nscone swarm ls --manager alice\nNODENO        SGX VERSION   DOCKER-ENGINE SGX-DRIVER    HOST                 STATUS     AVAILABILITY  MANAGER   \n4             1             SCONE         SCONE         dorothy              Ready      Active                  \n2             1             SCONE         SCONE         beatrix              Ready      Active                  \n1             1             SCONE         SCONE         alice                Ready      Active        Leader    \n3             1             SCONE         SCONE         caroline             Ready      Active             \n\n\n\n\nSince often you might actually interact always with the same swarm, you can drop the option \n--manager alice\n by\nsetting the environment variable \nSCONE_MANAGER\n:\n\n\nexport SCONE_MANAGER=alice\n\n\n\n\nNow, you can perform the swarm commands without the \n--manager\n option, like for example:\n\n\nscone swarm check\n\n\n\n\nScreencast\n\n\nhttps://asciinema.org/a/MhatVwfLY0hBrPk1d2XNF8pan\n\n\n\n\nDetails\n\n\nThe value of label \nsgx\n is set as follows:\n\n\n\n\n\n\nsgx == \"0\" iff the node does not support sgx\n\n\n\n\n\n\nsgx == \"1\" iff the node supports sgx version 1\n\n\n\n\n\n\nsgx == \"2\" iff the node supports sgx version 2 (which is not yet available)\n\n\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Swarm"
        },
        {
            "location": "/SCONE_Swarm/#scone-swarm",
            "text": "",
            "title": "SCONE SWARM"
        },
        {
            "location": "/SCONE_Swarm/#installation",
            "text": "Typically, you might want to set up a docker swarm with the  scone host  command.",
            "title": "Installation"
        },
        {
            "location": "/SCONE_Swarm/#node-labels",
            "text": "Docker Swarm supports the labeling of nodes. SCONE labels the nodes of a Docker swarm with several labels:    sgx : let's us determine if and what version of SGX the CPU of this node supports.    sgxdriver : shows the version of the SGX driver. It says  SCONE  if the node runs the latest patched SGX driver. Otherwise, it shows the version reported by the SGX driver.    dockerversion  shows the version of the docker engine. If it is the latest version of the SCONE patched Docker engine, it will say \"SCONE\".    nodeno . All nodes have a unique number between 1 and the number of nodes in the swarm.",
            "title": "Node Labels"
        },
        {
            "location": "/SCONE_Swarm/#initialising-and-checking-labels",
            "text": "To set these labels an to check the labels and fix these if not properly set, just run the following command - assuming that the manager of your swarm is called  alice :  scone swarm check --verbose --manager alice  To list all labels of the nodes managed by host  sgx2 , just execute the following command:  scone swarm ls --manager alice\nNODENO        SGX VERSION   DOCKER-ENGINE SGX-DRIVER    HOST                 STATUS     AVAILABILITY  MANAGER   \n4             1             SCONE         SCONE         dorothy              Ready      Active                  \n2             1             SCONE         SCONE         beatrix              Ready      Active                  \n1             1             SCONE         SCONE         alice                Ready      Active        Leader    \n3             1             SCONE         SCONE         caroline             Ready      Active               Since often you might actually interact always with the same swarm, you can drop the option  --manager alice  by\nsetting the environment variable  SCONE_MANAGER :  export SCONE_MANAGER=alice  Now, you can perform the swarm commands without the  --manager  option, like for example:  scone swarm check",
            "title": "Initialising and Checking Labels"
        },
        {
            "location": "/SCONE_Swarm/#screencast",
            "text": "https://asciinema.org/a/MhatVwfLY0hBrPk1d2XNF8pan",
            "title": "Screencast"
        },
        {
            "location": "/SCONE_Swarm/#details",
            "text": "The value of label  sgx  is set as follows:    sgx == \"0\" iff the node does not support sgx    sgx == \"1\" iff the node supports sgx version 1    sgx == \"2\" iff the node supports sgx version 2 (which is not yet available)    \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Details"
        },
        {
            "location": "/SCONE_Swarm_Example/",
            "text": "Starting a SCONE Application on a Swarm\n\n\nWe show how to run a \nsecure nginx\n version, i.e., one that runs inside an enclave in a\ndocker swarm with automatic restarts. To simplify the running of services, we provide \na simple wrapper around the \ndocker service\n command: the \nscone service\n executes\n\ndocker service\n commands on the manager of a swarm. The manager is either specified via\nan option \n--manager \n or via environment variable \nSCONE_MANAGER\n. This is \ndone in the same way as for command \nscone swarm\n.\n\n\nIn what follows, we assume that \nSCONE_MANAGER\n is set to the leader of the swarm.\nThe \nscone\n commands are typically executed in a container running at the \ndeveloper\nsite\n.\n\n\nPrerequisites\n\n\nRegistry support\n\n\nFor running an application in a Docker Swarm, you need to set up a local registry to\nensure that all nodes get access to the same container image. The scone CLI expects the\nregistry to be available at \nlocalhost:5000\n. You can start a default registry with the\nhelp of \nscone\n:\n\n\n> scone service registry --verbose\nRegistry is already running in swarm beatrix\n\n\n\n\nTo simplify pushing images to the local registry, the scone CLI includes a \nscone service pull\n command to pull\nan image from docker hub and then to push this image to the local registry. For example, to pull image\n\nsconecuratedimages/sconetainer:noshielding\n and store it as \nlocalhost:5000/sconetainer:noshielding\n,\njust execute:\n\n\n> scone service pull sconecuratedimages/sconetainer:noshielding\nnew tag: localhost:5000/sconetainer:noshielding\n\n\n\n\nSGX Support\n\n\nServices are automatically restarted. In case, there is a persistent failure in some service \nha\n, we would see\nrepeated restarts like: \n\n\n> scone service ps ha\nID                  NAME                IMAGE                      NODE                DESIRED STATE       CURRENT STATE           ERROR                       PORTS\nf65id6ow5n6w        ha.1                sconecuratedimages/nginx   beatrix             Ready               Ready 1 second ago                                  \njt6wj5e3lso4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 3 seconds ago    \"task: non-zero exit (1)\"   \nsspou3mcis8m         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 9 seconds ago    \"task: non-zero exit (1)\"   \np3bw780pu63b         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 15 seconds ago   \"task: non-zero exit (1)\"   \n75zjsesil5k4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 22 seconds ago   \"task: non-zero exit (1)\"   \n\n\n\n\nReasons for such failures might be that that the containers might not have access to the sgx device. \n\n\nThere are multiple reasons why the driver might not be accessible inside of a container: Did you indeed install the patched docker version? Did you indeed label the nodes correctly? To automatically diagnoses and in some cases, to perform some automatic corrections, just execute \nscone swarm check\n:\n\n\n> scone swarm check\nwarning:  'sgx device is not automatically mapped inside of container on host beatrix (stack=198 434 0)'  (Line numer: '198')\nwarning:  '--device=/dev/isgx: device mapper does not work inside of container on host beatrix (stack=199 434 0)'  (Line numer: '199')\n\n\n\n\nTo get a summary view of a swarm after you performed a check, just executed:\n\n\n> scone swarm ls\nNODENO        SGX VERSION   DOCKER-ENGINE SGX-DRIVER    HOST                 STATUS     AVAILABILITY  MANAGER   \n2             1             SCONE         SCONE         caroline             Ready      Active        Reachable \n3             1             SCONE         SCONE         dorothy              Ready      Active                  \n4             1             SCONE         SCONE         edna                 Ready      Active        Reachable \n1             1             SCONE         SCONE         beatrix              Ready      Active        Leader    \n\n\n\n\nStarting a Service\n\n\nAfter pulling an image into the local registry (see above), we can\nstart a service in the swarm via \nscone service create\n.\nDocker swarm will start the image and it also takes care of failures by restarting failed services.\n\n\nFor the next steps, make sure that all nodes have access to image \nsconecuratedimages/sconetainer:noshielding\n and pull this image via:\n\n\n> scone service pull sconecuratedimages/sconetainer:noshielding\nnew tag: localhost:5000/sconetainer:noshielding\n\n\n\n\nWe start a nginx service including a version of the scontain.com website. We start two replicas running inside separate enclaves - most likely on two different nodes:\n\n\n> scone service create --name sconeweb --detach=true  --publish 80:80 --publish 443:443 --replicas=2 localhost:5000/sconetainer:noshielding\n\n\n\n\nIn case the service starts up correctly, you will see a status like this:\n\n\n> scone service ps sconeweb\nID                  NAME           IMAGE                              NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTS\nba3odjkz6mx2        sconeweb.1     localhost:5000/nginx:noshielding   alice               Running             Running 8 minutes ago         \nx2xq1c3aede7        sconeweb.2     localhost:5000/nginx:noshielding   beatrix               Running             Running 8 minutes ago         \n\n\n\n\nIf, for example, an image is not available on all nodes, you might see the following status:\n\n\n> scone service ps sconeweb\nID                  NAME                IMAGE                                        NODE                DESIRED STATE       CURRENT STATE          ERROR                              PORTS\no79714pw2fpn        sconeweb.1          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago                                       \nt0byepte0fzj         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nmg4xdq868syq         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nry1pqen9jgan         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nq05ti7gkxc7r         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nzxj74inh2zdf        sconeweb.2          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago                                       \n\n\n\n\nStopping the service\n\n\nStop the service via:\n\n\n> scone service rm sconeweb\n\n\n\n\nUpdating the image of a service\n\n\nSay, there is a new version of the sconetainer image available. We can update this image in our local registry\nas follows:\n\n\nscone pull sconecuratedimages/sconetainer:noshielding\n\n\n\n\nWe can now update the service as follows:\n\n\nscone service update --image  localhost:5000/sconetainer sconeweb\n\n\n\n\nDraining a node\n\n\nTo be able to drain all containers from a node, we need to figure out the node's id. We can do this manually by executing the following command on the leader node:\n\n\n> sudo docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n91a1vvex4dgozfrzy1y136gmg *   alice               Ready               Active              Leader\njhrayos9ylu02egwvkxpqtbwb     beatrix             Ready               Active              \n\n\n\n\nYou can now take node \nalice\n out of service by executing:\n\n\n> sudo docker node update --availability drain 91a1vvex4dgozfrzy1y136gmg\n\n\n\n\nTo put the node back in service by executing:\n\n\n> sudo docker node update --availability active 91a1vvex4dgozfrzy1y136gmg\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Swarm Example"
        },
        {
            "location": "/SCONE_Swarm_Example/#starting-a-scone-application-on-a-swarm",
            "text": "We show how to run a  secure nginx  version, i.e., one that runs inside an enclave in a\ndocker swarm with automatic restarts. To simplify the running of services, we provide \na simple wrapper around the  docker service  command: the  scone service  executes docker service  commands on the manager of a swarm. The manager is either specified via\nan option  --manager   or via environment variable  SCONE_MANAGER . This is \ndone in the same way as for command  scone swarm .  In what follows, we assume that  SCONE_MANAGER  is set to the leader of the swarm.\nThe  scone  commands are typically executed in a container running at the  developer\nsite .",
            "title": "Starting a SCONE Application on a Swarm"
        },
        {
            "location": "/SCONE_Swarm_Example/#prerequisites",
            "text": "Registry support  For running an application in a Docker Swarm, you need to set up a local registry to\nensure that all nodes get access to the same container image. The scone CLI expects the\nregistry to be available at  localhost:5000 . You can start a default registry with the\nhelp of  scone :  > scone service registry --verbose\nRegistry is already running in swarm beatrix  To simplify pushing images to the local registry, the scone CLI includes a  scone service pull  command to pull\nan image from docker hub and then to push this image to the local registry. For example, to pull image sconecuratedimages/sconetainer:noshielding  and store it as  localhost:5000/sconetainer:noshielding ,\njust execute:  > scone service pull sconecuratedimages/sconetainer:noshielding\nnew tag: localhost:5000/sconetainer:noshielding  SGX Support  Services are automatically restarted. In case, there is a persistent failure in some service  ha , we would see\nrepeated restarts like:   > scone service ps ha\nID                  NAME                IMAGE                      NODE                DESIRED STATE       CURRENT STATE           ERROR                       PORTS\nf65id6ow5n6w        ha.1                sconecuratedimages/nginx   beatrix             Ready               Ready 1 second ago                                  \njt6wj5e3lso4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 3 seconds ago    \"task: non-zero exit (1)\"   \nsspou3mcis8m         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 9 seconds ago    \"task: non-zero exit (1)\"   \np3bw780pu63b         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 15 seconds ago   \"task: non-zero exit (1)\"   \n75zjsesil5k4         \\_ ha.1            sconecuratedimages/nginx   beatrix             Shutdown            Failed 22 seconds ago   \"task: non-zero exit (1)\"     Reasons for such failures might be that that the containers might not have access to the sgx device.   There are multiple reasons why the driver might not be accessible inside of a container: Did you indeed install the patched docker version? Did you indeed label the nodes correctly? To automatically diagnoses and in some cases, to perform some automatic corrections, just execute  scone swarm check :  > scone swarm check\nwarning:  'sgx device is not automatically mapped inside of container on host beatrix (stack=198 434 0)'  (Line numer: '198')\nwarning:  '--device=/dev/isgx: device mapper does not work inside of container on host beatrix (stack=199 434 0)'  (Line numer: '199')  To get a summary view of a swarm after you performed a check, just executed:  > scone swarm ls\nNODENO        SGX VERSION   DOCKER-ENGINE SGX-DRIVER    HOST                 STATUS     AVAILABILITY  MANAGER   \n2             1             SCONE         SCONE         caroline             Ready      Active        Reachable \n3             1             SCONE         SCONE         dorothy              Ready      Active                  \n4             1             SCONE         SCONE         edna                 Ready      Active        Reachable \n1             1             SCONE         SCONE         beatrix              Ready      Active        Leader",
            "title": "Prerequisites"
        },
        {
            "location": "/SCONE_Swarm_Example/#starting-a-service",
            "text": "After pulling an image into the local registry (see above), we can\nstart a service in the swarm via  scone service create .\nDocker swarm will start the image and it also takes care of failures by restarting failed services.  For the next steps, make sure that all nodes have access to image  sconecuratedimages/sconetainer:noshielding  and pull this image via:  > scone service pull sconecuratedimages/sconetainer:noshielding\nnew tag: localhost:5000/sconetainer:noshielding  We start a nginx service including a version of the scontain.com website. We start two replicas running inside separate enclaves - most likely on two different nodes:  > scone service create --name sconeweb --detach=true  --publish 80:80 --publish 443:443 --replicas=2 localhost:5000/sconetainer:noshielding  In case the service starts up correctly, you will see a status like this:  > scone service ps sconeweb\nID                  NAME           IMAGE                              NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTS\nba3odjkz6mx2        sconeweb.1     localhost:5000/nginx:noshielding   alice               Running             Running 8 minutes ago         \nx2xq1c3aede7        sconeweb.2     localhost:5000/nginx:noshielding   beatrix               Running             Running 8 minutes ago           If, for example, an image is not available on all nodes, you might see the following status:  > scone service ps sconeweb\nID                  NAME                IMAGE                                        NODE                DESIRED STATE       CURRENT STATE          ERROR                              PORTS\no79714pw2fpn        sconeweb.1          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago                                       \nt0byepte0fzj         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nmg4xdq868syq         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nry1pqen9jgan         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nq05ti7gkxc7r         \\_ sconeweb.1      sconecuratedimages/sconetainer:noshielding   beatrix             Shutdown            Rejected 4 hours ago   \"No such image: sconecuratedim\u2026\"   \nzxj74inh2zdf        sconeweb.2          sconecuratedimages/sconetainer:noshielding   alice               Running             Running 4 hours ago",
            "title": "Starting a Service"
        },
        {
            "location": "/SCONE_Swarm_Example/#stopping-the-service",
            "text": "Stop the service via:  > scone service rm sconeweb",
            "title": "Stopping the service"
        },
        {
            "location": "/SCONE_Swarm_Example/#updating-the-image-of-a-service",
            "text": "Say, there is a new version of the sconetainer image available. We can update this image in our local registry\nas follows:  scone pull sconecuratedimages/sconetainer:noshielding  We can now update the service as follows:  scone service update --image  localhost:5000/sconetainer sconeweb",
            "title": "Updating the image of a service"
        },
        {
            "location": "/SCONE_Swarm_Example/#draining-a-node",
            "text": "To be able to drain all containers from a node, we need to figure out the node's id. We can do this manually by executing the following command on the leader node:  > sudo docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n91a1vvex4dgozfrzy1y136gmg *   alice               Ready               Active              Leader\njhrayos9ylu02egwvkxpqtbwb     beatrix             Ready               Active                You can now take node  alice  out of service by executing:  > sudo docker node update --availability drain 91a1vvex4dgozfrzy1y136gmg  To put the node back in service by executing:  > sudo docker node update --availability active 91a1vvex4dgozfrzy1y136gmg  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Draining a node"
        },
        {
            "location": "/SCONE_Compose/",
            "text": "SCONE Compose\n\n\nSCONE supports to run secure applications  consisting of multiple secure containers. To do so, SCONE introduces slightly extended Docker \ncompose\n file. Such an extended compose file defines for each process that runs inside of an enclave, a unique hash value (\nMRENCLAVE\n). During startup, SCONE performs an \nattestation\n for all these \nsecure processes\n to ensure that the hash of the started program is as expected, i.e., is equal to \nMRENCLAVE\n. Only if it is equal, the arguments and the environment variables are passed to the process. In this way, we can pass secrets as arguments or environment variables in a secure fashion to a secure process.\n\n\nBy default, all containers are started with SCONE and the arguments are passed in a secure fashion to the started processes. However, you might not want to run all processes inside of enclaves. For containers that should be directly started with Docker Swarm, you need to set field \nnot_scone: \"true\"\n. In this case, all arguments and the environment variables are directly passed to the container with Docker Swarm (instead of SCONE).\n\n\nLet's consider an example, that consists of a \nhaproxy\n that runs in native mode and is directly started with Docker Swarm (indicated by line \nnot_scone: \"true\"\n) Moreover, we start \nmyapp\n (defined in container image \nmyapp-image\n) and specify \nMRENCLAVE\n. Only after ensuring that the program started in the enclave has the expected \nMRENCLAVE\n the arguments and the environment variables are passed to \nmyapp\n.\n\n\nversion: \"3.1.scone\"\nservices:\n    primary-service:\n        image: myapp-image:latest\n        command: /myapp arg1 arg2 arg3 $my_password\n        mrenclave: 5764436f08dd4cdb526f082be1a07a3422f79ef2b01a5e24f78f9034a838c335\n        environment:\n            - SECURE_ENV=value\n            - MY_PIN=$my_pin\n            - MY_PASSWORD=$my_password\n        working_dir: /\n    proxy:\n        image: haproxy\n        command: haproxy --read_config_from_environ\n        not_scone: \"true\"\n        environment:\n            - \"HAPROXY_CONFIG=a=b,c=d,3=4\"\nsecrets:\n    my_pin:\n        kind: numeric\n        length: \"4\"\n    my_password:\n        kind: ascii\n        length: \"8\"\n\n\n\n\nThe extended compose file is split by SCONE into a standard compose file and a configuration information that is stored in the SCONE \nConfigruation and Attestation Service\n (\nCAS\n):\n\n\n\n\nIn the current version of scone, we assume that the compose file is stored on a trusted host. (We plan to support compose files stored on untrusted host in the near future.)\n\n\nThe \nsplit\n functionality is part of the \nscone CLI\n, i.e., you can split a compose file via\n\n\nscone cas split <COMPOSE_FILE>\n\n\n\n\nThis creates a set of services in your Swarm. To be able to use a CAS, you are required to login the CAS first via:\n\n\nscone cas login\n\n\n\n\nNote for now, \nscone cas\n (unlike the other scone objects) still works on the local swarm\n. This will change in a future version of \nscone cas\n.\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Compose"
        },
        {
            "location": "/SCONE_Compose/#scone-compose",
            "text": "SCONE supports to run secure applications  consisting of multiple secure containers. To do so, SCONE introduces slightly extended Docker  compose  file. Such an extended compose file defines for each process that runs inside of an enclave, a unique hash value ( MRENCLAVE ). During startup, SCONE performs an  attestation  for all these  secure processes  to ensure that the hash of the started program is as expected, i.e., is equal to  MRENCLAVE . Only if it is equal, the arguments and the environment variables are passed to the process. In this way, we can pass secrets as arguments or environment variables in a secure fashion to a secure process.  By default, all containers are started with SCONE and the arguments are passed in a secure fashion to the started processes. However, you might not want to run all processes inside of enclaves. For containers that should be directly started with Docker Swarm, you need to set field  not_scone: \"true\" . In this case, all arguments and the environment variables are directly passed to the container with Docker Swarm (instead of SCONE).  Let's consider an example, that consists of a  haproxy  that runs in native mode and is directly started with Docker Swarm (indicated by line  not_scone: \"true\" ) Moreover, we start  myapp  (defined in container image  myapp-image ) and specify  MRENCLAVE . Only after ensuring that the program started in the enclave has the expected  MRENCLAVE  the arguments and the environment variables are passed to  myapp .  version: \"3.1.scone\"\nservices:\n    primary-service:\n        image: myapp-image:latest\n        command: /myapp arg1 arg2 arg3 $my_password\n        mrenclave: 5764436f08dd4cdb526f082be1a07a3422f79ef2b01a5e24f78f9034a838c335\n        environment:\n            - SECURE_ENV=value\n            - MY_PIN=$my_pin\n            - MY_PASSWORD=$my_password\n        working_dir: /\n    proxy:\n        image: haproxy\n        command: haproxy --read_config_from_environ\n        not_scone: \"true\"\n        environment:\n            - \"HAPROXY_CONFIG=a=b,c=d,3=4\"\nsecrets:\n    my_pin:\n        kind: numeric\n        length: \"4\"\n    my_password:\n        kind: ascii\n        length: \"8\"  The extended compose file is split by SCONE into a standard compose file and a configuration information that is stored in the SCONE  Configruation and Attestation Service  ( CAS ):   In the current version of scone, we assume that the compose file is stored on a trusted host. (We plan to support compose files stored on untrusted host in the near future.)  The  split  functionality is part of the  scone CLI , i.e., you can split a compose file via  scone cas split <COMPOSE_FILE>  This creates a set of services in your Swarm. To be able to use a CAS, you are required to login the CAS first via:  scone cas login  Note for now,  scone cas  (unlike the other scone objects) still works on the local swarm . This will change in a future version of  scone cas .  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "SCONE Compose"
        },
        {
            "location": "/SCONE_Fileshield/",
            "text": "SCONE File Protection\n\n\nSCONE supports the transparent encryption and/or authenticate files.\n\n\nObjective\n\n\nSetting up file encryption takes several steps and we are working on making this simpler.\n\n\nThe idea of file encryption is that a user can define file regions in which files must be \nencrypted\n (which always includes authentication), \nauthenticated\n (i.e., SCONE ensure that the content is not modified), or \nunprotected\n. \n\n\nExample\n\n\nTo show how the file encryption is set up, please have a look at the following screencast.\n\n\n\n\nBelow is the script that is executed in the screencast:\n\n\ndocker run -it -v $PWD:/mnt sconecuratedimages/crosscompilers:scone\n\nmkdir -p /example\nmkdir -p /mnt/authenticated/\nmkdir -p /mnt/encrypted/\ncd /example\nmkdir -p .original\n\nscone fspf create fspf.pb\nscone fspf create authenticated.pb\nscone fspf create encrypted.pb\n\n# add protection regions\nscone fspf addr fspf.pb / -e --ephemeral\nscone fspf addr authenticated.pb /mnt/authenticated -a --kernel /mnt/authenticated\nscone fspf addr encrypted.pb /mnt/encrypted -e --kernel /mnt/encrypted\n\n# add files\n\n# enclave program should expect the files (directories) found by the client in ./original in /mnt/authenticated\nscone fspf addf authenticated.pb /mnt/authenticated ./original\n\n# enclave program should expect the files (directories) found by the client in ./original in encrypted form in /mnt/encrypted\n# the client will write the encrypted files to ./mnt/encrypted\nscone fspf addf encrypted.pb /mnt/encrypted ./original ./mnt/encrypted\nencrypted_key=`scone fspf encrypt encrypted.pb | awk '{print $11}'`\n\necho \"encrypted.pb key: ${encrypted_key}\"\nscone fspf addfspf fspf.pb authenticated.pb\nscone fspf addfspf fspf.pb encrypted.pb ${encrypted_key}\ncat > example.c << EOF\n#include <stdio.h>\n\nint main() {\n    FILE *fp = fopen(\"/mnt/authenticated/hello\", \"w\");\n    fprintf(fp, \"hello world\\n\");\n    fclose(fp);\n\n    fp = fopen(\"/mnt/encrypted/hello\", \"w\");\n    fprintf(fp, \"hello world\\n\");\n    fclose(fp);\n}\nEOF\nscone gcc example.c -o sgxex\ncat > /etc/sgx-musl.conf << EOF\nQ 4\ne -1 0 0\ns -1 0 0\ne -1 1 0\ns -1 1 0\ne -1 2 0\ns -1 2 0\ne -1 3 0\ns -1 3 0\nEOF\nSCONE_FSPF=fspf.pb ./sgxex\ncat /mnt/authenticated/hello\ncat /mnt/encrypted/hello \ncat > cat.c << EOF\n#include <stdio.h>\n\nint main() {\n    char buf[80];\n    FILE *fp = fopen(\"/mnt/authenticated/hello\", \"r\");\n    fgets(buf, sizeof(buf), fp);\n    fclose(fp);\n    printf(\"read: '%s'\\n\", buf);\n\n    fp = fopen(\"/mnt/encrypted/hello\", \"r\");\n    fgets(buf, sizeof(buf), fp);\n    fclose(fp);\n    printf(\"read: '%s'\\n\", buf);\n}\nEOF\n\nscone gcc cat.c -o native_cat\n./native_cat\nscone gcc cat.c -o sgxcat\nSCONE_FSPF=fspf.pb ./sgxcat\n\n\n\n\nNotes\n\n\nThe SCONE File Protection documentation is not yet completed and more information will be provided soon.\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE File Protection"
        },
        {
            "location": "/SCONE_Fileshield/#scone-file-protection",
            "text": "SCONE supports the transparent encryption and/or authenticate files.",
            "title": "SCONE File Protection"
        },
        {
            "location": "/SCONE_Fileshield/#objective",
            "text": "Setting up file encryption takes several steps and we are working on making this simpler.  The idea of file encryption is that a user can define file regions in which files must be  encrypted  (which always includes authentication),  authenticated  (i.e., SCONE ensure that the content is not modified), or  unprotected .",
            "title": "Objective"
        },
        {
            "location": "/SCONE_Fileshield/#example",
            "text": "To show how the file encryption is set up, please have a look at the following screencast.   Below is the script that is executed in the screencast:  docker run -it -v $PWD:/mnt sconecuratedimages/crosscompilers:scone\n\nmkdir -p /example\nmkdir -p /mnt/authenticated/\nmkdir -p /mnt/encrypted/\ncd /example\nmkdir -p .original\n\nscone fspf create fspf.pb\nscone fspf create authenticated.pb\nscone fspf create encrypted.pb\n\n# add protection regions\nscone fspf addr fspf.pb / -e --ephemeral\nscone fspf addr authenticated.pb /mnt/authenticated -a --kernel /mnt/authenticated\nscone fspf addr encrypted.pb /mnt/encrypted -e --kernel /mnt/encrypted\n\n# add files\n\n# enclave program should expect the files (directories) found by the client in ./original in /mnt/authenticated\nscone fspf addf authenticated.pb /mnt/authenticated ./original\n\n# enclave program should expect the files (directories) found by the client in ./original in encrypted form in /mnt/encrypted\n# the client will write the encrypted files to ./mnt/encrypted\nscone fspf addf encrypted.pb /mnt/encrypted ./original ./mnt/encrypted\nencrypted_key=`scone fspf encrypt encrypted.pb | awk '{print $11}'`\n\necho \"encrypted.pb key: ${encrypted_key}\"\nscone fspf addfspf fspf.pb authenticated.pb\nscone fspf addfspf fspf.pb encrypted.pb ${encrypted_key}\ncat > example.c << EOF\n#include <stdio.h>\n\nint main() {\n    FILE *fp = fopen(\"/mnt/authenticated/hello\", \"w\");\n    fprintf(fp, \"hello world\\n\");\n    fclose(fp);\n\n    fp = fopen(\"/mnt/encrypted/hello\", \"w\");\n    fprintf(fp, \"hello world\\n\");\n    fclose(fp);\n}\nEOF\nscone gcc example.c -o sgxex\ncat > /etc/sgx-musl.conf << EOF\nQ 4\ne -1 0 0\ns -1 0 0\ne -1 1 0\ns -1 1 0\ne -1 2 0\ns -1 2 0\ne -1 3 0\ns -1 3 0\nEOF\nSCONE_FSPF=fspf.pb ./sgxex\ncat /mnt/authenticated/hello\ncat /mnt/encrypted/hello \ncat > cat.c << EOF\n#include <stdio.h>\n\nint main() {\n    char buf[80];\n    FILE *fp = fopen(\"/mnt/authenticated/hello\", \"r\");\n    fgets(buf, sizeof(buf), fp);\n    fclose(fp);\n    printf(\"read: '%s'\\n\", buf);\n\n    fp = fopen(\"/mnt/encrypted/hello\", \"r\");\n    fgets(buf, sizeof(buf), fp);\n    fclose(fp);\n    printf(\"read: '%s'\\n\", buf);\n}\nEOF\n\nscone gcc cat.c -o native_cat\n./native_cat\nscone gcc cat.c -o sgxcat\nSCONE_FSPF=fspf.pb ./sgxcat",
            "title": "Example"
        },
        {
            "location": "/SCONE_Fileshield/#notes",
            "text": "The SCONE File Protection documentation is not yet completed and more information will be provided soon.  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Notes"
        },
        {
            "location": "/Python/",
            "text": "Python\n\n\nSCONE supports running Python programs inside of SGX enclaves. To support this, we provide a simple Docker image (you need access rights for that).\n\n\nImage\n\n\nCurrently, we provde a simple Python 2.7 image that is based on the standard Python image python:2.7-alpine.\n\n\nYou can pull this image as follows:\n\n\ndocker pull sconecuratedimages/crosscompilers:python27\n\n\n\n\nPython Interpreter\n\n\nTo run the Python interpreter inside an enclave in interactive mode, just execute:\n\n\ndocker run -it -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers:python27\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=11000000\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=yes\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl\n\nPython 2.7.14 (default, Nov  4 2017, 00:12:32) \n[GCC 5.3.0] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \n\n\n\n\nRunning an application\n\n\nSay, you have a Python application called \nmyapp.py\n in your current directory.\nTo execute this with Pyhton 2.7 inside an enclave, you need to set some environment variables. \n\n\n\n\n\n\nTo run Python inside of an enclave, you can set the environment variable \nSCONE_MODE=HW\n and \nSCONE_ALPINE=1\n.\n\n\n\n\n\n\nTo issue some debug messages that show that we are running inside an enclave, set \nSCONE_VERSION=1\n\n\n\n\n\n\nIn general, we only permit the loading of dynamic libraries after the initial loading of the problem, only by explicitly defining \nSCONE_ALLOW_DLOPEN\n. To enable the loading of dynamic libraries after startup (and without requiring the authentication of this library via the file shield), we set \nSCONE_ALLOW_DLOPEN=2\n.\n\n\n\n\n\n\nExample:\n\n\ndocker run --rm -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp -e SCONE_MODE=HW -e SCONE_ALLOW_DLOPEN=2 -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:python27 python myapp.py\n\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\n...\n\n\n\n\nNOTE\n In some cases the SGX device cannot be opened inside of a container - despite being mapped in the container with \n--device\n and being visible inside of the container. In this case, try to map the devices inside of the container as a volume via \n-v /dev/isgx:/dev/isgx --privileged\n. For example, you might execute:\n\n\nsudo docker run -v /dev/isgx:/dev/isgx --privileged -e SCONE_MODE=HW -e SCONE_ALLOW_DLOPEN=2 -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:python27 python -c \"print('hello')\"\n\n\n\n\nExample\n\n\nLet's look at another example:\n\n\n\n\n\n\nWe use \npip\n to install a Python chess library.\n\n\n\n\n\n\nThen we run Python inside of an enclave and  import the chess library. \n\n\n\n\n\n\nWe use the Scholar's mate example from \nhttps://pypi.python.org/pypi/python-chess\n\n\n\n\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "Python"
        },
        {
            "location": "/Python/#python",
            "text": "SCONE supports running Python programs inside of SGX enclaves. To support this, we provide a simple Docker image (you need access rights for that).",
            "title": "Python"
        },
        {
            "location": "/Python/#image",
            "text": "Currently, we provde a simple Python 2.7 image that is based on the standard Python image python:2.7-alpine.  You can pull this image as follows:  docker pull sconecuratedimages/crosscompilers:python27",
            "title": "Image"
        },
        {
            "location": "/Python/#python-interpreter",
            "text": "To run the Python interpreter inside an enclave in interactive mode, just execute:  docker run -it -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp sconecuratedimages/crosscompilers:python27\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=11000000\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=yes\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl\n\nPython 2.7.14 (default, Nov  4 2017, 00:12:32) \n[GCC 5.3.0] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>>",
            "title": "Python Interpreter"
        },
        {
            "location": "/Python/#running-an-application",
            "text": "Say, you have a Python application called  myapp.py  in your current directory.\nTo execute this with Pyhton 2.7 inside an enclave, you need to set some environment variables.     To run Python inside of an enclave, you can set the environment variable  SCONE_MODE=HW  and  SCONE_ALPINE=1 .    To issue some debug messages that show that we are running inside an enclave, set  SCONE_VERSION=1    In general, we only permit the loading of dynamic libraries after the initial loading of the problem, only by explicitly defining  SCONE_ALLOW_DLOPEN . To enable the loading of dynamic libraries after startup (and without requiring the authentication of this library via the file shield), we set  SCONE_ALLOW_DLOPEN=2 .    Example:  docker run --rm -v \"$PWD\":/usr/src/myapp -w /usr/src/myapp -e SCONE_MODE=HW -e SCONE_ALLOW_DLOPEN=2 -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:python27 python myapp.py\n\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\n...  NOTE  In some cases the SGX device cannot be opened inside of a container - despite being mapped in the container with  --device  and being visible inside of the container. In this case, try to map the devices inside of the container as a volume via  -v /dev/isgx:/dev/isgx --privileged . For example, you might execute:  sudo docker run -v /dev/isgx:/dev/isgx --privileged -e SCONE_MODE=HW -e SCONE_ALLOW_DLOPEN=2 -e SCONE_ALPINE=1 -e SCONE_VERSION=1 sconecuratedimages/crosscompilers:python27 python -c \"print('hello')\"",
            "title": "Running an application"
        },
        {
            "location": "/Python/#example_1",
            "text": "Let's look at another example:    We use  pip  to install a Python chess library.    Then we run Python inside of an enclave and  import the chess library.     We use the Scholar's mate example from  https://pypi.python.org/pypi/python-chess     \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Example"
        },
        {
            "location": "/GO/",
            "text": "GO\n\n\nSCONE supports cross-compiling GO programs to run these inside of SGX enclaves. The GO cross-compiler is part of image \nsconecuratedimages/crosscompilers:scone\n.\n\n\nExample\n\n\nStart the SCONE crosscompiler container:\n\n\ndocker run -it -p 8080:8080 sconecuratedimages/crosscompilers:scone\n\n\n\n\nLets consider a simple GO program (take from a \nGO tutorial\n):\n\n\ncat > web-srv.go << EOF\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n)\n\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    fmt.Fprintf(w, \"Hi there, I love %s!\", r.URL.Path[1:])\n}\n\nfunc main() {\n    http.HandleFunc(\"/\", handler)\n    http.ListenAndServe(\":8080\", nil)\n}\nEOF\n\n\n\n\nYou can cross-compile this program as follows:\n\n\nSCONE_HEAP=1G scone-gccgo web-srv.go -O3 -o web-srv-go -g\n\n\n\n\nYou can start the compiled program (and enable some debug messages) as follows:\n\n\nSCONE_VERSION=1 ./web-srv-go\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=1073741824\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=no\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl\n\n\n\n\n\n\nYou can now connect to port 8080, for example, with \ncurl\n:\n\n\n> curl localhost:8080/SCONE\nHi there, I love SCONE!\n\n\n\n\nDebugging\n\n\nSCONE supports debugging of programs running inside of an enclave with the help of gdb.\n\n\nDebugging inside of a container\n\n\nStandard containers have not sufficient rights to use the debugger.  Hence, you must start a container with \nSYS_PTRACE\n capability. For example:\n\n\ndocker run --cap-add SYS_PTRACE -it -p 8080:8080 -v \"$PWD\"/EXAMPLE:/usr/src/myapp -w /usr/src/myapp  sconecuratedimages/crosscompilers:scone\n\n\n\n\nHandling Illegal instructions\n\n\nSome instructions, like CPUID, are not permitted inside of enclaves. For some of these instructions, like CPUID, we provide an automatic emulation. However, we recommend not to use any illegal instructions inside of enclaves despite having an automatic emulation of these instructions. For example, we provide static replacements of the CPUID instruction. \n\n\nIf your program contains some illegal instructions, you need to ask the debugger to forward the signals,\nthat these illegal instructions cause, to the program via \nhandle SIGILL nostop pass\n: \n\n\nscone-gdb ./web-srv-go\nGNU gdb (Ubuntu 7.12.50.20170314-0ubuntu1.1) 7.12.50.20170314-git\nCopyright (C) 2017 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n<http://www.gnu.org/software/gdb/bugs/>.\nFind the GDB manual and other documentation resources online at:\n<http://www.gnu.org/software/gdb/documentation/>.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nSource directories searched: /opt/scone/scone-gdb/gdb-sgxmusl-plugin:$cdir:$cwd\nSetting environment variable \"LD_PRELOAD\" to null value.\nReading symbols from ./web-srv-go...done.\n[SCONE] Initializing...\n(gdb) handle SIGILL nostop pass\nSignal        Stop  Print   Pass to program Description\nSIGILL        No    Yes Yes     Illegal instruction\n(gdb)\n\n\n\n\nSince we do not patch the CPUID instructions in this run, you will see something like this:\n\n\n(gdb) run\nStarting program: /usr/src/myapp/web-srv-go \nwarning: Error disabling address space randomization: Operation not permitted\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n[SCONE] Enclave base: 1000000000\n[SCONE] Loaded debug symbols\n[New Thread 0x7f1786d26700 (LWP 105)]\n[New Thread 0x7f1786525700 (LWP 106)]\n[New Thread 0x7f1785d24700 (LWP 107)]\n[New Thread 0x7f1785523700 (LWP 108)]\n[New Thread 0x7f1787502700 (LWP 109)]\n[New Thread 0x7f17874fa700 (LWP 110)]\n[New Thread 0x7f17874f2700 (LWP 111)]\n[New Thread 0x7f17874ea700 (LWP 112)]\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 8 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\n\n\n\n\nYou could interrupt this execution via control c:\n\n\n^C\nThread 1 \"web-srv-go\" received signal SIGINT, Interrupt.\n0x00007f17870f69dd in pthread_join (threadid=139739022911232, thread_return=0x7ffe1c807928) at pthread_join.c:90\n90  pthread_join.c: No such file or directory.\n(gdb) where\n#0  0x00007f17870f69dd in pthread_join (threadid=139739022911232, thread_return=0x7ffe1c807928) at pthread_join.c:90\n#1  0x0000002000004053 in main (argc=1, argv=0x7ffe1c807c18, envp=0x7ffe1c807c28) at ./tools/starter-exec.c:764\n(gdb) cont\nContinuing.\n\n\n\n\nBreakpoints\n\n\nOf course, you might also set breakpoints. Say, we want to get control in the debugger whenever a request is being\nprocessed by the handler. We would set a breakpoint at function \nmain.handler\n as follows:\n\n\n> scone-gdb ./web-srv-go\n...\n[SCONE] Initializing...\n(gdb) handle SIGILL nostop pass\nSignal        Stop      Print   Pass to program Description\nSIGILL        No        Yes     Yes             Illegal instruction\n(gdb) break main.handler\nFunction \"main.handler\" not defined.\nMake breakpoint pending on future shared library load? (y or [n]) y\nBreakpoint 1 (main.handler) pending.\n(gdb) run\nStarting program: /usr/src/myapp/web-srv-go \nwarning: Error disabling address space randomization: Operation not permitted\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n[SCONE] Enclave base: 1000000000\n[SCONE] Loaded debug symbols\n[New Thread 0x7fb6cad32700 (LWP 243)]\n[New Thread 0x7fb6ca531700 (LWP 244)]\n[New Thread 0x7fb6c9d30700 (LWP 245)]\n[New Thread 0x7fb6c952f700 (LWP 246)]\n[New Thread 0x7fb6cb50e700 (LWP 247)]\n[New Thread 0x7fb6cb506700 (LWP 248)]\n[New Thread 0x7fb6cb4fe700 (LWP 249)]\n[New Thread 0x7fb6cb4f6700 (LWP 250)]\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\n\n\n\nNote that at the time when we are setting the breakpoint, the symbols of the code running inside\nof the enclave are not yet known. Hence, we just let gdb know that the symbol will be defined later on.\n\n\nWe are now sending a request with the help of \ncurl\n from a different window. This triggers the breakpoint:\n\n\n[Switching to Thread 0x7fb6cb506700 (LWP 248)]\n\nThread 7 \"web-srv-go\" hit Breakpoint 1, main.handler (w=..., r=0x100909e300) at web-srv.go:8\n8       func handler(w http.ResponseWriter, r *http.Request) {\n(gdb) n\n9           fmt.Fprintf(w, \"Hi there, I love %s!\", r.URL.Path[1:])\n(gdb) n\n8       func handler(w http.ResponseWriter, r *http.Request) {\n(gdb) c\nContinuing.\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "GO"
        },
        {
            "location": "/GO/#go",
            "text": "SCONE supports cross-compiling GO programs to run these inside of SGX enclaves. The GO cross-compiler is part of image  sconecuratedimages/crosscompilers:scone .",
            "title": "GO"
        },
        {
            "location": "/GO/#example",
            "text": "Start the SCONE crosscompiler container:  docker run -it -p 8080:8080 sconecuratedimages/crosscompilers:scone  Lets consider a simple GO program (take from a  GO tutorial ):  cat > web-srv.go << EOF\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n)\n\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    fmt.Fprintf(w, \"Hi there, I love %s!\", r.URL.Path[1:])\n}\n\nfunc main() {\n    http.HandleFunc(\"/\", handler)\n    http.ListenAndServe(\":8080\", nil)\n}\nEOF  You can cross-compile this program as follows:  SCONE_HEAP=1G scone-gccgo web-srv.go -O3 -o web-srv-go -g  You can start the compiled program (and enable some debug messages) as follows:  SCONE_VERSION=1 ./web-srv-go\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=1073741824\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=no\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl  You can now connect to port 8080, for example, with  curl :  > curl localhost:8080/SCONE\nHi there, I love SCONE!",
            "title": "Example"
        },
        {
            "location": "/GO/#debugging",
            "text": "SCONE supports debugging of programs running inside of an enclave with the help of gdb.  Debugging inside of a container  Standard containers have not sufficient rights to use the debugger.  Hence, you must start a container with  SYS_PTRACE  capability. For example:  docker run --cap-add SYS_PTRACE -it -p 8080:8080 -v \"$PWD\"/EXAMPLE:/usr/src/myapp -w /usr/src/myapp  sconecuratedimages/crosscompilers:scone  Handling Illegal instructions  Some instructions, like CPUID, are not permitted inside of enclaves. For some of these instructions, like CPUID, we provide an automatic emulation. However, we recommend not to use any illegal instructions inside of enclaves despite having an automatic emulation of these instructions. For example, we provide static replacements of the CPUID instruction.   If your program contains some illegal instructions, you need to ask the debugger to forward the signals,\nthat these illegal instructions cause, to the program via  handle SIGILL nostop pass :   scone-gdb ./web-srv-go\nGNU gdb (Ubuntu 7.12.50.20170314-0ubuntu1.1) 7.12.50.20170314-git\nCopyright (C) 2017 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n<http://www.gnu.org/software/gdb/bugs/>.\nFind the GDB manual and other documentation resources online at:\n<http://www.gnu.org/software/gdb/documentation/>.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nSource directories searched: /opt/scone/scone-gdb/gdb-sgxmusl-plugin:$cdir:$cwd\nSetting environment variable \"LD_PRELOAD\" to null value.\nReading symbols from ./web-srv-go...done.\n[SCONE] Initializing...\n(gdb) handle SIGILL nostop pass\nSignal        Stop  Print   Pass to program Description\nSIGILL        No    Yes Yes     Illegal instruction\n(gdb)  Since we do not patch the CPUID instructions in this run, you will see something like this:  (gdb) run\nStarting program: /usr/src/myapp/web-srv-go \nwarning: Error disabling address space randomization: Operation not permitted\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n[SCONE] Enclave base: 1000000000\n[SCONE] Loaded debug symbols\n[New Thread 0x7f1786d26700 (LWP 105)]\n[New Thread 0x7f1786525700 (LWP 106)]\n[New Thread 0x7f1785d24700 (LWP 107)]\n[New Thread 0x7f1785523700 (LWP 108)]\n[New Thread 0x7f1787502700 (LWP 109)]\n[New Thread 0x7f17874fa700 (LWP 110)]\n[New Thread 0x7f17874f2700 (LWP 111)]\n[New Thread 0x7f17874ea700 (LWP 112)]\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 8 \"web-srv-go\" received signal SIGILL, Illegal instruction.  You could interrupt this execution via control c:  ^C\nThread 1 \"web-srv-go\" received signal SIGINT, Interrupt.\n0x00007f17870f69dd in pthread_join (threadid=139739022911232, thread_return=0x7ffe1c807928) at pthread_join.c:90\n90  pthread_join.c: No such file or directory.\n(gdb) where\n#0  0x00007f17870f69dd in pthread_join (threadid=139739022911232, thread_return=0x7ffe1c807928) at pthread_join.c:90\n#1  0x0000002000004053 in main (argc=1, argv=0x7ffe1c807c18, envp=0x7ffe1c807c28) at ./tools/starter-exec.c:764\n(gdb) cont\nContinuing.  Breakpoints  Of course, you might also set breakpoints. Say, we want to get control in the debugger whenever a request is being\nprocessed by the handler. We would set a breakpoint at function  main.handler  as follows:  > scone-gdb ./web-srv-go\n...\n[SCONE] Initializing...\n(gdb) handle SIGILL nostop pass\nSignal        Stop      Print   Pass to program Description\nSIGILL        No        Yes     Yes             Illegal instruction\n(gdb) break main.handler\nFunction \"main.handler\" not defined.\nMake breakpoint pending on future shared library load? (y or [n]) y\nBreakpoint 1 (main.handler) pending.\n(gdb) run\nStarting program: /usr/src/myapp/web-srv-go \nwarning: Error disabling address space randomization: Operation not permitted\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n[SCONE] Enclave base: 1000000000\n[SCONE] Loaded debug symbols\n[New Thread 0x7fb6cad32700 (LWP 243)]\n[New Thread 0x7fb6ca531700 (LWP 244)]\n[New Thread 0x7fb6c9d30700 (LWP 245)]\n[New Thread 0x7fb6c952f700 (LWP 246)]\n[New Thread 0x7fb6cb50e700 (LWP 247)]\n[New Thread 0x7fb6cb506700 (LWP 248)]\n[New Thread 0x7fb6cb4fe700 (LWP 249)]\n[New Thread 0x7fb6cb4f6700 (LWP 250)]\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.\n\nThread 6 \"web-srv-go\" received signal SIGILL, Illegal instruction.  Note that at the time when we are setting the breakpoint, the symbols of the code running inside\nof the enclave are not yet known. Hence, we just let gdb know that the symbol will be defined later on.  We are now sending a request with the help of  curl  from a different window. This triggers the breakpoint:  [Switching to Thread 0x7fb6cb506700 (LWP 248)]\n\nThread 7 \"web-srv-go\" hit Breakpoint 1, main.handler (w=..., r=0x100909e300) at web-srv.go:8\n8       func handler(w http.ResponseWriter, r *http.Request) {\n(gdb) n\n9           fmt.Fprintf(w, \"Hi there, I love %s!\", r.URL.Path[1:])\n(gdb) n\n8       func handler(w http.ResponseWriter, r *http.Request) {\n(gdb) c\nContinuing.  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Debugging"
        },
        {
            "location": "/SCONE_ENV/",
            "text": "SCONE Environment Variables\n\n\nTo simplify development and debugging, SCONE supports a range of environment variables to control its behavior. These environment variables are mainly used for development and debugging. In operational settings, the configuration would be provided in a secure fashion via the SCONE configuration and attestation service.\n\n\nAlso, the performance of SCONE-based applications can be tuned by selecting the appropriate configuration for an application. We have tool support to automatically tune these parameters.\n\n\nSCONE Configuration File\n\n\nThe location of the SCONE configuration file can be controlled with an environment variable:\n\n\n\n\nSCONE_CONFIG\n: if defined, this determines the path of SCONE configuration file. If this environment variable is not defined or the file cannot be opened,  the default configuration file located in \n/etc/sgx-musl.conf\n is read instead. If the default configuration file cannot be read either, the program exits with an error message.\n\n\n\n\nChanging the location of the configuration file is, for example, useful in the context of testing or when you run your application outside of a container when you want to run different applications with different configurations inside of enclaves.\n\n\nThe configuration file can define most of the  behaviors that one can define via environment variables.\nHowever, the \nSCONE_* \n environment variables have higher priority than the settings from the config file.\n\n\nFormat of SCONE Configuration File\n\n\nThe format for the configuration file: on each line, there is a\nstatement beginning with a single-character command code, and up to\nthree numbers. The possible commands currently are:\n\n\n\n\nQ \nn\n  - defines the number of queues used to execute system calls\n\n\nn = number of queues\n: sets the number of syscall-return queue pairs to allocate. This is equivalent to setting the \nSCONE_QUEUES\n environment variable;\n\n\n\n\n\n\nH \ns\n - defines the heap size in bytes\n\n\ns = heap size in bytes\n: sets the size of heap, equivalent to setting \nSCONE_HEAP\n environment variable;\n\n\n\n\n\n\nP \nN\n - determines the backoff behavior of the queues\n\n\nN = spin number\n: equivalent to setting \nSCONE_SSPINS\n environment variable;\n\n\n\n\n\n\nL \nS\n - determines the backoff behavior of the queues\n\n\nS = sleep time\n: equivalent to setting \nSCONE_SSLEEP\n environment variable;\n\n\n\n\n\n\ns \nC Q R\n  - \nsthread\n serving system calls outside of an enclave\n\n\nC = core-no\n: if non-negative number: pin this sthread to core \nC\n; if a negative number, do not pin this thread\n\n\nQ = queue-no in [0..n]\n: this sthreads serves this queue\n\n\nR = realtime?\n: always set this to 0\n\n\n\n\n\n\ne \nC Q R\n  \nethread\n running inside of enclave and executes application threads (which we call lthreads)\n\n\nC = core-no\n: non-negative number: pin to this core; negative number: no pinning ot this thread\n\n\nQ = queue-no in [0..n]\n: this sthreads serves this queue\n\n\nR = realtime?\n: always set this to 0\n\n\n\n\n\n\n\n\nNote\n For now, the number of \nsthreads\n should always be larger than the number of  \nlthreads\n blocked in system calls.\nIn a first approximation, you could set the number of \nsthreads\n as follows.\n\n\n # sthreads  =  # ethreads + # lthreads \n \n\n\nWe plan to automatically adjust the number of \nsthreads\n and \nethreads\n in the future. \n\n\nRun Mode\n\n\n\n\n\n\nSCONE_MODE\n: defines if application should run inside of an enclave or outside in simulation mode.\n\n\n\n\n\n\n=HW\n: run program inside of enclave. If program fails to create an enclave, it will fail.\n\n\n\n\n\n\n=SIM\n: run program outside of enclave. All SCONE related software runs but just outside of the enclave. This is not 100% compatible with hardware mode since, for example, some instructions are permitted in native mode that are not permitted in hardware mode.\n\n\n\n\n\n\n=AUTO\n: run program inside of enclave if SGX is available. Otherwise, run in simulation mode.\n\n\n\n\n\n\n\n\n\n\nSCONE_HEAP\n: size of the heap allocated for the program during the startup of the enclave.\n\n\n\n\n=s\n  the requested heap size in bytes\n\n\n\n\n\n\n\n\nDebug\n\n\n\n\nSCONE_VERSION\n if defined, SCONE will print the values of some of the SCONE environment variables during startup.\n\n\n\n\nExample output:\n\n\nexport SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=1073741824\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=no\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl\n\n\n\n\nDynamic library support:\n\n\n\n\n\n\nSCONE_ALLOW_DLOPEN\n: if defined, permit to load shared libraries during startup. All libraries that are loaded during startup are measured and contribute to the hash of the enclave, i.e., the are part of \nMRENCLAVE\n.\n\n\n\n\n\n\nSCONE_ALLOW_DLOPEN=\"2\"\n: not only can dynamic libraries be loaded during startup but also later on. For example, Python programs might dynamically load modules after startup. Our approach to enforce the integrity of these dynamic libraries with the help of a file protection shield.\n\n\n\n\n\n\nPerformance tuning variables:\n\n\n\n\n\n\nSCONE_QUEUES\n: number of systemcall queues to be used.\n\n\n\n\n\n\nSCONE_SLOTS\n: systemcall queue length: must be larger than the maximum number of \nlthreads\n.\n\n\n\n\n\n\nSCONE_SIGPIPE\n: if set to \"1\", \nSIGPIPE\n signals are delivered to the application\n\n\n\n\n\n\nSCONE_SSPINS=N\n: In case an Ethread does not have any lthread to execute, an Ethread first pauses for up to N times to wait for more work to show up. After that, it sleeps for up to N times. Each time increasing the sleep time. \n\n\n\n\n\n\nSCONE_SSLEEP\n: determines how fast we increase the backoff.\n\n\n\n\n\n\nSafety\n\n\n\n\nSCONE_SGXBOUNDS\n: must be defined to enable bounds checking. Furthermore, you need to compile your program with our SGX boundschecker.\n\n\n\n\nDynamic link loader\n\n\nThe dynamic link loader is part of image \nsconecuratedimages/crosscompilers:runtime\n (\nsee tutorial\n).\n\n\n\n\n\n\nLD_LIBRARY_PATH\n: you can control from where the dynamic link loader looks for shared libraries.\n\n\n\n\n\n\nLD_PRELOAD\n: you can instruct the dynamic link loader to load libraries before loading the libraries specified by the program itself.\n\n\n\n\n\n\nSCONE_ALPINE=1\n: run dynamically-linked program inside of an enclave.\n\n\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Environment variables"
        },
        {
            "location": "/SCONE_ENV/#scone-environment-variables",
            "text": "To simplify development and debugging, SCONE supports a range of environment variables to control its behavior. These environment variables are mainly used for development and debugging. In operational settings, the configuration would be provided in a secure fashion via the SCONE configuration and attestation service.  Also, the performance of SCONE-based applications can be tuned by selecting the appropriate configuration for an application. We have tool support to automatically tune these parameters.",
            "title": "SCONE Environment Variables"
        },
        {
            "location": "/SCONE_ENV/#scone-configuration-file",
            "text": "The location of the SCONE configuration file can be controlled with an environment variable:   SCONE_CONFIG : if defined, this determines the path of SCONE configuration file. If this environment variable is not defined or the file cannot be opened,  the default configuration file located in  /etc/sgx-musl.conf  is read instead. If the default configuration file cannot be read either, the program exits with an error message.   Changing the location of the configuration file is, for example, useful in the context of testing or when you run your application outside of a container when you want to run different applications with different configurations inside of enclaves.  The configuration file can define most of the  behaviors that one can define via environment variables.\nHowever, the  SCONE_*   environment variables have higher priority than the settings from the config file.  Format of SCONE Configuration File  The format for the configuration file: on each line, there is a\nstatement beginning with a single-character command code, and up to\nthree numbers. The possible commands currently are:   Q  n   - defines the number of queues used to execute system calls  n = number of queues : sets the number of syscall-return queue pairs to allocate. This is equivalent to setting the  SCONE_QUEUES  environment variable;    H  s  - defines the heap size in bytes  s = heap size in bytes : sets the size of heap, equivalent to setting  SCONE_HEAP  environment variable;    P  N  - determines the backoff behavior of the queues  N = spin number : equivalent to setting  SCONE_SSPINS  environment variable;    L  S  - determines the backoff behavior of the queues  S = sleep time : equivalent to setting  SCONE_SSLEEP  environment variable;    s  C Q R   -  sthread  serving system calls outside of an enclave  C = core-no : if non-negative number: pin this sthread to core  C ; if a negative number, do not pin this thread  Q = queue-no in [0..n] : this sthreads serves this queue  R = realtime? : always set this to 0    e  C Q R    ethread  running inside of enclave and executes application threads (which we call lthreads)  C = core-no : non-negative number: pin to this core; negative number: no pinning ot this thread  Q = queue-no in [0..n] : this sthreads serves this queue  R = realtime? : always set this to 0     Note  For now, the number of  sthreads  should always be larger than the number of   lthreads  blocked in system calls.\nIn a first approximation, you could set the number of  sthreads  as follows.   # sthreads  =  # ethreads + # lthreads     We plan to automatically adjust the number of  sthreads  and  ethreads  in the future.",
            "title": "SCONE Configuration File"
        },
        {
            "location": "/SCONE_ENV/#run-mode",
            "text": "SCONE_MODE : defines if application should run inside of an enclave or outside in simulation mode.    =HW : run program inside of enclave. If program fails to create an enclave, it will fail.    =SIM : run program outside of enclave. All SCONE related software runs but just outside of the enclave. This is not 100% compatible with hardware mode since, for example, some instructions are permitted in native mode that are not permitted in hardware mode.    =AUTO : run program inside of enclave if SGX is available. Otherwise, run in simulation mode.      SCONE_HEAP : size of the heap allocated for the program during the startup of the enclave.   =s   the requested heap size in bytes",
            "title": "Run Mode"
        },
        {
            "location": "/SCONE_ENV/#debug",
            "text": "SCONE_VERSION  if defined, SCONE will print the values of some of the SCONE environment variables during startup.   Example output:  export SCONE_QUEUES=4\nexport SCONE_SLOTS=256\nexport SCONE_SIGPIPE=0\nexport SCONE_MMAP32BIT=0\nexport SCONE_SSPINS=100\nexport SCONE_SSLEEP=4000\nexport SCONE_KERNEL=0\nexport SCONE_HEAP=1073741824\nexport SCONE_CONFIG=/etc/sgx-musl.conf\nexport SCONE_MODE=hw\nexport SCONE_SGXBOUNDS=no\nexport SCONE_ALLOW_DLOPEN=no\nRevision: 9b355b99170ad434010353bb9f4dca24e532b1b7\nBranch: master\nConfigure options: --enable-file-prot --enable-shared --enable-debug --prefix=/scone/src/built/cross-compiler/x86_64-linux-musl",
            "title": "Debug"
        },
        {
            "location": "/SCONE_ENV/#dynamic-library-support",
            "text": "SCONE_ALLOW_DLOPEN : if defined, permit to load shared libraries during startup. All libraries that are loaded during startup are measured and contribute to the hash of the enclave, i.e., the are part of  MRENCLAVE .    SCONE_ALLOW_DLOPEN=\"2\" : not only can dynamic libraries be loaded during startup but also later on. For example, Python programs might dynamically load modules after startup. Our approach to enforce the integrity of these dynamic libraries with the help of a file protection shield.",
            "title": "Dynamic library support:"
        },
        {
            "location": "/SCONE_ENV/#performance-tuning-variables",
            "text": "SCONE_QUEUES : number of systemcall queues to be used.    SCONE_SLOTS : systemcall queue length: must be larger than the maximum number of  lthreads .    SCONE_SIGPIPE : if set to \"1\",  SIGPIPE  signals are delivered to the application    SCONE_SSPINS=N : In case an Ethread does not have any lthread to execute, an Ethread first pauses for up to N times to wait for more work to show up. After that, it sleeps for up to N times. Each time increasing the sleep time.     SCONE_SSLEEP : determines how fast we increase the backoff.",
            "title": "Performance tuning variables:"
        },
        {
            "location": "/SCONE_ENV/#safety",
            "text": "SCONE_SGXBOUNDS : must be defined to enable bounds checking. Furthermore, you need to compile your program with our SGX boundschecker.",
            "title": "Safety"
        },
        {
            "location": "/SCONE_ENV/#dynamic-link-loader",
            "text": "The dynamic link loader is part of image  sconecuratedimages/crosscompilers:runtime  ( see tutorial ).    LD_LIBRARY_PATH : you can control from where the dynamic link loader looks for shared libraries.    LD_PRELOAD : you can instruct the dynamic link loader to load libraries before loading the libraries specified by the program itself.    SCONE_ALPINE=1 : run dynamically-linked program inside of an enclave.    \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Dynamic link loader"
        },
        {
            "location": "/SCONE_Publications/",
            "text": "SCONE Related Publications\n\n\nSCONE: Secure Linux Containers with Intel SGX, USENIX, OSDI 2016\n\n\nThis paper describes how we support unmodified applications inside of enclaves. The focus is on our asynchronous system\n call interface.\n\n\n\n\n\n\nAuthors\n:  Sergei Arnautov, Bohdan Trach, Franz Gregor, Thomas Knauth, Andr\u00e9 Martin, Christian Priebe, Joshua Lind, Divya Muthukumaran, Daniel O'Keeffe, Mark L Stillwell, David Goltzsche, Dave Eyers, R\u00fcdiger Kapitza, Peter Pietzuch, Christof Fetzer\n\n\n\n\n\n\nMedia\n: \npdf\n, \nslides\n\n\naudio\n\n\n\n\n\n\nAbstract\n:  In multi-tenant environments, Linux containers managed by Docker or Kubernetes have a lower resource footprint, faster startup times, and higher I/O performance compared to virtual machines (VMs) on hypervisors. Yet their weaker isolation guarantees, enforced through software kernel mechanisms, make it easier for attackers to compromise the confidentiality and integrity of application data within containers.\nWe describe SCONE, a secure container mechanism for Docker that uses the SGX trusted execution support of Intel CPUs to protect container processes from outside attacks. The design of SCONE leads to (i) a small trusted computing base (TCB) and (ii) a low performance overhead: SCONE offers a secure C standard library interface that transparently encrypts/decrypts I/O data; to reduce the performance impact of thread synchronization and system calls within SGX enclaves, SCONE supports user-level threading and asynchronous system calls. Our evaluation shows that it protects unmodified applications with SGX, achieving 0.6x\u20131.2x of native throughput.\n\n\n\n\n\n\n Building Critical Applications Using Microservices, IEEE Security & Privacy, Volume: 14 Issue: 6, December 2016 \n\n\n\n\n\n\nAuthor\n: Christof Fetzer\n\n\n\n\n\n\nMedia\n: \nhtml\n\n\n\n\n\n\nAbstract\n: Safeguarding the correctness of critical software is a grand challenge. A microservice-based system is described that builds trustworthy systems on top of legacy hardware and software components, ensuring microservices' integrity, confidentiality, and correct execution with the help of secure enclaves.\n\n\n\n\n\n\n SGXBounds: Memory Safety for Shielded Execution, EuroSys 2017\n\n\nTo protect the code running inside of an enclave, we implemented a novel bounds checker for enclaves. While we had expected\n to just be able to use MPX, we had to realized that MPX does not perform that well inside of enclaves. For details regarding\n the overheads,  please see this paper. \nThis won the best paper award of EuroSys 2017.\n\n\n\n\n\n\nAuthors\n: D. Kuvaiskii, O. Oleksenko, S. Arnautov, B. Trach, P. Bhatotia, P. Felber, C. Fetzer \n\n\n\n\n\n\nMedia\n: \npdf\n \n\n\n\n\n\n\nAbstract\n: Shielded execution based on Intel SGX provides strong security guarantees for legacy applications running on untrusted platforms. However, memory safety attacks such as Heartbleed can render the confidentiality and integrity properties of shielded execution completely ineffective. To prevent these attacks, the state-of-the-art memory-safety approaches can be used in the context of shielded execution. In this work, we first showcase that two prominent software- and hardware-based defenses, AddressSanitizer and Intel MPX respectively, are impractical for shielded execution due to high performance and memory overheads. This motivated our design of SGXBounds -- an efficient memory-safety approach for shielded execution exploiting the architectural features of Intel SGX. Our design is based on a simple combination of tagged pointers and compact memory layout. We implemented SGXBounds based on the LLVM compiler framework targeting unmodified multithreaded applications. Our evaluation using Phoenix, PARSEC, and RIPE benchmark suites shows that SGXBounds has performance and memory overheads of 18% and 0.1% respectively, while providing security guarantees similar to AddressSanitizer and Intel MPX. We have obtained similar results with four real-world case studies: SQLite, Memcached, Apache, and Nginx.\n\n\n\n\n\n\n FFQ: A Fast Single-Producer/Multiple-Consumer Concurrent FIFO Queue, IPDPS 2017\n\n\nThis paper describes our new lock-free queue for our asynchronous system calls.\n\n\n\n\n\n\nAuthors\n: Sergei Arnautov, Pascal Felber, Christof Fetzer and Bohdan Trach\n\n\n\n\n\n\nMedia\n: \nsorry, not yet available\n \n\n\n\n\n\n\nAbstract\n:  With the spreading of multi-core architectures, operating systems and applications are becoming increasingly more concurrent and their scalability is often limited by the primitives used to synchronize the different hardware threads. In this paper, we address the problem of how to optimize the throughput of a system with multiple producer and consumer threads. Such applications typically synchronize their threads via multi- producer/multi-consumer FIFO queues, but existing solutions have poor scalability, as we could observe when designing a secure application framework that requires high-throughput communication between many concurrent threads. In our target system, however, the items enqueued by different producers do not necessarily need to be FIFO ordered. Hence, we propose a fast FIFO queue, FFQ, that aims at maximizing throughput by specializing the algorithm for single-producer/multiple-consumer settings: each producer has its own queue from which multiple consumers can concurrently dequeue. Furthermore, while we pro- vide a wait-free interface for producers, we limit ourselves to lock-free consumers to eliminate the need for helping. We also propose a multi-producer variant to show which synchronization operations we were able to remove by focusing on a single producer variant. Our evaluation analyses the performance using micro- benchmarks and compares our results with other state-of-the-art solutions: FFQ exhibits excellent performance and scalability.\n\n\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "SCONE Publications"
        },
        {
            "location": "/SCONE_Publications/#scone-related-publications",
            "text": "SCONE: Secure Linux Containers with Intel SGX, USENIX, OSDI 2016  This paper describes how we support unmodified applications inside of enclaves. The focus is on our asynchronous system\n call interface.    Authors :  Sergei Arnautov, Bohdan Trach, Franz Gregor, Thomas Knauth, Andr\u00e9 Martin, Christian Priebe, Joshua Lind, Divya Muthukumaran, Daniel O'Keeffe, Mark L Stillwell, David Goltzsche, Dave Eyers, R\u00fcdiger Kapitza, Peter Pietzuch, Christof Fetzer    Media :  pdf ,  slides  audio    Abstract :  In multi-tenant environments, Linux containers managed by Docker or Kubernetes have a lower resource footprint, faster startup times, and higher I/O performance compared to virtual machines (VMs) on hypervisors. Yet their weaker isolation guarantees, enforced through software kernel mechanisms, make it easier for attackers to compromise the confidentiality and integrity of application data within containers.\nWe describe SCONE, a secure container mechanism for Docker that uses the SGX trusted execution support of Intel CPUs to protect container processes from outside attacks. The design of SCONE leads to (i) a small trusted computing base (TCB) and (ii) a low performance overhead: SCONE offers a secure C standard library interface that transparently encrypts/decrypts I/O data; to reduce the performance impact of thread synchronization and system calls within SGX enclaves, SCONE supports user-level threading and asynchronous system calls. Our evaluation shows that it protects unmodified applications with SGX, achieving 0.6x\u20131.2x of native throughput.     Building Critical Applications Using Microservices, IEEE Security & Privacy, Volume: 14 Issue: 6, December 2016     Author : Christof Fetzer    Media :  html    Abstract : Safeguarding the correctness of critical software is a grand challenge. A microservice-based system is described that builds trustworthy systems on top of legacy hardware and software components, ensuring microservices' integrity, confidentiality, and correct execution with the help of secure enclaves.     SGXBounds: Memory Safety for Shielded Execution, EuroSys 2017  To protect the code running inside of an enclave, we implemented a novel bounds checker for enclaves. While we had expected\n to just be able to use MPX, we had to realized that MPX does not perform that well inside of enclaves. For details regarding\n the overheads,  please see this paper.  This won the best paper award of EuroSys 2017.    Authors : D. Kuvaiskii, O. Oleksenko, S. Arnautov, B. Trach, P. Bhatotia, P. Felber, C. Fetzer     Media :  pdf      Abstract : Shielded execution based on Intel SGX provides strong security guarantees for legacy applications running on untrusted platforms. However, memory safety attacks such as Heartbleed can render the confidentiality and integrity properties of shielded execution completely ineffective. To prevent these attacks, the state-of-the-art memory-safety approaches can be used in the context of shielded execution. In this work, we first showcase that two prominent software- and hardware-based defenses, AddressSanitizer and Intel MPX respectively, are impractical for shielded execution due to high performance and memory overheads. This motivated our design of SGXBounds -- an efficient memory-safety approach for shielded execution exploiting the architectural features of Intel SGX. Our design is based on a simple combination of tagged pointers and compact memory layout. We implemented SGXBounds based on the LLVM compiler framework targeting unmodified multithreaded applications. Our evaluation using Phoenix, PARSEC, and RIPE benchmark suites shows that SGXBounds has performance and memory overheads of 18% and 0.1% respectively, while providing security guarantees similar to AddressSanitizer and Intel MPX. We have obtained similar results with four real-world case studies: SQLite, Memcached, Apache, and Nginx.     FFQ: A Fast Single-Producer/Multiple-Consumer Concurrent FIFO Queue, IPDPS 2017  This paper describes our new lock-free queue for our asynchronous system calls.    Authors : Sergei Arnautov, Pascal Felber, Christof Fetzer and Bohdan Trach    Media :  sorry, not yet available      Abstract :  With the spreading of multi-core architectures, operating systems and applications are becoming increasingly more concurrent and their scalability is often limited by the primitives used to synchronize the different hardware threads. In this paper, we address the problem of how to optimize the throughput of a system with multiple producer and consumer threads. Such applications typically synchronize their threads via multi- producer/multi-consumer FIFO queues, but existing solutions have poor scalability, as we could observe when designing a secure application framework that requires high-throughput communication between many concurrent threads. In our target system, however, the items enqueued by different producers do not necessarily need to be FIFO ordered. Hence, we propose a fast FIFO queue, FFQ, that aims at maximizing throughput by specializing the algorithm for single-producer/multiple-consumer settings: each producer has its own queue from which multiple consumers can concurrently dequeue. Furthermore, while we pro- vide a wait-free interface for producers, we limit ourselves to lock-free consumers to eliminate the need for helping. We also propose a multi-producer variant to show which synchronization operations we were able to remove by focusing on a single producer variant. Our evaluation analyses the performance using micro- benchmarks and compares our results with other state-of-the-art solutions: FFQ exhibits excellent performance and scalability.    \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "SCONE Related Publications"
        },
        {
            "location": "/glossary/",
            "text": "Glossary\n\n\n\n\n\n\ncloud-native application\n. An application designed to run inside of a cloud. One requirement is that the application is deployed with the help of containers.\n\n\n\n\n\n\ncontainer\n. An light-weight alternative to a virtual machine (VM). The isolation of containers is implemented by the operating system. Docker and Kubernetes use Linux for isolation. In the case of VMs, the isolation is implemented with the help of CPU extensions.\n\n\n\n\n\n\nenclave\n. This is an alias for \nSGX enclave\n.\n\n\n\n\n\n\nEPC\n. A cache of memory pages belonging to enclaves. This cache resides in a reserved part of the main memory that is directly managed by the CPU (and not by the operating system or the hypervisor). The data in this cache is encrypted. Unlike enclave pages residing in the main memory, the CPU can encrypt and decrypt individual cache lines residing inside the EPC. This results in low overheads.\n\n\n\n\n\n\nSecure container\n. A container which uses additional hardware isolation mechanisms, i.e., SGX to provide better application security. In particular, a secure container runs one or more \nsecure programs\n. Additionally, the integrity and confidentiality of files inside a secure container are protected by SCONE.\n\n\n\n\n\n\nSecure program\n. A program that executes inside an enclave.\n\n\n\n\n\n\nSGX\n. A CPU extension by Intel that permits to create SGX enclaves.\n\n\n\n\n\n\nSGX enclave\n. A protected area inside the address space of a program such that only the code inside this enclave can access the data and code stored in this address range. All pages belonging to an enclave are encrypted by the CPU and only the CPU knows the encryption key. These pages can reside in the main memory or the EPC.\n\n\n\n\n\n\nethread, lthread, sthread\n. SCONE usese different kind of threads:\n\n\n\n\nethread\n: a thread that executes application threads inside of an enclave\n\n\nlthread\n: an application thread. Typically, created by the application directly or indirectly via a \npthread_create\n call. In SCONE, this \npthread_create\n call will create a \nlthread\n. The lthread is executed by some \nethread\n. In this way, we can quickly switch to another application thread whenever an application thread would get block. In this way, we reduce the number of enclave entries and exits - which are costly.\n\n\nsthread\n: a thread that runs outside of the enclave and that executes system calls on behalf of the threads running inside the enclave\n\n\n\n\n\n\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "Glossary"
        },
        {
            "location": "/glossary/#glossary",
            "text": "cloud-native application . An application designed to run inside of a cloud. One requirement is that the application is deployed with the help of containers.    container . An light-weight alternative to a virtual machine (VM). The isolation of containers is implemented by the operating system. Docker and Kubernetes use Linux for isolation. In the case of VMs, the isolation is implemented with the help of CPU extensions.    enclave . This is an alias for  SGX enclave .    EPC . A cache of memory pages belonging to enclaves. This cache resides in a reserved part of the main memory that is directly managed by the CPU (and not by the operating system or the hypervisor). The data in this cache is encrypted. Unlike enclave pages residing in the main memory, the CPU can encrypt and decrypt individual cache lines residing inside the EPC. This results in low overheads.    Secure container . A container which uses additional hardware isolation mechanisms, i.e., SGX to provide better application security. In particular, a secure container runs one or more  secure programs . Additionally, the integrity and confidentiality of files inside a secure container are protected by SCONE.    Secure program . A program that executes inside an enclave.    SGX . A CPU extension by Intel that permits to create SGX enclaves.    SGX enclave . A protected area inside the address space of a program such that only the code inside this enclave can access the data and code stored in this address range. All pages belonging to an enclave are encrypted by the CPU and only the CPU knows the encryption key. These pages can reside in the main memory or the EPC.    ethread, lthread, sthread . SCONE usese different kind of threads:   ethread : a thread that executes application threads inside of an enclave  lthread : an application thread. Typically, created by the application directly or indirectly via a  pthread_create  call. In SCONE, this  pthread_create  call will create a  lthread . The lthread is executed by some  ethread . In this way, we can quickly switch to another application thread whenever an application thread would get block. In this way, we reduce the number of enclave entries and exits - which are costly.  sthread : a thread that runs outside of the enclave and that executes system calls on behalf of the threads running inside the enclave     \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Glossary"
        },
        {
            "location": "/aboutScone/",
            "text": "About SCONE\n\n\nThe SCONE platform is commercially supported by \nscontain.com\n. \n\n\nThe SCONE platform has been developed at the \nSystems Engineering group\n at \nTU Dresden\n in the context of the following EU projects:\n\n\n\n\n\n\nSereca\n which investigates how to use Intel SGX enclave in the context of reactive programs written in \nVert.x\n.\n\n\n\n\n\n\nSecure Cloud\n which focuses on the processing of (big) data in untrusted clouds.\n\n\n\n\n\n\nWe investigate use cases and extensions of SCONE in the context of the following EU projects:\n\n\n\n\n\n\nSELIS\n: we investigate how to secure data processing within a \nShared European Logistics Intelligent Information Space\n with the help of SCONE.\n\n\n\n\n\n\nATMOSPHERE\n: a new EU project in which we address secure data management services. This will help to extend the SCONE platform.\n\n\n\n\n\n\nLEGATO\n: a new EU project in which we address \nhigh integrity computations\n inside of enclaves to be able to detect and tolerate miscomputations inside of enclaves.\n\n\n\n\n\n\nComputing Resources\n\n\nscontain.com\n can provide access to SGX-capable machines with the help of \nCLOUD&HEAT\n.\n\n\nConsulting Services\n\n\nscontain.com\n provides consulting services as well as helping you to port your applications to SGX. We also have external partners like \nSIListra Systems\n that can port applications to run software inside of SGX enclaves with the help of SCONE.\n\n\nContact\n\n\nIf you want to evaluate the SCONE platform, want to rent some SGX-capable computing resources, need SGX and SCONE-related consulting, or have some technical questions, please contact us at \ninfo@scontain.com\n.\n\n\nLegal Notice\n\n\nThe content of this documentation is maintained by \nscontain.com\n.\n\n\n\u00a9 \nscontain.com\n, November 2017. \nQuestions or Suggestions?",
            "title": "About Scone"
        },
        {
            "location": "/aboutScone/#about-scone",
            "text": "The SCONE platform is commercially supported by  scontain.com .   The SCONE platform has been developed at the  Systems Engineering group  at  TU Dresden  in the context of the following EU projects:    Sereca  which investigates how to use Intel SGX enclave in the context of reactive programs written in  Vert.x .    Secure Cloud  which focuses on the processing of (big) data in untrusted clouds.    We investigate use cases and extensions of SCONE in the context of the following EU projects:    SELIS : we investigate how to secure data processing within a  Shared European Logistics Intelligent Information Space  with the help of SCONE.    ATMOSPHERE : a new EU project in which we address secure data management services. This will help to extend the SCONE platform.    LEGATO : a new EU project in which we address  high integrity computations  inside of enclaves to be able to detect and tolerate miscomputations inside of enclaves.",
            "title": "About SCONE"
        },
        {
            "location": "/aboutScone/#computing-resources",
            "text": "scontain.com  can provide access to SGX-capable machines with the help of  CLOUD&HEAT .",
            "title": "Computing Resources"
        },
        {
            "location": "/aboutScone/#consulting-services",
            "text": "scontain.com  provides consulting services as well as helping you to port your applications to SGX. We also have external partners like  SIListra Systems  that can port applications to run software inside of SGX enclaves with the help of SCONE.",
            "title": "Consulting Services"
        },
        {
            "location": "/aboutScone/#contact",
            "text": "If you want to evaluate the SCONE platform, want to rent some SGX-capable computing resources, need SGX and SCONE-related consulting, or have some technical questions, please contact us at  info@scontain.com .",
            "title": "Contact"
        },
        {
            "location": "/aboutScone/#legal-notice",
            "text": "The content of this documentation is maintained by  scontain.com .  \u00a9  scontain.com , November 2017.  Questions or Suggestions?",
            "title": "Legal Notice"
        }
    ]
}